[{"body":"User documentation and files How to chat with the team (for support, to join us, for GSoC, or anything else)\nWhat's CCExtractor? (the software, not the organization)\nAbout CCExtractor Development (the organization, not the software)\nDownloads\nChangelog\nUsing the command line tool\nUsing the Windows GUI\nReal time demo - Currently down, our primary source of data is moving to a new office and their infrastructure is not yet available.\nExtracting burned-in subtitles\nExtracting CEA-708 subtitles\nTranslating subtitles in real time\nUsing the cross-platform GUI\nExtracting closed captions from a DVD step by step tutorial\nWorking with HDHomeRun\nUsing SPUPNG\nTV samples\nDonate\nCool external projects that use subtitles\n Technical documentation Most of these pages are the result of Summer of Code work.\nGetting started with our code\nRotating capture system with HDHomeRun\nSubtitle standards around the world\nRegression system\nOnline real time repository\nSubtitle Downloader (user)\nSubtitle Downloader (technical)\nDVD Subtitles Technical Documentation GSoC'16\nPython Extension Module Technical Documentation GSoC'17\nPython Extension Module Compilation Documentation GSoC'17\nBuilding CCExtractor inside a Vagrant box\nActivity Extractor (user)\nActivity Extractor (technical)\n Google Code-in public/ pages Google Code-in 2016 task list\nGoogle Code-in 2017 code-in for designers\nGoogle Code-in 2018\nGoogle Code-in 2019 Welcome and introduction (start here)\nGoogle Code-in 2019 Flutter\nGoogle Code-in 2019 Mastermind\n Summer of Code public/ pages Ideas page for Summer of Code 2021\nIdeas page for Summer of Code 2020\nIdeas page for Summer of Code 2019\nIdeas page for Summer of Code 2018\nWelcome to Summer of Code 2016\nWelcome to Summer of Code 2015\nCcextractor Bug Hunt\nCcextractor Tasks\nCCExtractor unassigned tasks (pick what you like)\nBlog Posts from our Students\n Season of docs public/ pages Ideas page for Season of Docs 2019\nIdeas page for Season of Docs 2020\n GSoC Students Project Report 2019\nAmit - Poor Man's Rekognition\nBowen - PiPot\nFaiz - Poor Man's Rekognition \nSarfaraz - Poor Man's Rekognition\nShivam Kumar Jha - Sample Platform\n2018\nArchit - FabBits\nAaditya - Project Nephos\nShivam Kumar Jha - Project Nephos\nSaurabh Shrivastava - CCExtractor Web - A web application for subtitle extraction through CCExtractor.\nSatyam Mittal - The sample platform / Continuous integration\n2017\nDiptanshu - Python Extension Module (bindings) for CCExtractor\nSaurabh - CCAligner - Word by Word Audio Subtitle Synchronisation\nSatyam - Sample platform improvements (Windows testing)\n2016\nWillem - Sample platform iteration 2\nAbishek - Subtitle Extractor and CCExtractor improvements\nAbhinav - Extract hard-coded subtitles from video streams\nShruti - News shot classification\nRishabh - DVD Subtitle Extraction\nRuslan - Real-time Repository and website\nVasanth - Commercial detection\n2015\nWillem - Sample submission platform / CCExtractor improvements\nNurendra - Sentiment Analysis / Realtime Translation with Google Translate/Apertium\n Contract work How to hire CCExtractor developers\n Miscellaneous resources about things that interest us Rust\nFlutter\nPreparing for interviews (Silicon Valley style )\nUseful linux tools\nArticles about vim (the editor)\n","link":"https://ccextractor.org/docs/cchome/","title":"CCExtractor's home page"},{"body":"Welcome to CCExtractor CCExtractor Development is an informal (meaning we're not incorporated anywhere) organization that exists to coordinate the development efforts of the volunteers that contribute to the software and to manage our participation in specific events such as Google Summer of Code and Code-In.\nThis website is still in beta, you might come across formatting errors or pages not found. Please report them on slack.  To get in touch with us, join our slack channel. Most CCExtractor developers hang out in a slack team. You're welcome to request an invitation here  Read the DocsHere for GSoC'21?\n ","link":"https://ccextractor.org/docs/","title":"Docs"},{"body":"Welcome to our ideas page. It's great you want to start early. Please join us in our slack channel! (we'll leave as an exercise to you to find it --- it's on our website).\nThis is an \u0026quot;new way of doing things year\u0026quot;. GSoC projects are now supposed to take around 175 hours and we've adapted our ideas to reflect that. If you think any idea is too long or too short please let us know - we still need to fine tune this!\nAs you will see, this year has a lot of Rust. The reason is simple: Security. Our C code base has known (and we suspect, a lot of unknown) security issues caused by the usual memory management in C. Lots of people have touched the code over the years, and it shows.\nThere's also Flutter, which we love, and more.\nWe will provide resources for students --- we'll give access to a high-speed server, all our samples (we'll even ship a portable drive with them anywhere in the world, so don't worry about slow connections) and various other perks.\nYou are welcome to check out the page (actual ideas at the bottom of the page, with each project having it's own separate page as well) and start early in the community bonding process as well as learning a bit about our code ethics and practices. And of course, we'd love you to stay around even if we are not invited to GSoC or if we cannot invite you as a student.\nThe ideas we currently have Important: If you have something else in mind that relates to subtitles and accessibility please get in touch. We prefer that you do something that you are passionate about even if it's something we hadn't considered.\nAfter you check out our ideas please continue reading to the bottom of the page to get information about who we are, how we collaborate, what resources we will provide to you, etc.\nSome tasks descriptions are still vague. We know that. Feel free to get in touch for questions, or just check their page from time to time. We will update the descriptions often.  CCExtractor Rust rewrite    Name Description Tech you need to know Tech you will learn Difficulty     Initial Rust scaffolding Set up the base Rust infrastructure. Build with cargo. FFI. (Some) Rust, Some (C) A lot of Rust + C interoperability. CCExtractor internals Medium   Rewrite 708 decoder in Rust CEA-708 is the American standard for digital subtitles. We have a reasonably good (meaning, easy to understand, and it was written when we knew what we were doing) C base. We'd like to port it to rust. We will provide you with the official technical standards. (Some) Rust, Some (C) Digital subtitles Working with standards. Medium   Rewrite 608 decoder in Rust CEA-608 is the American standard for analog subtitles. It also carries things like emergency alerts, basic TV guide, and content classification. We have a complete implementation in C that works OK (possibly with some bugs) but that is not really very well organized. We'd like to port it to rust. We will provide you with the official technical standards. (Some) Rust, Some (C) Analog subtitles, XDS Working with standards. Medium   Rewrite the OCR subsystem in Rust. We use tesseract to OCR bitmap based subtitles. It's a great library, but because its input is a bitmap that is preprocessed (so provide a reasonable input) there's lots of places in which there can be buffer overruns, underruns… many of the problems that Rust shines on are evidenced here. So a Rust rewrite of this would be a big win. OCR Rust FFI Tesseract Imaging OCR Medium    Core subtitle tool (CCExtractor itself)    Name Description Tech you need to know Tech you will learn Difficulty     Add support for DTMB countries DTMB is the standard for Chinese TV, also implemented by countries such as Cuba. What kind of student is ideal for this task? One with lots of analytic skills and patience. If you are one of those, don't disregard this task just because you don't speak (or maybe, even care) about Chinese. The experience on dealing with this will be extremely valuable in the future.We will use part of the organization funds to buy standard documents you might need, a capture device, and in general, anything required to make your life easier. C DTMB Video standards Hardware Research Unknown   Add Japanese support Captions are used by people all over the world on a regular basis. Most of us are familiar with regular horizontal captions at the bottom of the screen, but did you know that in Japan a common position for captions is vertically on the right or left side of the screen? Come learn more about what Japanese audiences need out of captions as well as how captioning standard likes IMSC and WebVTT support these features. Japanese (or be good with foreign languages) Depends Suspected hard    Artificial Intelligence and clever algorithms    Name Description Tech you need to know Tech you will learn Difficulty     Poor man's Rekognition (III) Amazon Rekognition is a (paid) service that is able to identify celebrity faces in a picture. Last year we did some work towards creating a free alternative. This year we want to improve on the past work. Your choice AI Computer vision Unknown   Poor man's Textract Amazon Textract a (paid) service that \u0026quot;automatically extracts text and data from scanned documents. Amazon Textract goes beyond simple optical character recognition (OCR) to also identify the contents of fields in forms and information stored in tables\u0026quot;. We want to build a free alternative that provides an output of similar quality. Your choice AI Computer vision OCR Unknown    Support tools we and other orgs use as part of their development process    Name Description Tech you need to know Tech you will learn Difficulty     The sample platform (/ continuous integration) project The sample platform is a good way to help new contributors to check if their code doesn't introduce any regressions. It's pretty stable, but is often hard to interpret for new contributors, and still pretty slow if the queue builds up. We want to move the platform towards GCP (Google Cloud Platform) and run the tests on disposable instances rather than through KVM. This project is guaranteed to be selected if the proposal is good. Git Python Google Cloud API's GitHub Actions GitHub API's Continuous Integration (CI) Automated deployments GitHub integration Medium/Hard    Multimedia (misc)    Name Description Tech you need to know Tech you will learn Difficulty     Improve our reference channel for Roku  Roku is currently the most common media streamer. It's cheap and neutral (it's not in any \u0026quot;fight\u0026quot;). Unfortunately, there aren't any good open source channels, so if you want to start your own you have to start from scratch. Last year we started a new channel everyone can use as a starting point. We'd like to continue working on it, adding new features. We will send a free Roku to our student for development. None Brightscript Roku Video Streaming Medium    Flutter    Name Description Tech you need to know Tech you will learn Difficulty     ruTorrent mobile interface (II)  ruTorrent is a popular web interface for rTorrent, which is possibly the most used BitTorrent client in linux. Last year we started a new project to write a Flutter based interface and was successful and it's gaining traction on its own. We want to work on that project and include new features. Flutter BitTorrent Medium   support more torrent clients  We'd like to add support for other clients to our ruTorrent mobile interface (which of course will get a new name): Flood and Deluge. Flutter API, Teamwork Medium   CCExtractor's GUI in Flutter  Over the years there's been a few attempts to replace the GUI for our core tool, CCExtractor, but none have been really successful. Using flutter, let's write a modern GUI. Flutter CCExtractor Medium    rTorrent We use jesec/rtorrent. It provides a more modern base with Bazel/CMake and C++ 17 (instead of autotools and C++ 0x). Plus, your works are guaranteed to be incorporated if they match expectations.\n   Name Description Tech you need to know Tech you will learn Difficulty     a modern RPC interface  rTorrent currently uses an antique XMLRPC interface, which is limited in capability, not scalable, hard to use, insecure and low-performance. Community needs a modern RPC interface with full bidirectional, stream processing, incremental data loading and high concurrency capabilities, which allows real-time events for RPC users, reduced serialization/transfer overheads, potentially better security (with authentication and/or TLS), etc. C++ RPC, Event Loop Medium/Hard   asynchronous name resolution UDP tracker name resolution is not asynchronous at the moment, which causes blocking in the main thread and can block (timeout) other ongoing/incoming connections/transfers. c-ares or libwebsockets implementation is preferred, as c-ares is already used by curl, which rTorrent depends on, while libwebsockets may be used by a future WebSockets RPC interface. C, C++ Threading, Event Loop Medium   improve scalability - on start It takes 3 minutes to load 28890 entries from the session directory on start. Only 1 core is used. Deal with this situation, potentially by making the session functions thread safe and spawning more threads for the tasks. C++ Threading Medium   improve scalability rTorrent has a well-defined threading behaviour, which makes it stable and light on resources. There are 3 permanent threads only: main, disk and scgi. However, in the age of Gigabit/10G connections, 3 threads are often not sufficient. Implement a new threading model with better scalability. C++ Threading Hard   scheduling/queuing In some cases, users might want to download a series of torrents one-by-one without having to manually start the next when the previous is completed. Implement a scheduler along with a queue to allow users to limit the number of maximum simultaneous downloads. Enqueue if the user adds a download or decrease the limit. Dequeue when a download is completed or the user increases the limit. Keep the queue state across reboots. C++ Scheduling Medium    New things we're currently interested on    Name Description Tech you need to know Tech you will learn Difficulty     Mouseless for Linux  Mouseless is a nice tool to practice keyboard shortcuts for a few popular apps. Unfortunately it's only available for Mac. We'd like to create an open-source Linux version that can be easily extended. Your choice ?? Unknown   BitTorrent over TLS  BitTorrent protocol is not secure. Its encryption mechanism is outdated and weak. Even for obfuscation, it is ineffective. Nowadays, even an entry-level gateway has the capability to detect and block BitTorrent traffic at little to no risk. The BitTorrent community would benefit from a new standard encryption mechanism that allows strong encryption, forward secrecy and resistance to censorship. Depends Networking, Standardization Hard   The next peer-to-peer protocol  BitTorrent is of course the world's most used peer to peer protocol. It's great, but it was designed before the cloud was ubiquitous and it doesn't make use of the places where you have the most storage or the most bandwidth. Can we design something for the next decade? Depends Peer-to-peer, cloud Unknown   Linux tuning for network throughput  Come up with a system that tunes the linux kernel to maximize network throughput for a number of workloads, such as web server or BitTorrent. We will provide access to a server with a huge pipe (10 Gbit/s, SSD, lots of cores) and your job is to build a tool that maximizes the throughput (and prove it!) Linux Kernel internals, Networking Hard    About us We are a small org, which means that your contribution will have a large impact. It's not going to mean a 0.5% improvement on a big project --- it's going to be more than 10% on a medium size one. If you like challenges and want a chance to shine this is your place.\nWe have we think statistically amazing continuity in the team: Most GSoC students from all the past years are still involved, even if they are no longer eligible as students. They still contribute code, and they mentor both in GSoC and the sister program GCI. As mentors, they also come to the Summer of Code summit which traditionally takes place in October.\nWe have mentors all over the world (North America, Europe, Asia and Australia), so time zones are never a problem. Our main channel of communication is a Slack channel to which everyone is welcome. We expect all accepted students to be available on Slack very often, even if you don't need to talk to your mentor. This will help you ask questions when necessary, and you might be able to help others out as well while working on your project.\nException: If your country (such as Russia) has banned Slack please get in touch in we'll work out a solution with you. We absolutely want you to participate.\nA mailing list is also available for those that prefer email over slack. It's a new mailing list (the old one hasn't been used in a long time) but it's read by everyone involved in GSoC.\nAll our top committers will be mentoring. Many of them are former GSoC students or winners of GCI.\nPerks All accepted students get a programming book immediately after being accepted, with the hope that they read them before the coding starts. We want to see if this increases the quality of the work. So far we have selected these three books (pick one), but we're open to suggestions: Clean Code, Elements of Programming Interviews in Python, Cracking the code interview.\nWe will also provide to all accepted students: - 6 months of access (from the acceptance date) to all courses in educative.io - 12 months of access (from the acceptance date) to backtobackswe, which is a fantastic resource to learn algorithms, prepare for coding interviews, and in general learn fundamentals.\nThe student working on CEA-708 will also receive a copy of the latest CEA-708 specification document.\nAbout what we use This is what we use today. It doesn't mean this is what we want to continue using. Probably not --- we're really open to change. We're just describing the status quo so you know what you are getting into :-)\nThe core tool that names the organization (CCExtractor) is a command-line program written in C (not C++).\nThe current Windows GUI is written in C #, and we have another GUI for Linux that's written with Qt, and a small GUI that's integrated into the main program (C). In we're being honest, nothing is great. Good news for you is that you can start over if you want.\nThe testing tool we use to run regression tests is mainly written in Python, but it also used Javascript, CSS and some shell scripting. The Test suite is written in C#. One of the projects this year is about replacing it.\nThe prototype real time subtitle website is written in NodeJS.\nWe also have a number of support tools that do a number of different things, from downloading subtitles from streaming services to translating them with Google Translate or DeepL. Most of them are written in Python, but since they are small tools that do their job you don't need to worry much about them.\nFor totally new things you can use whatever tool you feel is best for the job.\nAbout sample media and other resources We work with huge files. Not all of them are huge, but many are. We know that many students don't have access to high speed internet. To those students we will ship (as soon as they are selected) a portable hard drive with all our samples. So if your internet connection is not good, don't worry --- as long as you can plug a USB drive to your development computer you can participate with us.\nWe also have a shared Linux development server with lots of storage and a Gigabit uplink. Students get an account on it and they are welcome to use it. There's nothing there except our own work, so it's a trusted environment (for a server that is connected to internet of course).\nThe sample platform also hosts a bunch of samples, both which are small or decently sized.\nSome projects have specific requirements: For example to add support for JokerTV you will need a physical JokerTV device. We will send one to the student that takes this project well before GSoC starts. The LiveTV project requires a subscription to YouTube with LiveTV (whatever it's called this week) and Hulu. We will pay for those. If your project requires some cloud resources (Google Compute Engine, for example), we will pay for that, too.\nIn general, you are not expected to pay for anything (other than your own development computer and internet, of course) related to any project.\nIf you need anything not mentioned (such as a book) let us know. Within reason, we'll help you.\nAbout the projects and getting accepted Qualification: Our selection system is based on several factors. Of course no student ranks in all criteria, so don't worry when you read the list below.\nWork on our core tool: Even if you are going to be working on something totally different. This might seen counter intuitive, but the thing is if you prove you can dig into our (messy) code base, find yourself your way around it, and fix a few bugs, you are just the kind of person we can trust to \u0026quot;figure things out\u0026quot;. GSoC is among other things, a learning experience. No matter what project you decide to work on, there's going to be roadblocks, things you don't know how to do, etc. So we really like it when students embrace those situations.\nQualification tasks specific to the project: The detail page for some projects contains specific qualification tasks that apply to them.\nContributions to existing open source projects: This can be anything. From a good GitHub profile to pull-requests sent to any other existing project, participation in hackathons, Google Code-In, past GSoCs and so on.\nA good proposal: This is the one criteria that is non-negotiable. Your proposal has to be good, period.\nProject popularity: Some ideas just have more competition, so if participating in GSoC is a top priority for you (over working on a specific project), consider applying to one of the \u0026quot;niche\u0026quot; ideas. After all, that's a great way to get your foot in the door :-)\nBest core tool tasks\nWe're added a difficulty level to all our open issues on GitHub. Best thing you can do is head there and see if you are able to fix some of the easy ones and work your way up. We don't expect you to be able to do the hard ones but we'd be impressed if you did :-)\nFor some of the easy ones you don't even need to know C. Just being able to compile CCExtractor and dig around a bit will be enough.\nThe sample platform's issues are tagged with \u0026quot;gsoc-proposal-task\u0026quot;, so you can easily see what you can work on.\nTake home qualification tasks If instead of working on existing code you'd prefer to show us your skills working on something new, you can pick one of these projects.\nCommunity etiquette It goes without saying that everyone in the community has to be polite and respectful, and consider everyone else a member of a team and not a competitor.\nAll developers are part of the team, by the way. Our Slack channel has mentors, code-in participants, other students, or developers and users that are none of the above but they all play some kind of role in CCExtractor's community.\nPart of being respectful is giving consideration to everyone else's time. Most of us have day jobs, and as such are limited in the time we can use to guide you. We'd like to spend it on quality discussions, and not on things that are for example written on this website, things that you can easily retrieve by reading documentation on used libraries or on the software's help screen. Asking this kind of questions in the Slack channel shows little respect for our time. This doesn't mean you can't ask questions, but remember that being a clueless user and a lazy developer are two very different things. If you ask those questions you will probably get an answer as if you were a clueless user (polite no matter what), but if you apply to GSoC you will be considered a lazy developer. Google is your friend ;)\nTell things as you see them. Politely -you're not Linus-, but don't sugar-coat it. We know some parts of our code is poorly written, poorly documented, etc. It stands out, so you will know when you dig in. No one is going to be offended by having that code rewritten or refactored. Peer review applies to everybody's work and is done by everybody.\nCross project proposals Because we use a number of libraries and in fact \u0026quot;are a library\u0026quot; ourselves (meaning other programs can link CCExtractor as a library, or invoke the binary) we interact with other communities and their software. From time to time there's a chance to do something interesting that affects CCExtractor and something else (FFmpeg comes to mind, but also Kodi, VLC, libGPAC, Red Hen, to mention just a few of our friends that typically participate in Summer of Code). So how does this work? As long as the work benefits CCExtractor and it's part of your summer project, we're OK with you spending some time on the other project. For example if you are improving our MP4 support, for which we use libGPAC, and need to fix or improve something on libGPAC you are welcome to do so. If you do, make sure you submit your changes to their maintainers and follow through with their merge process.\nYour proposal You can propose to do any of the following ideas, or you can bring your own. In any case, make sure you run them by us before you actually submit your proposal.\nAt the very least your proposal needs to\n Explain what you want to do, why it is important to you (don't make up a story here — the reason can be that you need it, that you just think it's cool, that you have an itch to work on it, etc), and why it could be important or useful to us. Explain how you intend to accomplish the goal, in enough detail that makes it clear that you have done your homework. For example, “I will modify the CCExtractor binary so that it's able to convert audio to text with perfect accuracy” is the same thing as sending your proposal to the trash. You need to have a plan. Detail the timeline explaining what the expected progress is for each week or every two weeks (pay special attention to the milestones within the GSoC timeline itself, of course) and how we should validate the results. Detail what kind of support you will need from us. For example, if you are going to need test streams, hardware, access to a server, etc, let us know, so we can prepare everything for you as soon as possible. Detail your expected working hours in UTC. We're used to weird working schedules, so don't worry about working in the middle of the night, or weekends instead of other days, etc. Knowing your hours may help us to match you better with a mentor. Mention your planned absences. We don't need you to detail what you will be doing when you are not working of course, but if you are going away for any reason we need to know so we don't think you've abandoned. Link to your GitHub (or any other repository) profile, if you have one, so we can take a look at your previous work. GSoC is a coding program: This means that ideas that are about testing (unless it involves coding something to test our programs ;) ), website design, etc, are out. However, we want to have good documentation: Make sure you have time to write a good technical article explaining your work. Be realistic and honest with the timeline. Consider each week you should work around 30 hours. If your timeline reserves a lot of time for minor things we'll think that you are not going to be working full-time in GSoC. On the other hand if you promise to do things in a lot less than that it seems realistic to us it will seem that you don't really know how much work things take. If you are going to be using 3rd party libraries (that's OK), make sure to validate that their license is compatible with GPLv2 (which is ours). List the libraries in your proposal. Check that they are cross-platform. If you will need to extend those libraries in any way please explain. In this case, your proposal should include time to get that extension submitted to the maintainers (we love to contribute to other projects).  Something else: Mentors often have their fingers in several pies. If you send the same proposal to several orgs everyone will know. So do yourself a favor and don't do that. You can apply to several organizations and that's totally fine, but each organization will want to see that you have put the time to write a great proposal that is focused on them.\nUseful resources A great resource for GSoC.\n","link":"https://ccextractor.org/docs/ideas_page_for_summer_of_code_2021/","title":"Google Summer of Code (GSoC) 2021 ideas page"},{"body":"Welcome to our ideas page. It's great you want to start early. Please join us in our slack channel! (we'll leave as an exercise to you to find it --- it's on our website).\nThis is an \u0026quot;new way of doing things year\u0026quot;. GSoC projects are now supposed to take around 175 hours and we've adapted our ideas to reflect that. If you think any idea is too long or too short please let us know - we still need to fine tune this!\nAs you will see, this year has a lot of Rust. The reason is simple: Security. Our C code base has known (and we suspect, a lot of unknown) security issues caused by the usual memory management in C. Lots of people have touched the code over the years, and it shows.\nThere's also Flutter, which we love, and more.\nWe will provide resources for students --- we'll give access to a high-speed server, all our samples (we'll even ship a portable drive with them anywhere in the world, so don't worry about slow connections) and various other perks.\nYou are welcome to check out the page (actual ideas at the bottom of the page, with each project having it's own separate page as well) and start early in the community bonding process as well as learning a bit about our code ethics and practices. And of course, we'd love you to stay around even if we are not invited to GSoC or if we cannot invite you as a student.\nThe ideas we currently have Important: If you have something else in mind that relates to subtitles and accessibility please get in touch. We prefer that you do something that you are passionate about even if it's something we hadn't considered.\nAfter you check out our ideas please continue reading to the bottom of the page to get information about who we are, how we collaborate, what resources we will provide to you, etc.\nSome tasks descriptions are still vague. We know that. Feel free to get in touch for questions, or just check their page from time to time. We will update the descriptions often.  CCExtractor Rust rewrite    Name Description Tech you need to know Tech you will learn Difficulty     Initial Rust scaffolding Set up the base Rust infrastructure. Build with cargo. FFI. (Some) Rust, Some (C) A lot of Rust + C interoperability. CCExtractor internals Medium   Rewrite 708 decoder in Rust CEA-708 is the American standard for digital subtitles. We have a reasonably good (meaning, easy to understand, and it was written when we knew what we were doing) C base. We'd like to port it to rust. We will provide you with the official technical standards. (Some) Rust, Some (C) Digital subtitles Working with standards. Medium   Rewrite 608 decoder in Rust CEA-608 is the American standard for analog subtitles. It also carries things like emergency alerts, basic TV guide, and content classification. We have a complete implementation in C that works OK (possibly with some bugs) but that is not really very well organized. We'd like to port it to rust. We will provide you with the official technical standards. (Some) Rust, Some (C) Analog subtitles, XDS Working with standards. Medium   Rewrite the OCR subsystem in Rust. We use tesseract to OCR bitmap based subtitles. It's a great library, but because its input is a bitmap that is preprocessed (so provide a reasonable input) there's lots of places in which there can be buffer overruns, underruns… many of the problems that Rust shines on are evidenced here. So a Rust rewrite of this would be a big win. OCR Rust FFI Tesseract Imaging OCR Medium    Core subtitle tool (CCExtractor itself)    Name Description Tech you need to know Tech you will learn Difficulty     Add support for DTMB countries DTMB is the standard for Chinese TV, also implemented by countries such as Cuba. What kind of student is ideal for this task? One with lots of analytic skills and patience. If you are one of those, don't disregard this task just because you don't speak (or maybe, even care) about Chinese. The experience on dealing with this will be extremely valuable in the future.We will use part of the organization funds to buy standard documents you might need, a capture device, and in general, anything required to make your life easier. C DTMB Video standards Hardware Research Unknown   Add Japanese support Captions are used by people all over the world on a regular basis. Most of us are familiar with regular horizontal captions at the bottom of the screen, but did you know that in Japan a common position for captions is vertically on the right or left side of the screen? Come learn more about what Japanese audiences need out of captions as well as how captioning standard likes IMSC and WebVTT support these features. Japanese (or be good with foreign languages) Depends Suspected hard    Artificial Intelligence and clever algorithms    Name Description Tech you need to know Tech you will learn Difficulty     Poor man's Rekognition (III) Amazon Rekognition is a (paid) service that is able to identify celebrity faces in a picture. Last year we did some work towards creating a free alternative. This year we want to improve on the past work. Your choice AI Computer vision Unknown   Poor man's Textract Amazon Textract a (paid) service that \u0026quot;automatically extracts text and data from scanned documents. Amazon Textract goes beyond simple optical character recognition (OCR) to also identify the contents of fields in forms and information stored in tables\u0026quot;. We want to build a free alternative that provides an output of similar quality. Your choice AI Computer vision OCR Unknown    Support tools we and other orgs use as part of their development process    Name Description Tech you need to know Tech you will learn Difficulty     The sample platform (/ continuous integration) project The sample platform is a good way to help new contributors to check if their code doesn't introduce any regressions. It's pretty stable, but is often hard to interpret for new contributors, and still pretty slow if the queue builds up. We want to move the platform towards GCP (Google Cloud Platform) and run the tests on disposable instances rather than through KVM. This project is guaranteed to be selected if the proposal is good. Git Python Google Cloud API's GitHub Actions GitHub API's Continuous Integration (CI) Automated deployments GitHub integration Medium/Hard    Multimedia (misc)    Name Description Tech you need to know Tech you will learn Difficulty     Improve our reference channel for Roku  Roku is currently the most common media streamer. It's cheap and neutral (it's not in any \u0026quot;fight\u0026quot;). Unfortunately, there aren't any good open source channels, so if you want to start your own you have to start from scratch. Last year we started a new channel everyone can use as a starting point. We'd like to continue working on it, adding new features. We will send a free Roku to our student for development. None Brightscript Roku Video Streaming Medium    Flutter    Name Description Tech you need to know Tech you will learn Difficulty     ruTorrent mobile interface (II)  ruTorrent is a popular web interface for rTorrent, which is possibly the most used BitTorrent client in linux. Last year we started a new project to write a Flutter based interface and was successful and it's gaining traction on its own. We want to work on that project and include new features. Flutter BitTorrent Medium   support more torrent clients  We'd like to add support for other clients to our ruTorrent mobile interface (which of course will get a new name): Flood and Deluge. Flutter API, Teamwork Medium   CCExtractor's GUI in Flutter  Over the years there's been a few attempts to replace the GUI for our core tool, CCExtractor, but none have been really successful. Using flutter, let's write a modern GUI. Flutter CCExtractor Medium    rTorrent We use jesec/rtorrent. It provides a more modern base with Bazel/CMake and C++ 17 (instead of autotools and C++ 0x). Plus, your works are guaranteed to be incorporated if they match expectations.\n   Name Description Tech you need to know Tech you will learn Difficulty     a modern RPC interface  rTorrent currently uses an antique XMLRPC interface, which is limited in capability, not scalable, hard to use, insecure and low-performance. Community needs a modern RPC interface with full bidirectional, stream processing, incremental data loading and high concurrency capabilities, which allows real-time events for RPC users, reduced serialization/transfer overheads, potentially better security (with authentication and/or TLS), etc. C++ RPC, Event Loop Medium/Hard   asynchronous name resolution UDP tracker name resolution is not asynchronous at the moment, which causes blocking in the main thread and can block (timeout) other ongoing/incoming connections/transfers. c-ares or libwebsockets implementation is preferred, as c-ares is already used by curl, which rTorrent depends on, while libwebsockets may be used by a future WebSockets RPC interface. C, C++ Threading, Event Loop Medium   improve scalability - on start It takes 3 minutes to load 28890 entries from the session directory on start. Only 1 core is used. Deal with this situation, potentially by making the session functions thread safe and spawning more threads for the tasks. C++ Threading Medium   improve scalability rTorrent has a well-defined threading behaviour, which makes it stable and light on resources. There are 3 permanent threads only: main, disk and scgi. However, in the age of Gigabit/10G connections, 3 threads are often not sufficient. Implement a new threading model with better scalability. C++ Threading Hard   scheduling/queuing In some cases, users might want to download a series of torrents one-by-one without having to manually start the next when the previous is completed. Implement a scheduler along with a queue to allow users to limit the number of maximum simultaneous downloads. Enqueue if the user adds a download or decrease the limit. Dequeue when a download is completed or the user increases the limit. Keep the queue state across reboots. C++ Scheduling Medium    New things we're currently interested on    Name Description Tech you need to know Tech you will learn Difficulty     Mouseless for Linux  Mouseless is a nice tool to practice keyboard shortcuts for a few popular apps. Unfortunately it's only available for Mac. We'd like to create an open-source Linux version that can be easily extended. Your choice ?? Unknown   BitTorrent over TLS  BitTorrent protocol is not secure. Its encryption mechanism is outdated and weak. Even for obfuscation, it is ineffective. Nowadays, even an entry-level gateway has the capability to detect and block BitTorrent traffic at little to no risk. The BitTorrent community would benefit from a new standard encryption mechanism that allows strong encryption, forward secrecy and resistance to censorship. Depends Networking, Standardization Hard   The next peer-to-peer protocol  BitTorrent is of course the world's most used peer to peer protocol. It's great, but it was designed before the cloud was ubiquitous and it doesn't make use of the places where you have the most storage or the most bandwidth. Can we design something for the next decade? Depends Peer-to-peer, cloud Unknown   Linux tuning for network throughput  Come up with a system that tunes the linux kernel to maximize network throughput for a number of workloads, such as web server or BitTorrent. We will provide access to a server with a huge pipe (10 Gbit/s, SSD, lots of cores) and your job is to build a tool that maximizes the throughput (and prove it!) Linux Kernel internals, Networking Hard    About us We are a small org, which means that your contribution will have a large impact. It's not going to mean a 0.5% improvement on a big project --- it's going to be more than 10% on a medium size one. If you like challenges and want a chance to shine this is your place.\nWe have we think statistically amazing continuity in the team: Most GSoC students from all the past years are still involved, even if they are no longer eligible as students. They still contribute code, and they mentor both in GSoC and the sister program GCI. As mentors, they also come to the Summer of Code summit which traditionally takes place in October.\nWe have mentors all over the world (North America, Europe, Asia and Australia), so time zones are never a problem. Our main channel of communication is a Slack channel to which everyone is welcome. We expect all accepted students to be available on Slack very often, even if you don't need to talk to your mentor. This will help you ask questions when necessary, and you might be able to help others out as well while working on your project.\nException: If your country (such as Russia) has banned Slack please get in touch in we'll work out a solution with you. We absolutely want you to participate.\nA mailing list is also available for those that prefer email over slack. It's a new mailing list (the old one hasn't been used in a long time) but it's read by everyone involved in GSoC.\nAll our top committers will be mentoring. Many of them are former GSoC students or winners of GCI.\nPerks All accepted students get a programming book immediately after being accepted, with the hope that they read them before the coding starts. We want to see if this increases the quality of the work. So far we have selected these three books (pick one), but we're open to suggestions: Clean Code, Elements of Programming Interviews in Python, Cracking the code interview.\nWe will also provide to all accepted students: - 6 months of access (from the acceptance date) to all courses in educative.io - 12 months of access (from the acceptance date) to backtobackswe, which is a fantastic resource to learn algorithms, prepare for coding interviews, and in general learn fundamentals.\nThe student working on CEA-708 will also receive a copy of the latest CEA-708 specification document.\nAbout what we use This is what we use today. It doesn't mean this is what we want to continue using. Probably not --- we're really open to change. We're just describing the status quo so you know what you are getting into :-)\nThe core tool that names the organization (CCExtractor) is a command-line program written in C (not C++).\nThe current Windows GUI is written in C #, and we have another GUI for Linux that's written with Qt, and a small GUI that's integrated into the main program (C). In we're being honest, nothing is great. Good news for you is that you can start over if you want.\nThe testing tool we use to run regression tests is mainly written in Python, but it also used Javascript, CSS and some shell scripting. The Test suite is written in C#. One of the projects this year is about replacing it.\nThe prototype real time subtitle website is written in NodeJS.\nWe also have a number of support tools that do a number of different things, from downloading subtitles from streaming services to translating them with Google Translate or DeepL. Most of them are written in Python, but since they are small tools that do their job you don't need to worry much about them.\nFor totally new things you can use whatever tool you feel is best for the job.\nAbout sample media and other resources We work with huge files. Not all of them are huge, but many are. We know that many students don't have access to high speed internet. To those students we will ship (as soon as they are selected) a portable hard drive with all our samples. So if your internet connection is not good, don't worry --- as long as you can plug a USB drive to your development computer you can participate with us.\nWe also have a shared Linux development server with lots of storage and a Gigabit uplink. Students get an account on it and they are welcome to use it. There's nothing there except our own work, so it's a trusted environment (for a server that is connected to internet of course).\nThe sample platform also hosts a bunch of samples, both which are small or decently sized.\nSome projects have specific requirements: For example to add support for JokerTV you will need a physical JokerTV device. We will send one to the student that takes this project well before GSoC starts. The LiveTV project requires a subscription to YouTube with LiveTV (whatever it's called this week) and Hulu. We will pay for those. If your project requires some cloud resources (Google Compute Engine, for example), we will pay for that, too.\nIn general, you are not expected to pay for anything (other than your own development computer and internet, of course) related to any project.\nIf you need anything not mentioned (such as a book) let us know. Within reason, we'll help you.\nAbout the projects and getting accepted Qualification: Our selection system is based on several factors. Of course no student ranks in all criteria, so don't worry when you read the list below.\nWork on our core tool: Even if you are going to be working on something totally different. This might seen counter intuitive, but the thing is if you prove you can dig into our (messy) code base, find yourself your way around it, and fix a few bugs, you are just the kind of person we can trust to \u0026quot;figure things out\u0026quot;. GSoC is among other things, a learning experience. No matter what project you decide to work on, there's going to be roadblocks, things you don't know how to do, etc. So we really like it when students embrace those situations.\nQualification tasks specific to the project: The detail page for some projects contains specific qualification tasks that apply to them.\nContributions to existing open source projects: This can be anything. From a good GitHub profile to pull-requests sent to any other existing project, participation in hackathons, Google Code-In, past GSoCs and so on.\nA good proposal: This is the one criteria that is non-negotiable. Your proposal has to be good, period.\nProject popularity: Some ideas just have more competition, so if participating in GSoC is a top priority for you (over working on a specific project), consider applying to one of the \u0026quot;niche\u0026quot; ideas. After all, that's a great way to get your foot in the door :-)\nBest core tool tasks\nWe're added a difficulty level to all our open issues on GitHub. Best thing you can do is head there and see if you are able to fix some of the easy ones and work your way up. We don't expect you to be able to do the hard ones but we'd be impressed if you did :-)\nFor some of the easy ones you don't even need to know C. Just being able to compile CCExtractor and dig around a bit will be enough.\nThe sample platform's issues are tagged with \u0026quot;gsoc-proposal-task\u0026quot;, so you can easily see what you can work on.\nTake home qualification tasks If instead of working on existing code you'd prefer to show us your skills working on something new, you can pick one of these projects.\nCommunity etiquette It goes without saying that everyone in the community has to be polite and respectful, and consider everyone else a member of a team and not a competitor.\nAll developers are part of the team, by the way. Our Slack channel has mentors, code-in participants, other students, or developers and users that are none of the above but they all play some kind of role in CCExtractor's community.\nPart of being respectful is giving consideration to everyone else's time. Most of us have day jobs, and as such are limited in the time we can use to guide you. We'd like to spend it on quality discussions, and not on things that are for example written on this website, things that you can easily retrieve by reading documentation on used libraries or on the software's help screen. Asking this kind of questions in the Slack channel shows little respect for our time. This doesn't mean you can't ask questions, but remember that being a clueless user and a lazy developer are two very different things. If you ask those questions you will probably get an answer as if you were a clueless user (polite no matter what), but if you apply to GSoC you will be considered a lazy developer. Google is your friend ;)\nTell things as you see them. Politely -you're not Linus-, but don't sugar-coat it. We know some parts of our code is poorly written, poorly documented, etc. It stands out, so you will know when you dig in. No one is going to be offended by having that code rewritten or refactored. Peer review applies to everybody's work and is done by everybody.\nCross project proposals Because we use a number of libraries and in fact \u0026quot;are a library\u0026quot; ourselves (meaning other programs can link CCExtractor as a library, or invoke the binary) we interact with other communities and their software. From time to time there's a chance to do something interesting that affects CCExtractor and something else (FFmpeg comes to mind, but also Kodi, VLC, libGPAC, Red Hen, to mention just a few of our friends that typically participate in Summer of Code). So how does this work? As long as the work benefits CCExtractor and it's part of your summer project, we're OK with you spending some time on the other project. For example if you are improving our MP4 support, for which we use libGPAC, and need to fix or improve something on libGPAC you are welcome to do so. If you do, make sure you submit your changes to their maintainers and follow through with their merge process.\nYour proposal You can propose to do any of the following ideas, or you can bring your own. In any case, make sure you run them by us before you actually submit your proposal.\nAt the very least your proposal needs to\n Explain what you do want to do, why it is important to you (don't make up a story here — the reason can be that you need it, that you just think it's cool, that you have an itch to work on it, etc), and why it could be important or useful to us. Explain how you intend to accomplish the goal, in enough detail that makes it clear that you have done your homework. For example, “I will modify the CCExtractor binary so that it's able to convert audio to text with perfect accuracy” is the same thing as sending your proposal to the trash. You need to have a plan. Detail the timeline explaining what the expected progress is for each week or every two weeks (pay special attention to the milestones within the GSoC timeline itself, of course) and how we should validate the results. Detail what kind of support you will need from us. For example, if you are going to need test streams, hardware, access to a server, etc, let us know, so we can prepare everything for you as soon as possible. Detail your expected working hours in UTC. We're used to weird working schedules, so don't worry about working in the middle of the night, or weekends instead of other days, etc. Knowing your hours may help us to match you better with a mentor. Mention your planned absences. We don't need you to detail what you will be doing when you are not working of course, but if you are going away for any reason we need to know so we don't think you've abandoned. Link to your GitHub (or any other repository) profile, if you have one, so we can take a look at your previous work. GSoC is a coding program: This means that ideas that are about testing (unless it involves coding something to test our programs ;) ), website design, etc, are out. However, we want to have good documentation: Make sure you have time to write a good technical article explaining your work. Be realistic and honest with the timeline. Consider each week you should work around 30 hours. If your timeline reserves a lot of time for minor things we'll think that you are not going to be working full-time in GSoC. On the other hand if you promise to do things in a lot less than that it seems realistic to us it will seem that you don't really know how much work things take. If you are going to be using 3rd party libraries (that's OK), make sure to validate that their license is compatible with GPLv2 (which is ours). List the libraries in your proposal. Check that they are cross-platform. If you will need to extend those libraries in any way please explain. In this case, your proposal should include time to get that extension submitted to the maintainers (we love to contribute to other projects).  Something else: Mentors often have their fingers in several pies. If you send the same proposal to several orgs everyone will know. So do yourself a favor and don't do that. You can apply to several organizations and that's totally fine, but each organization will want to see that you have put the time to write a great proposal that is focused on them.\nUseful resources A great resource for GSoC.\n","link":"https://ccextractor.org/public/gsoc/ideas_page_for_summer_of_code_2021/","title":"Google Summer of Code (GSoC) 2021 ideas page"},{"body":"A tool that analyzes video files and produces independent subtitle files from the closed captions data. CCExtractor is portable, small, and very fast. It works in Linux, Windows, and OSX.\nWhat kind of closed captions does CCExtractor support? Almost all of them:\n American TV captions (CEA-608 is well supported, and CEA-708 is starting to look good) European Teletext European DVB Brazilian ISBD DVD MXF  Missing:\n DTMB (Chinese)  How easy is it to use CCExtractor? Very. Just tell it what file to process and it does everything for you.\nCCExtractor integration with other tools It is possible to integrate CCExtractor in a larger process. A couple of tools already call CCExtractor as part their video process - this way they get subtitle support for free. Starting in 0.52, CCExtractor is very front-end friendly. Front-ends can easily get real-time status information. The GUI source code is provided and can be used for reference. Any tool, commercial or not, is specifically allowed to use CCExtractor for any use the authors seem fit. So if your favourite video tools still lacks captioning tool, feel free to send the authors here.\nYou can also use CCExtractor as a library (as opposed to just running the binary), or take parts of the code. Keep in mind however that CCExtractor is GPLv2 so if you take parts or all of the source code your code must also be GPLv2.\nWhat's the point of generating separate files for subtitles, if they are already in the source file? There are several reasons to have subtitles separated from the video file, including:\n Closed captions never survive MPEG processing. If you take a MPEG file and encode it to any format (such as divx), your result file will not have closed captions. This means that if you want to keep the subtitles, you need to keep the original file. This is hardly practical if you are archiving HDTV shows for example. Subtitles files are small - so small (around 250 Kb for a movie) that you can quickly download them, or email them, etc, in case you have a recording without subtitles. Subtitles files are indexable: You can have a database with all your subtitles if you want (there are many available), so you can search the dialogs. Subtitles files are a de-facto standard: Almost every player can use them. In fact, many setbox players accept subtitles files in .srt format - so you can have subtitles in your .mp4/.mkv/.avi./etc movies and not just in your original DVDs. Closed captions are stored in many different formats by capture cards. Upgrading to a new card, if it comes with a new player, may mean that you can't use your previously recorded closed captions, even if the audio/video are fine. Closed captions require a closed caption decoder. All US TV have one (it's a legal requirement), but no European TV does, since there are not closed captions in Europe (teletext and DVB subtitles are used instead). Basically this means that if you buy a DVD in the US which has closed captions but no DVD subtitles, you are out of luck. This is a problem with many (most) old TV shows DVDs, which only come with closed captions. DVD producers don't bother doing DVD subs, since it's another way to segment the market, same as with DVD regions.  How I do use subtitles once they are in a separate file? CCExtractor generates files in the two most common formats: .srt (SubRip) and .smi (which is a Microsoft standard). Most players support at least .srt natively. You just need to name the .srt file as the file you want to play it with, for example sample.avi and sample.srt.\nOther formats just as .txt (transcripts) are supported as well.\nWhat kind of files can I extract closed captions from? CCExtractor currently handles:\n Most HDTV captures (where you save the Transport Stream). Captures where captions are recorded in bttv format. The number of cards that use this card is huge. My test samples came from a Hauppage PVR-250. You can check the complete list here. DVR-MS (microsoft digital video recording). Tivo files ReplayTV files Dish Network files DVDs  Usually, if you record a TV show with your capture card and CCExtractor produces the expected result, it will work for your all recordings. If it doesn't, which means that your card uses a format CCExtractor can't handle, please contact me and we'll try to make it work.\nCan I edit the subtitles? .srt files are just text files, with time information (when subtitles are supposed to be shown and for how long) and some basic formatting (use italics, bold, etc). So you can edit them with any text editor. If you need to do serious editing (such as adjusting timing), you can use subtitle editing tools - there are many available.\nCan CCExtractor generate other subtitles formats? At this time, CCExtractor can generate .srt, .smi and raw and bin files.\nWhat's a raw file? A raw file is a file that contains an exact dump of the closed captions bytes, without any processing. This lets you use any tool of your choice to process the data. For example, McPoodle's excellent tools can generate subtitles files in several formats, adjust timing, etc.\nWhat's a bin file? How is it different from a raw file? A bin file contains a dump of the closed captions bytes (same as a raw file) but it also includes timing information. This is a format that we made up for CCExtractor, i.e. it's not any kind of industry standard. However, it's the most useful (to us) for debugging purposes, so if you need to send us a sample please use this format. Also, a bin format can hold several CC streams (several languages, even from both analog and digital). A raw file cannot.\nHow long does it take to process a MPEG file? Obviously, it depends on the computer and the length of the file. In my (really old) computer it took around 90 seconds for a 45 minutes show in HDTV, with CPU usage around 3% (I/O operations are what's holding it back). Currently (2018) we're processing as many as 20 TV channels in real time using a single computer with a i5 CPU.\nWhat platforms does CCExtractor work on? CCExtractor is developed and tested in Windows and Linux. It is also known to compile and run fine in OSX (a build script is included in the source .zip).\nWhere can I download it? The source code is hosted on github. Check out our download page for links to everything. Old versions were hosted on sourceforge. We're keeping those there for statistical purposes. This is the old download page and this is the old project summary page.\nHow I can contact the author? There's no longer one author. Carlos is still the official maintainer but there's a lot of people contributing to the project. Best thing is to check out our support page.\nHow do I use this tool (parameters, etc)? Run it without parameters and you will get a help screen. Basically, you just give it the input file name, like this:\nccextractor the.sopranos.ts\nAs for the lack of documentation: There is no lack of documentation! It's just included in the program itself. Just run it without parameters and you will get complete details.\nHow can I contribute to this project? There are several ways:\n If you are a developer, since the source code is available, you can fix things or add features yourself and submit a patch. If you are an user and find any bug, or have good suggestions, let me know. If you are doing your own recordings and have any particular one that CCExtractor can't process correctly, I'd definitely like to take a look at it and try to fix it. If you really hate that there is not a lot of documentation, you can write it yourself. I'll answer any question you might have.  Does CCExtractor use code from other projects? Yes. Lots of code came originally from McPoodle's tools (even though it was ported from Perl to C). We've also taken code from MythTV (which in turn took some from other places) and FFmpeg. The teletext code is 95% Petr Kutalek's and was integrated with permission.\nA good thing about Open Source is that you don't need to reinvent the wheel unless you want to (or unless you think you can come up with a 'rounder' wheel).\n","link":"https://ccextractor.org/public/general/whatsccextractor/","title":"What's CCExtractor"},{"body":"Anshul Maheshwari at GSOC 15\n","link":"https://ccextractor.org/playground/anshul/","title":""},{"body":"PlayGround ","link":"https://ccextractor.org/playground/playground/","title":""},{"body":"Slack Slack it's a very convenient tool for team work. It comes with a number of useful features, but the one we should be using most it's the online chat. It saves logs which can be read at any time (so you don't have to be online all the time not to miss things), desktop notifications and Android/iOS apps. It can also be integrated with a number of tools such as GitHub (to notify in channel when something has been pushed).\nEveryone in the People page have been invited.\nhttps://rhccgsoc15.slack.com\nAnd you can request an invite by sending filling out this form here\n","link":"https://ccextractor.org/private/gsoc/slack_a_communications_tools/","title":""},{"body":"Preliminary task page This year we are try new things and see how it works out.\nOn top of design and coding small tools and minor features, we're going to have two more tracks: Google Assistant and IA.\nGoogle Assistant The Google Assistant one is perfect because anyone can create a reasonably useful action in 2-3 hours, without any coding, so it would fall into product design rather than coding. But then, it's easy to use a well thought design to extend it with coding, cloud functions and so on. We happen to have some Google Cloud credits lying around in case we do something so popular it needs more than the free tier, so everything works out.\nIA The second thing is IA. In theory this is way beyond the scope and knowledge you would expect from high schoolers, but things have changed a lot and with Keras (a high level API that sits on top of Tensorflow) and the excellent resources are there it's possible to build small things, even if the math behind it is not completely understood, in two days or so.\nRecommendations __(If you are a mentor and you feel strongly about something follow your gut, if you are in doubt if something is OK or not then probably it's not but feel free to ask admins)__\nTasks from both 2016 or 2017 that no one touched: Let's leave them out, we want good tasks only. Tasks from 2017 that were worked on but no one finished or we couldn't use: Add as backup tasks. Tasks that require access to non-public systems, if any: Leave for the very last days, when it's already clear who are going to become permanent team members.\n1) Install Koala to add project ideas. https://projects.coala.io/#/projects\n","link":"https://ccextractor.org/public/codein/google_code-in_2018_task_list_sample/","title":""},{"body":"__Google Code-In 2017__\nWe're happy to see you here :-) (come here often, we will update this page until the end of Code-In).\nWe've been accepted to Code-In 2017, along another 24 amazing organizations. Last year was fantastic by all possibly metrics and we're really excited about being invited again.\nMost likely you came here so see what kind of tasks we have. Well, we cannot show you the actual list as they will be published in Code-in's website when the time comes, and it's important that no one has an unfair advantage, but we can tell you this:\n- We value all categories. We will have tasks for developers (of course), web designers (our website could use a new theme, couldn't it), graphic designers (for example, a new logo is in order), documentation writers (tutorials are highly useful), project organizers (yes, getting everyone on the same page is not always trivial) and more. To sum it up, if you want to work, we will have tasks for you no matter what your interests or skills are. - If you are looking for sample code tasks, check the currently open issues at GitHub. Most or all of them will become one or more tasks (depending on difficulty or amount of work required). This is probably true for most organizations so we aren't disclosing a big secret here. - We have a slack channel in which everyone is welcome. You will find members of the core team, past Summer of Code students and mentors, past Code-In students including the winners, etc. Feel free to come talk to us. You can invite yourself from our support page.\nA video of our two winners from Code-In 2016 talking at Google's offices in San Francisco about what they did:\n{{ youtube\u0026gt;6Ti1X1peqMA }} Do you want to be one of the two students that visit California next year?\n__Useful resources__\n(come here often, we will update as new resources are added).\nPlayground repository in GitHub Use it to submit beginner tasks that use GitHub.\nPlayground wiki page Use it to learn the basics of dokuwiki and to submit documentation tasks.\nDesigners welcome. What to expect if you want to participate in Code-in as a designer.\n__** Tags **__ As you probably know, tasks in Code-in have tags. We will try to have tags consistently so you that you easily find new tasks in areas that interest you. This list will be updated often, as we add new tasks. The following tasks are official as of now, meaning that tasks related to the following topics will have a correct tag for you to find them:\nDVB: DVB is the subtitle format used in most of Europe these days for digital TV. It's bitmap based, which means that instead of the subtitles being \u0026quot;text\u0026quot; (as in a string of characters) they are an image. This has the advantage of being more powerful (they are not limited by a character set, for example) but the disadvantage that in order to get the text we need to use a OCR (optical recognition) library. In general, our DVB support is decent, thanks a lot of the work by last year winners in code-in and previous Summer of Code students, but it's still not perfect. There are a few corner cases and some weird crashes.\n708: CEA-708 (previously called EIA-708) is the subtitle format in digital TV in North America and a few other countries. It's widely adopted now, even though due to legal regulations the old analog format (CEA-608) is still in use. We do support 708, but implementation is not yet perfect. There are a number of tasks about correcting this. All of them are high value and classified as hard.\nKorean: If you're from Europe or America you're probably surprised that we want to support Korean. Well, it's not really about Korean, but rather about all languages, and Korean is one of the hard cases for which we have some samples that aren't working or aren't working perfectly. Possibly fixing all the issues with Korean means fixing most of the issues with everything else, too. So why to give it a try?\nBug: Quite self explaining. These are non-trivial (not necessarily hard, but not immediately obvious or they would have been fixed) issues reported in GitHub.\nCI: We have our own custom Continuous Integration (CI) tool that helps us ensure that we don't break things when we add new code. It's a nice tool that tests changes against our video repository. As everything else, it's useful but not perfect, and we want to improve it.\nHardtask: High risk, high reward tasks. They are likely to take time and patience, however successfully completing these tasks give you a lots of points for the ultimate prize. By the way, we may say that a task is hard but we can be mistaken in our estimation, so don't take our word for it. Check it out, and decide for yourself.\nFeature: Tasks with this tag are about implement something new, so usually they are also classified as hard.\n__** Winning strategies **__ Definitely reading documents like this one up to the end is a good start. If you've read Code-in rules you have probably figured out that, unless you are a rock star with lots of free time, the safest best is to pick one organization and focus on their tasks. This is because each organization gets to pick exactly two winners and whatever work you do for one organization doesn't count for any other. So spending your time in two orgs doesn't multiply your chances - it reduces them. Blatant advertisement: Because each org chooses two winners regardless of the organization popularity, focusing on smaller orgs (like ours) also increases your chances of becoming a winner. Whatever organization your choose, becoming a winner requires two things: a) Being in the top ten by number of tasks done for that organization, and b) Being chosen by the organization as a winner. We cannot speak for other organizations, but we select our winners based on task value, not task count. For example, doing all the tasks from one of the big \u0026quot;task groups\u0026quot; (you can figure what are those by checking our tags) is very high value. Fixing a lot of bugs from our github issue tracker is also high value. Of course, those hard tasks have a gamble component, as it's possible you spend a lot of time of them but are unable to completely solve them. Another thing that gives big points is collaboration with other developers. This includes other GCI participants. Everyone working on CCExtractor is part of the team, and we compete among each other for motivational purposes, to produce better code that benefits the project in the long run. GCI runs for a few weeks, but we're open all year round. So consider the GCI prizes a perk that comes with being part of an open source community rather than the final goal.\n","link":"https://ccextractor.org/public/codein/welcome_2017/","title":""},{"body":"If you like CCExtractor but can't submit code patches, or video samples, you can contribute a bit by inviting the developers to a beer which is just as fine as all other kinds of support.\nDonate via sourceforge\n","link":"https://ccextractor.org/public/general/http/sourceforge.net_donate_index.php/","title":""},{"body":"Building Tesseract in Windows Warning - the development of the current version of Tesseract and cppan is very active, and this tutorial may be obsolete. This documentation is working at 21.12.2016\nTesseract is an optical character recognition engine for various operating systems. This library is currently used in CCExtractor. At the moment, the alpha version 4.0.0 is available from current master https://github.com/tesseract-ocr/tesseract\nHistorically, build it for Windows is complex and unclear. Now in projects with tesseract is advised to use cppan (https://github.com/cppan/cppan) that can be used in CMake projects and automatically downloads all dependencies. This program is used for the compilation of the current master of tesseract (because of the dependencies), too.\nYou must install Git, CMake, cppan and put in to PATH variable https://github.com/tesseract-ocr/tesseract/wiki/Compiling#windows And it is recommended to install Visual Studio 2015\nOpen cmd.exe (I think better as administrator) and run git clone https://github.com/tesseract-ocr/tesseract tesseract cd tesseract cppan --self-upgrade cppan mkdir build \u0026amp;\u0026amp; cd build cmake .. First problem - process can hangs at: -- Performing 71 checks using 4 thread(s) -- This process may take up to 5 minutes depending on your hardware Follow this hack - https://github.com/tesseract-ocr/tesseract/issues/464#issuecomment-264166445\nTry to build it: cmake --build . --config Release You can get errors: {{ https://cloud.githubusercontent.com/assets/5406399/21389984/7e4508ee-c795-11e6-85ef-67489154fa24.png }}\nThis problem is related to the bad files from libtiff.\nHow to fix it - during the commands you have new files at C:/Users/user/.cppan. In folder .cppan/storage/lnk in one of folders you can find tiff-4.0.7.sln, try to open it in Visual Studio and compile\n{{ https://cloud.githubusercontent.com/assets/5406399/21390188/9dffcdee-c796-11e6-8c67-02f541d85ade.png }}\nOpen the file tif_config.h and edit 189 line \n define SIZEOF_UNSIGNED_LONG 4  1. define TIFF\\_UINT64\\_T unsigned long int Build it again. All should be OK.\nTry to run it in console again: cmake --build . --config Release\nAll should be OK {{ https://cloud.githubusercontent.com/assets/5406399/21390504/54b285e4-c798-11e6-9c74-f70a9a1d8e12.png }}\nNow you have deps dll (in tesseract/build/bin/Release), tesseract lib (in tesseract/build/Release). Deps libs you can find in C:\\Users\\user\\.cppan\\storage\\lib\\511d09b6\\Release (instead of 511d09b6 you can have other value)\nYou can also build debug version\ncmake --build . --config Debug\nIf you want to update Tesseract in ccextractor.sln Note - if you just add a built libraries to ccextractor.sln without updating ccextractor OCR code, there may be errors due to legacy code.\nOpen tesseract/build/tesseract.sln and explore it. To find out where the header files and .lib files, open Properties of \u0026quot;tesseract\u0026quot; project. You must look at C/C++-\u0026gt;General-\u0026gt;Additional Include Directories and Linker-\u0026gt;Input-\u0026gt;Additional Dependencies. DLL files are in tesseract/build/bin folder. Copy all files in ccextractor\\windows\\libs and update settings in ccextractor\\windows\\ccextractor.sln\n{{ https://cloud.githubusercontent.com/assets/5406399/21391982/e7f4783e-c79e-11e6-8ca6-58e772a6521c.png }}\n","link":"https://ccextractor.org/public/general/tess_build/","title":""},{"body":"Using Vagrant What is Vagrant? Vagrant provides easy to configure, reproducible, and portable work environments built on top of industry-standard technology and controlled by a single consistent workflow to help maximize the productivity and flexibility of you and your team. Vagrant will isolate dependencies and their configuration within a single disposable, consistent environment, without sacrificing any of the tools you are used to working with (editors, browsers, debuggers, etc.). Once you or someone else creates a single Vagrantfile, you just need to %%vagrant up%% and everything is installed and configured for you to work. You can read more about the advantages of Vagrant at https://www.vagrantup.com/docs/why-vagrant/\nInstallation  Install vagrant for your OS https://www.vagrantup.com/downloads.html Install VirtualBox for your OS https://www.virtualbox.org/wiki/Download_Old_Builds Warning: Install VirtualBox 5.0 (Newer versions are not supported yet in vagrant). Version VirtualBox 5.0.30 at the top will be OK  vagrant up Download repository of CCExtractor from GitHub https://github.com/CCExtractor/ccextractor (Or your fork of this repo)\nThe repository contains a file Vagrantfile that looks like this\nVagrant.configure(2) do |config| config.vm.box = \u0026quot;ubuntu/xenial64\u0026quot; # Uncomment this line if you want to sync other folders # config.vm.synced_folder \u0026quot;/home/user/video\u0026quot;, \u0026quot;/video\u0026quot; config.vm.provision \u0026quot;shell\u0026quot;, inline: \u0026lt;\u0026lt;-SHELL sudo apt-get install -y gcc sudo apt-get install -y libcurl4-gnutls-dev sudo apt-get install -y tesseract-ocr sudo apt-get install -y tesseract-ocr-dev sudo apt-get install -y libleptonica-dev SHELL end If you have not Vagrantfile, simply create it in project folder and copy and paste in Vagrantfile all of the code from above.\nHere it is clear that the system of the environment (or box, or virtual machine) is Ubuntu 16.04. After 'vagrant up' vagrant installs additional libraries in environment (not on host system!) for compiling CCExtractor.\nTo start the environment, go to the folder with the project and run: vagrant up At first time it may take a while to create virtual machine and install dependencies (about a minute or more), but in the next launches it will take place much faster. This command launch the virtual machine. For stop the virtual machine run: vagrant halt\nvagrant ssh To connect to the environment (environment must be launched), run in project folder vagrant ssh\nIf you want to return to your computer terminal, run logout\nBy default, the project folder is synchronized with environment (that is available in your computer, and in a virtual machine). The project folder is located in /vagrant.\nLets build the project\ncd /vagrant cd linux ./build Now virtual environment and computer both have built CCExtractor in folder linux. Even if your computer does not have curl, tesseract, leptonica, gcc. Run in environment's linux folder ./ccextractor and you will see a description of the program. Run ./ccextractor [arguments] to get subtitles.\nSynced folders Synced folders - those folders that are both available and in the environment, and on the host computer. Initially synchronized folder is only the project folder (where is Vagrantfile exists). You can synchronize more folders - just uncomment this line in Vagrantfile (delete the character '#' at the beginning of the line)\nconfig.vm.synced_folder \u0026quot;/home/user/video\u0026quot;, \u0026quot;/video\u0026quot; This means that the folder with the path to \u0026quot;/home/user/video\u0026quot; will be available in the envitonment with the path \u0026quot;/video\u0026quot;. You can add any number of folders, each folder on your line. Example changed Vagrantfile:\nVagrant.configure(2) do |config| config.vm.box = \u0026quot;ubuntu/xenial64\u0026quot; config.vm.synced_folder \u0026quot;/home/MyName/video\u0026quot;, \u0026quot;/video\u0026quot; config.vm.synced_folder \u0026quot;/home/MyName/Desktop\u0026quot;, \u0026quot;/desk\u0026quot; config.vm.synced_folder \u0026quot;/home/MyName/Downloads/videofiles\u0026quot;, \u0026quot;/stuff\u0026quot; config.vm.provision \u0026quot;shell\u0026quot;, inline: \u0026lt;\u0026lt;-SHELL sudo apt-get install -y gcc sudo apt-get install -y libcurl4-gnutls-dev sudo apt-get install -y tesseract-ocr sudo apt-get install -y tesseract-ocr-dev sudo apt-get install -y libleptonica-dev SHELL end Now, after changing Vagrantfile, if you have environment is launched, you have to perform in the host computer terminal %%vagrant reload --provision %%, or if stopped, run %%vagrant up%%\nExample - subtitles will be created in synced folder /video\nYou can edit the code from both the host computer and the virtual machine, and build it in virtual machine.\n","link":"https://ccextractor.org/public/general/vagrant/","title":""},{"body":"Amazon AWS deployment =\nThis is a guide for deploying, configuring and administrating CC Repository on Amazon Web Service.\nServer Architecture First, let's consider server architecture. I suggest to use the approach based only on EC2, RDS and ELB services provided by Amazon.\nServer architecture includes the following components:\n MySQL server. This server is based on Amazon RDS instance and is used for storing MySQL database and accessing it from other servers NFS server. This EC2 instance is used for sharing file system across other servers and also for running some supplementary programs. Web servers. These are EC2 instances responsible only for running Apache i.e. only for web access. They are joined in autoscaling group which can start/terminate instances depending on chosen policies. Repository servers. These are EC2 instances responsible only for running repository application (ccr) and receiving traffic from ccextractor (i.e. tuners) clients. They are also joined in autoscaling group. Web severs load balancer. This is Amazon ELB that receives connections on 80 port and distributing them across web servers. Its DNS name end-clients would use to access web site from their browsers. Repository servers load balancer. This Amazon ELB is used for handling connections from ccextractor applications and distributing them across repository servers.  Installation Creating Security Groups We'll need to create following security groups with specified inbound rules:\ncc-tuners-lb Security group for repository servers load balancer. For each server with tuners you'll need to create an inbound rule with its IP as a source.\n^ Type ^ Ports ^ Source ^ | Custom TCP | 3030 | \u0026lt;servers_IPs\u0026gt; |\ncc-web-lb Security group for web servers load balancer. This group grants access from any IP to web pages.\n^ Type ^ Ports ^ Source ^ | HTTP | 80 | 0.0.0.0/0 |\ncc-slave Security group for EC2 instances in both autoscaling groups. It opens ports for load balancer and NFS server. SSH is added for administration purposes and can be removed later. To create rules for NFS you will have create cc-master group first.\n^ Type ^ Ports ^ Source ^ | All TCP | 0-65535 | | | Custom TCP | 111 | | | Custom TCP | 2049 | | | Custom UDP | 111 | | | Custom UDP | 32806 | | | SSH | 22 | \u0026quot;My Ip\u0026quot; |\ncc-master Security group for NFS server.\n^ Type ^ Ports ^ Source ^ | Custom TCP | 111 | | | Custom TCP | 2049 | | | Custom UDP | 111 | | | Custom UDP | 32806 | | | SSH | 22 | \u0026quot;My Ip\u0026quot; |\ncc-db Security group for RDS MySQL database instance.\n^ Type ^ Ports ^ Source ^ | MYSQL/Auror | 3306 | | | MYSQL/Aurora | 3306 | \u0026quot;My Ip\u0026quot; |\nCreating Database  Launch RDS MySQL instance with //cc-db// security group. Now you need to create database tables by calling mysql --user=root --password=root-password --host=...rds.amazonaws.com cc \u0026lt; misc/tables.sql Then edit the following lines in //misc/users.sql// to set passwords for two users //cc_ro// and //cc_rw// that will be used to connect form PHP scripts and from server application.SET @ro_passwd = 'read-only-user-password'; SET @rw_passwd = 'read-write-user-password'; Execute this SQL file by callingmysql --user=root --password=root-password --host=...rds.amazonaws.com cc \u0026lt; misc/users.sql  Configuring NFS server  Launch EC2 Instance based on Amazon Linux AMI with //cc-master// security group and connect to it. Create empty volume in the same region as this instance. Attach this volume to the instance. Let's say it's ///dev/xvdf// Create file system on this volume: sudo mkfs -t ext4 /dev/xvdf Add following line to the end of ///etc/fstab// file. It make system mount //xvdf// volume to ///srv// directory at server startup. /dev/xvdf /srv ext4 defaults,nofail 0 0 Mount this volume sudo mount -a Create repository directories for storing logs, temporary files and files with captions: sudo mkdir /srv/logs /srv/web /srv/archive Install git and clone source files to your home directory:sudo yum install git git clone https://github.com/rkuchumov/ccextractor-server From //misc// directory install //ccr-watchdog// – a service that closes connections if they are no longer alive. It's not really important, but sometimes magic happens and connections doesn't close gracefully.cd ccextractor-server/misc sudo ./install-watchdog.sh The command above will place watchdog script to ///etc/init.d/// and configuration files to ///etc/ccr///. You'll need to place your database host, user with read-write access (cc_rw) and its password in ///etc/ccr/db.ini// Now you need to start this service and make it run at each system bootsudo service ccr-watchdog start sudo chkconfig ccr-watchdog on Next steps will set up NFS server itself. First, you need to install //nfs-utils// and //rpcbind//yum install nfs-utils rpcbind Now you need to specify which directories to share and options for them. Create ///etc/exports// file with the following content:/srv/archive *(rw,async,no_root_squash,no_acl) /srv/web *(rw,sync,no_root_squash,no_acl) /srv/logs *(rw,sync,no_root_squash,no_acl) Now you need to load the changes by callingsudo exportfs -ar The following commands will start NFS service and related services and make them run on each system startupsudo service rpcbind start sudo service nfs start sudo service nfslock start sudo chkconfig rpcbind on sudo chkconfig nfslock on sduo chkconfig nfs on It's probably a good idea to create an image of this instance in EC2 console and turn on termination protection.  Configuring repository servers  Launch EC2 Instance based on Amazon Linux AMI with //cc-slave// and //cc-tuners// security groups and connect to it. First, we'll set up NFS client. You'll need to install //nfs-utils// and //rpcbind// by callingsudo yum install nfs-utils rpcbind Start and enable NFS services:sudo service rpcbind start sudo service nfslock start sudo chkconfig rpcbind on sudo chkconfig nfslock on Add the following lines to the end of ///etc/fstab//. It'll make the system mount these directories at each system boot. //nfs_server// is public DNS of your NFS server. You can find in EC2 console. It's something like //ec2-52-26-9-221.us-west-2.compute.amazonaws.com//nfs_server:/srv/web /srv/web nfs rw,noac,noacl,nocto,nodiratime 0 0 nfs_server:/srv/logs /srv/logs nfs rw,noac,noacl,nocto,nodiratime 0 0 nfs_server:/srv/archive /srv/archive nfs rw,async,noacl,nocto,nodiratime 0 0 To mount directories listed above callsudo mount -a Next, we'll install repository application. First, you'll need to install Git and addition packages for compilationsudo yum install git gcc mysql-devel Download CCExtractor source code, compile and install it. The last command shall place //ccextractor// binary to ///usr/bin/// directoryhttps://github.com/CCExtractor/ccextractor ~ cd ~/ccextractor make sudo make install Download repository application source, compile and install it.git clone https://github.com/rkuchumov/ccextractor-server cd ccextractor-server sudo make install Now you need to specify database host, user with read-write access (cc_rw) and its password in ///etc/ccr/db.ini// configuration file. Start and enable repository service by calling:sudo service ccr start sudo chkconfig ccr on Finally, create instance image from EC2 console  Configuring web servers  Launch EC2 Instance based on Amazon Linux AMI with //cc-slave// and //cc-web// security groups and connect to it. First, we'll set up NFS client. You'll need to install //nfs-utils// and //rpcbind// by callingsudo yum install nfs-utils rpcbind Start and enable NFS services:sudo service rpcbind start sudo service nfslock start sudo chkconfig rpcbind on sudo chkconfig nfslock on Add the following lines to the end of ///etc/fstab//. It'll make the system mount these directories at each system boot. //nfs_server// is public DNS of your NFS server. You can find in EC2 console. It's something like //ec2-52-26-9-221.us-west-2.compute.amazonaws.com//nfs_server:/srv/web /srv/web nfs ro,noac,noacl,nocto,nodiratime 0 0 nfs_server:/srv/logs /srv/logs nfs rw,noac,noacl,nocto,nodiratime 0 0 nfs_server:/srv/archive /srv/archive nfs ro,noac,noacl,nocto,nodiratime 0 0 To mount directories listed above callsudo mount -a Next, we'll install repository application, Apache, PHP and MySQL client. sudo yum install git httpd24 php56 php56-mysqlnd git clone https://github.com/rkuchumov/ccextractor-server cd ccextractor-server/web/ sudo ./install.sh The last command will copy web pages to ///var/www///, configure php.ini, and copy Apache configuration file to ///etc/httpd/conf.d///. You'll need to edit this file and set database host, read-only user (cc_ro) and its password in environment variables:SetEnv CC_DB_HOST localhost SetEnv CC_DB_NAME cc SetEnv CC_DB_USER cc_ro SetEnv CC_DB_PASSWORD read-only-user-password Uncomment //ErrorLog /srv/logs/apache.log// line to redirect Apache error messages in /srv/logs/ Set //DocumnetRoot// to ///var/www/public/// in ///etc/httpd/conf/httpd.conf//. Start and enable Apache server by calling sudo service httpd start sudo chkconfig httpd on Create instance image from EC2 Console.  Creating Load Balancers  Follow this guide to create launch configuration, load balancers and auto scaling groups for web servers.  Launch configuration should contain web server instance image and //cc-slave// and //cc-web// security groups. Load balancer should accept connections on 80 TCP port and have //cc-web-lb// security group.   Repeat the same procedure for repository servers  Launch configuration should contain repository server instance image and //cc-slave// and //cc-tuners// security groups. Load balancer should accept connections on 3030 TCP port and have //cc-tuners-lb// security group.    Administration Guidelines  One connected CCExtractor client takes about 250-300 Mb of RAM. Thus, if your repository instance has 1GB of RAM, it can successfully handle 3 connected tuners. ..... ???? TODO  ","link":"https://ccextractor.org/public/gsoc/amazon_aws_deployment/","title":""},{"body":"======= GSOC 2015 Documentation =======\nTechnical Documentation Transport Stream Data structure in Transport Stream made for Multiprogram.\nDecoder In CCextractor we have single Decoder Initialization function, struct lib_cc_decode* init_cc_decode (struct ccx_decoders_common_settings_t *setting) where settings of decoder are passed in its parameter \nstruct ccx_decoders_common_settings_t {\n LLONG subs_delay; // ms to delay (or advance) subs\n enum ccx_output_format output_format; // What kind of output format should be used?\n int fix_padding; // Replace 0000 with 8080 in HDTV (needed for some cards)\n struct ccx_boundary_time extraction_start, extraction_end; // Segment we actually process\n int cc_to_stdout;\n int extract; // Extract 1st, 2nd or both fields\n int fullbin; // Disable pruning of padding cc blocks\n struct ccx_decoder_608_settings *settings_608; // Contains the settings for the 608 decoder.\n ccx_decoder_dtvcc_settings_t *settings_dtvcc; //Same for cea 708 captions decoder (dtvcc)\n int cc_channel; // Channel we want to dump in srt mode\n unsigned send_to_srv;\n unsigned int hauppauge_mode; // If 1, use PID=1003, process specially and so on\n int program_number;\n enum ccx_code_type codec;\n void *private_data;\n};\n In settings subs\\_delay is deprecated and should not be used further, subs\\_delay parameter was added for transition period and need to be removed. same thing for send\\_to\\_srv, output\\_format. If Demuxer has already initialized deocder like in case of teletext and dvbsub at the time of demuxing then private\\_data can be filled with context of specific format decoder and initialize value enum ccx\\_code\\_type codec. ### How to use multiprogram extraction using CCExtractor? For Command line user its simply passing -multiprogram argument to ccextractor `cextractor -multiprogram `\u0026lt;input ts filename\u0026gt; ### How to use OCR for extracting bitmap subtitle in text format? For doing OCR on bitmap image of subtitles, compile code after enabling OCR in source code. While compiling ccextractor, follow OCR.txt in doc folder of ccextractor source code. ### Link list data structure in CCextractor Background ---------- Link List implemented in CCextractor is taken from Linux Source Code. Please note ccextractor Link list does not have same syntax as it is in linux source code but its similar and only changes that you will in CCextractor link list would be adaptation of Windows environment. Implementation -------------- For implementing link list you need head of link list using which you can always traverse update or delete the complete link list. Keep head of link List in safe location, most common mistake developer do is keeping head inside node structure and do memory leakage if loosing Head of link list. for example we need multiple decoders to extract different Subtitles from different programs. so as discussed above Head of link list should not be kept in Decoder Context. It must be in its parent which cant die or deleted before its child. We will keep head of decoder link list in CCextractor library Context which contain all demuxer, decoder and encoder. Following would be syntax for keeping decoder List in Library Context. \u0026lt;code\u0026gt; struct lib\\_ccx\\_ctx { ` struct list_head dec_ctx_head;` }; ~~~ now next thing to do is initialize the head of link list, for decoder link list we would initialize it in initialization part of library \u0026lt;code\u0026gt; void init\\_libraries(void) { ` INIT_LIST_HEAD(\u0026amp;ctx-\u0026gt;dec_ctx_head);` } ~~~ Now in your decoder context put connector of link list, which will actually make your dec\\_ctx as node `struct lib_cc_decode` `{` `struct list_head list;` `};` Put your decoder node back in link list, in below code I have assumed that you allocated decoder Context and saved in variable dec\\_ctx and your library with head of your link list is saved in ctx variable. `list_add_tail( \u0026amp;(dec_ctx-\u0026gt;list), \u0026amp;(ctx-\u0026gt;dec_ctx_head) );` One of the reason that people prefer Array because traversing, searching, updating and deleting them is very easy, now that excuse wont work, Now only reason to use Array would be contiguous memory allocation. Traversing Link List for searching and updating some parameter \u0026lt;code\u0026gt; list\\_for\\_each\\_entry(dec\\_ctx, \u0026amp;ctx-\\\u0026gt;dec\\_ctx\\_head, list, struct lib\\_cc\\_decode) { ` //Access your parameter here`\\ ` print(dec_ctx-\u0026gt;program_number);` } ~~~ there is different code for traversing link list when you might delete complete node of link list while traversing. also mind that delete link of node from link list first after then delete or free your memory allocated for node \u0026lt;code\u0026gt; list\\_for\\_each\\_entry\\_safe(dec\\_ctx, dec\\_ctx1, \u0026amp;lctx-\\\u0026gt;dec\\_ctx\\_head, list, struct lib\\_cc\\_decode) { ` list_del(\u0026amp;dec_ctx-\u0026gt;list);`\\ ` free(dec_ctx);` } ~~~ ##### How to evaluate? Clone my repository from git hub in **any** directory of gsoc server `git clone --depth `[`https://github.com/anshul1912/ccextractor.git`](https://github.com/anshul1912/ccextractor.git) Run CCextractor with multiprogram in argument `ccextractor /repository/newRepository/TestFiles/General/Closedcaption_atsc_multiprog.ts -multiprogram -o a.srt` In file specified in above command there are 6 program with closed caption. but ccextractor tries to extract Closed caption from all 8 programs therefore it makes 2 empty files. you would have following file in directory where command was executed. `[anshul@gsocdev linux]$ ls a_*` `a_1.srt a_2.srt a_3.srt a_4.srt a_5.srt a_6.srt a_7.srt a_8.srt` From same file extract subtitles individually using -pn argument. you can use following command to extract each program. `ccextractor /repository/newRepository/TestFiles/General/Closedcaption_atsc_multiprog.ts -pn 1 -o pn_1.srt` `ccextractor /repository/newRepository/TestFiles/General/Closedcaption_atsc_multiprog.ts -pn 2 -o pn_2.srt` `ccextractor /repository/newRepository/TestFiles/General/Closedcaption_atsc_multiprog.ts -pn 3 -o pn_3.srt` `ccextractor /repository/newRepository/TestFiles/General/Closedcaption_atsc_multiprog.ts -pn 4 -o pn_4.srt` `ccextractor /repository/newRepository/TestFiles/General/Closedcaption_atsc_multiprog.ts -pn 5 -o pn_5.srt` `ccextractor /repository/newRepository/TestFiles/General/Closedcaption_atsc_multiprog.ts -pn 6 -o pn_6.srt` Now check the difference between files generated by ccextractor with multiprogram and pn. for example you can use command line tool like following. `diff a_1.srt pn_1.srt` ##### Contribution for blog Now CCextractor have feature to extract Closed Caption from all channels simultaneously. Its not just about extracting Closed caption from all channel but also converting them to desirable format. Now there is no need of multiple Capture Device to capture single live closed caption. Use this wonderful openSource software and save your hard earn money to donate in technology and make this software more wonderful. This Multiprogram Closed caption Extraction works for DVBSub, Teletext and Closed Caption. which means whichever is your country Multi programs Extraction would work. If in some peoples country multiprogram subtitles extraction is still not working, we would say invest here and help this newer `generation to do more wonderful and innovative work instead of discovering or inventing Wheel` ##### Addendum = My Graduation would be completed this year, so I would seek the opportunity to be mentor or co-mentor in CCExtractor. CCExtractor is great tool which can be used for various multimedia application, so my development would continue in this project at least till C has its charm. Since the part of work that I have done in CCextractor was done with atmost care according to my knowledge, therefore I would try to remove any bug in part of my code reported by someone else or encountered by me. ","link":"https://ccextractor.org/public/gsoc/anshul_maheshwari_gsoc15/","title":""},{"body":"Configuration options This document describes repository application and website configuration options\nRepository application config There are 3 ways to configure server application: config files, environment variables and command line arguments. Options from config files can be overwritten by environment variables which can be overwritten by cmd arguments.\nTo get a list of options' values that application will use in runtime, you can call it with //-a// or //--variables// argument.\nDefault location of config file is ///etc/ccr/ccr.ini//, but its location can be overwritten. There is also separate config file ///etc/ccr/db.ini// that canbe used for storing database connection parameters.\nSyntax of config file is similar to INI format:\n * One key-value pair per line separated by equal sign\n * Semi-column is used for comments\n * String values should be double-quoted\n * Boolean values is //true/false/1/0//\nBellow is a list of options supported by server application. Option name is represented by its name in config files, environment variable and command line argument.\ndaemon, env: CC_DAEMON, cmd: --daemon\nDefault: false if true, server shall run as standalone daemon process.\ndb-host, env: CC_DB_HOST, cmd: --db-host\nMySQL server host.\ndb-user, env: CC_DB_USER, cmd: --db-user\nMySQL user name when connecting to the server.\ndb-password, env: CC_DB_PASSWORD, cmd: --db-password\nMySQL user password to use when connecting to the server.\ndb-name, env: CC_DB_NAME, cmd: --db-name\nMySQL database name to use.\ndb-timezone, env: CC_DB_TIMEZONE, cmd: --db-timezone\nDefault: +00:00 MySQL database time-zone varable value.\nport, env: CC_PORT, cmd: --port\nDefault: 3030 TCP port for accepting CCExtractor connections.\npassword, env: CC_PASSWORD, cmd: --password\nThe password clinets must use for their captions to accepted. If it's epmty, server doesn't require password.\nping-interval, env: CC_PING_INTERVAL, cmd: --ping-interval\nDefault: 3 The interval (in seconds) between sending keep-alive pakets to the clinet.\nping-timeout, env: CC_PING_TIMEOUT, cmd: --ping-timeout\nDefault: 20 The number of seconds server waits for keep-alive packets before closing connection.\npid-file, env: CC_PID_FILE, cmd: --pid-file\nDefault: /var/run/ccr.pid Path to PID file when running in daemon mode.\nconfig-file, env: CC_CONFIG_FILE, cmd: --config-file\nDefault: /etc/ccr/ccr.ini Path to server's configuration file. (Note that this cmd argument doesn't work now)\ndb-config-file, env: CC_DB_CONFIG_FILE, cmd: --db-config-file\nDefault: /etc/ccr/db.ini Path to database connection configuration file. (Note that this cmd argument doesn't work now)\nerror-log, env: CC_ERROR_LOG, cmd: --error-log\nDefault: /var/log/ccr-error.log Path to the log file with errors.\ndebug-log, env: CC_DEBUG_LOG, cmd: --debug-log\nDefault: /var/log/ccr-debug.log Path to the log file with debug messages. To create this file you should set --verbose option to true.\nlog-stderr, env: CC_LOG_STDERR, cmd: --log-stderr\nDefault: false If true log messages will be outputed to standart output (stdout) and no log files will be created. You can't use this option in daemon mode\nverbose, env: CC_VERBOSE, cmd: --verbose\nDefault: false If true debug log messages will be printed in log file\nweb-buffer-dir, env: CC_WEB_BUFFER_DIR, cmd: --web-buffer-dir\nDefault: /srv/web Path to the directory shall contain website buffer files.\nbuffer-file-max-lines, env: CC_BUFFER_FILE_MAX_LINES, cmd: --buffer-file-max-lines\nDefault: 200 The max number of lines in website buffer file. When number of lines reaches thisvalue, several first lines is removed so that the file contains 'buffer-file-min-lines' lines.\nbuffer-file-min-lines, env: CC_BUFFER_FILE_MIN_LINES, cmd: --buffer-file-min-lines\nDefault: 100 The number of lines website buffer file will be cropped to when it reaches 'buffer-file-max-lines.'\narchive-dir, env: CC_ARCHIVE_DIR, cmd: --archive-dir\nDefault: /srv/archive Path to the directory that shall contain files with closed captions (.srt, .txt, .bin)\nprogram-change-timeout, env: CC_PROGRAM_CHANGE_TIMEOUT, cmd: --program-change-timeout\nDefault: 7200 The number of seconds untill current program is changed to unknown, (if no EPG is reported)\nprogram-change-eps, env: CC_PROGRAM_CHANGE_EPS, cmd: --program-change-eps\nDefault: 120 The maximum gap in seconds between adjacent EPG enevts. If the gap is large, current program is changed to undefined.\nstore-cc, env: CC_STORE_CC, cmd: --store-cc\nDefault: true If true, closed catptions will be stored in filesystem and in database. If it's false, database is still required for storing info about active connections.\nccextractor-path, env: CC_CCEXTRACTOR_PATH, cmd: --ccextractor-path\nDefault: /usr/bin/ccextractor Path to CCExtractor executable.\nccextractor-output-dir, env: CC_CCEXTRACTOR_OUTPUT_DIR, cmd: --ccextractor-output-dir\nDefault: /tmp/cce-output Path to the directory that shall contain CCExtractor output files.\nccextractor-input-dir, env: CC_CCEXTRACTOR_INPUT_DIR, cmd: --ccextractor-input-dir\nDefault: /tmp/cce-input Path to the directory that shall contain CCExtractor intput files.\nWeb pages config Web pages a configured using Apache environment variables. These variables can be set in //web/ccr.conf// file or in ///etc/httpd/conf.d/ccr.conf// after installation.\nSupported variables are:\n * **CC_DB_HOST** --- MySQL server host.\n * **CC_DB_NAME** --- MySQL database name to use.\n * **CC_DB_USER** --- MySQL user name when connecting to the server.\n * **CC_DB_PASSWORD** --- MySQL user password to use when connecting to the server. If it is not set, then empty password is used\n","link":"https://ccextractor.org/public/gsoc/configuration_options/","title":""},{"body":"Database architecture Tables Clients Stores information about clients that have ever send any data. It includes:\n * client IPv4 or IPv6\n * transmission description presented by the client (e.g. tv station name) using -tcpdesc flag.\nCREATE TABLE IF NOT EXISTS `clients` (\n `cli_id` INT NOT NULL AUTO_INCREMENT,\n `ip` VARBINARY(16) NOT NULL,\n `desc` VARCHAR(300) COLLATE utf8_bin DEFAULT NULL,\n PRIMARY KEY (`cli_id`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin AUTO_INCREMENT=1 ; ~~~\nPrograms Stores program information and its extracted CC data. It includes:\n * id of a client who send this program,\n * time-stamps of the beginning and the end of the program. May not match actual start and end time (in case user started transmission in the middle of the show),\n * title, description, category, language fetched from EPG,\n * closed captions in TXT format. The are used only for searching; CC in srt, ttxt, bin are stored in server's file system\nCREATE TABLE IF NOT EXISTS `programs` (\n `id` INT NOT NULL AUTO_INCREMENT,\n `cli_id` INT NOT NULL,\n `start` TIMESTAMP NULL DEFAULT NULL,\n `stop` TIMESTAMP NULL DEFAULT NULL,\n `title` VARCHAR(150) COLLATE utf8_bin DEFAULT NULL,\n `desc` VARCHAR(150) COLLATE utf8_bin DEFAULT NULL,\n `lang` VARCHAR(5) COLLATE utf8_bin DEFAULT NULL,\n `category` VARCHAR(150) COLLATE utf8_bin DEFAULT NULL,\n `cc_data` MEDIUMTEXT COLLATE utf8_bin,\n PRIMARY KEY (`id`),\n FOREIGN KEY (`cli_id`) REFERENCES clients(cli_id)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin AUTO_INCREMENT=1 ; ~~~\nActive clients Stores ids of connected clients at the moment and timestamps of the last received keep-alive packet (watchdog use this values to clean up not gracefully closed connections)\nCREATE TABLE IF NOT EXISTS `active_clients` (\n `cli_id` INT NOT NULL UNIQUE,\n `last_ping` TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,\n FOREIGN KEY (`cli_id`) REFERENCES clients(cli_id)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin ; ~~~\nInitializing database To create the tables above you can execute //misc/tables.sql// file by calling something likemysql -uroot \u0026lt; misc/tables.sql\nIf you are setting up database for production environment I recommend you to add users with minimal privileges for connecting from Web scrips and from server application. To do that there is //misc/users.sql// file. Before executing it edit passwords and subnet in the beginning. It shall add users with the following privileges:\n - cc_rw\n * SELECT,INSERT,UPDATE,DELETE ON active_clients\n * SELECT,INSERT,UPDATE ON clients\n * SELECT,INSERT,UPDATE ON programs\n - cc_ro\n * SELECT ON active_clients\n * SELECT ON clients\n * SELECT ON programs\n","link":"https://ccextractor.org/public/gsoc/database_architecture/","title":""},{"body":"This seems interesting. Here's the original request email:\nDoes CCExtractor have support for extracting captions contained in the VAUX area on DV streams, and I just can't figure out how to use it?\nIf not, are there any plans to integrate this into CCExtractor? It seems to me that the only software available to do this is MacCaption, which costs many hundreds of dollars.\nHere are some links to specifications I have run across: https://dvswitch.alioth.debian.org/wiki/DV_format/ http://ffmpeg.sourcearchive.com/documentation/0.6/dvdata_8h-source.html\nThis page contains links to two DV-stream-containing files that supposedly contain captions in their streams, meant for testing one's equipment chain: http://www.cpcweb.com/dv/dv-hardware.htm http://www.cpcweb.com/samples/CPCDemo_DV_720x480_CC.mov http://www.cpcweb.com/samples/CPCDemo_DV_720x480_CC.avi\nTo extract the DV stream from those containers while retaining the VAUX stream, apparently one can use http://www.kinodv.org/article/view/182/1/11/ according to https://lists.libav.org/pipermail/ffmpeg-user/2010-March/024594.html\nHere is a discussion where someone wants to transcribe a VHS via a DV camera while preserving closed captions. It seems they gave up and used (bought?) a DVD/VHS combo machine to dump directly to MPEG2, preserving Line 21 at the cost of quality and edit-ability: https://discussions.apple.com/thread/764469?start=0\u0026amp;tstart=0\nIf one wants to transcribe an NTSC source with captions and already owns a good analog source (LaserDisc, SVHS) and DV-based digitizer, it would be nice to have this capability in CCExtractor's arsenal of features.\nThanks for your time and consideration.\n","link":"https://ccextractor.org/public/gsoc/dv_support_request/","title":""},{"body":"FFmpeg + Rust: Code builder Why is this a CCExtractor project and not an FFmpeg project?\nBecause the FFmpeg team doesn't need it :-) We do.\nIntroduction\nFFmpeg is, of course, everybody's go-to tool when it comes to video manipulation: Resize, apply filters, convert to a different encoding or container, etc, it does it all. They even participate in GSoC every year!\nIf you read their documentation, you will see that FFmpeg, the command-line tool, is mostly a \u0026quot;shell\u0026quot; that actually builds a graph that then runs in their libraries.\nFor developers that need to use FFmpeg to do \u0026quot;something\u0026quot; specific with video, the usual way to do it it just by executing FFmpeg with the right parameters (using spawn, exec, or whatever it's called in their language of choice), wait for it to finish, and then do something with the result.\nOften that's good enough, but many times it's not: You can't easily get progress, you absolutely can't do anything in the middle of the process and so on.\nYour job\nYour job here is to build a \u0026quot;source code generator\u0026quot; that given a FFmpeg command line is able to write the source code of a program, preferably in Rust, that executes the graph using FFmpeg's libraries - but this is not about spawning FFmpeg! For example, given a command line like this:\nffmpeg -i input.mkv -vf scale=320:240 output.mp4\nYou can see that it's going to read the file \u0026quot;input.mkv\u0026quot;, resize it to 320x240, and write it as output.mp4, so there's a resize filter there and also a container conversion.\nWhat we want to get is a program that does that for exactly those files and those tasks, and it needs to use FFmpeg's low level libraries so it's possible to add code into the program that does whatever the developer needs to do: For example, they might want to modify each frame to add something that is not supported by an FFmpeg filter - may be something that needs to be fetched for an external source.\nYour output program needs to be compilable (of course) and do exactly the same thing as FFmpeg would do if called with the specified parameters.\nOf course, you are expected to dig into how FFmpeg does it and build from there.\nWe prefer Rust but C would also be OK. However, if you already know C or C++ learning Rust is not too hard and it's totally worth it.\nQualification tasks\nTake a look at this page.\n","link":"https://ccextractor.org/public/gsoc/ffmpeg-rust/","title":""},{"body":"rutorrent mobile interface Introduction\nrutorrent is the most popular web interface for rtorrent, which is possibly the most used BitTorrent client in linux. It is mostly a web application, but it has its own backend that connects to rtorrent. You could connect to rtorrent directly as well, but by doing that you would be missing lots of features that come with rutorrent, for example RSS support.\nYes, there are two things with almost the same name. To summarize:\nrtorrent =\u0026gt; The BitTorrent client, a console-based tool that also has an API to interact with it. rutorrent =\u0026gt; A web interface for rtorrent that uses that API. It also does other things, for example, it can download torrents from an RSS feed. You configure RSS feeds in rutorrent's web interface, but there's also a backend service (written in PHP) that is part of rutorrent to do the actual download.\nYour job\nThe job is to write a Flutter based web interface that uses rutorrent's backend service to provide a native interface.\nThe basic things (for example, torrent listing) are easy to do, but rutorrent is extensible (it has good plugin support) and your tool needs to support that, too.\nThe job is to write a native application that feels written for mobile. It's not about cloning rutorrent's interface. So yes there needs to be a torrent list but the columns may be different (definitely less), colors, sorting, how you interact with the tool and so on.\nrtorrent, by the way, runs in a server, and rutorrent is the web interface that lets you interact with rtorrent. We don't want to add BitTorrent capability to mobile or anything like that. This is a 100% frontend job, using pre-existing work in rutorrent to control rtorrent from the phone.\nNotes\nIn order to understand what to do you need to actually install rtorrent and rutorrent and play with them.\nYou don't need to have previous experience (really, not important for this - it's all about Flutter), but you won't be able to come up with a good proposal if you don't know how things work.\nAlso, if you are unable to run rtorrent and rutorrent on your system, please use this docker image.\nQualification tasks\nTake a look at this page.\n","link":"https://ccextractor.org/public/gsoc/flutterrutorrent/","title":""},{"body":"~~META: title = Google Summer of Code with CCExtractor Development! GSoC 2019 ~~\nGoogle Summer of Code with CCExtractor Development! Click here for : Slack, Mailing List, 2019 Ideas Page, Past Archives, GitHub.\n {{ :public/gsoc/gsoc-cc.png?nolink |}}\nCCExtractor Development has been accepted to Google Summer of Code each year, ever since we applied for the first time in 2014 and we have had absolutely amazing 5 years! Continuing with open source spirit, we are actively applying to Google Summer of Code 2019 to work with potential new community members! \nIf you're coming across Google summer of Code, which we'll call GSoC from now, for the first time -- it is a global program where students work with an open source organization on a 3 month programming project during their break from school. Google awards stipends (and other good stuff) to students for their work, which they do from their home. Several experience and involved community members serve as mentors for the projects. This is a mutual learning and growing program for both students and mentors. \nRead more about GSoC : https://summerofcode.withgoogle.com/ \nWho are we? CCExtractor is originally an organization about subtitles and accessibility (our \u0026quot;official\u0026quot; description below). However, we're doing lots of other things that are related, including tinkering with open video hardware (JokerTV), imaging (OCR), and more. So we have projects that cover a range of interests, despite our core tool being the most amazing subtitle extractor. \nAnd now, the official description: Whether it's because you are learning a new language, have hearing problems or just at a loud place, subtitles are an essential part of enjoying TV and movies for a a lot of people. There's plenty of tools to manage audio/video, but when it comes to subtitles, the few tools that exist are closed source and extremely expensive. CCExtractor is the one tool that is free, portable, open source and community managed that can take a recording from a TV show and generate an external subtitle file for it. If you regularly watch content with subtitles you download from fan sites - you should know that the source file is most likely generated by CCExtractor. If you are a student in a university that uses subtitles for natural language study, you should know that most likely we are involved somehow. While we already support subtitles from North America, Europe, Australia and more, our world map is not yet complete. We are actively looking for students that want to help us fill the gaps. \nWhy choose us? An interesting article on closed captions (surely explains better than us why there are so useful) \nWe are a small org, which means that your contribution will have a large impact. It's not going to mean a 0.5% improvement on a big project - it's going to be more than 10% on a medium size one. If you like challenges and want a chance to shine this is your place. \nWe have ~we think~ statistically amazing continuity in the team: Most GSoC students from all the past years are still involved, even if they are no longer eligible as students. They still contribute code, and they mentor both in GSoC and the sister program GCI. As mentors, they also come to the Summer of Code summit which traditionally takes place in October. \nWe provide exceptional resources for students - we'll give access to a high speed servers, all our samples (we'll even ship a portable drive with them anywhere in the world, if you have slow connections), specifications et cetera. Students have flexibility of choosing projects from a wide range of topics \u0026amp; technologies and even propose their own. \nWe have *mentors all over the world* (North America, Europe, Asia and Australia), so time zones are never a problem. All our top committers will be mentoring. Many of them are our former GSoC students or winners of GCI. \nWant to find out more? Come hang out on our slack group! \nGCoC 2019 Projects We have a dedicated page for covering this year's projects, check it out here. It also contains proposal guidelines and other information you need to know before applying. If you have any suggestions or you want to propose your own project - please reach out to us in the Slack group.\n Previous Year Projects You may read about our past projects in the official GSoC archive here. We also have most of the final submissions on our website, which you may find here here. \nCan't access slack? Apparently Russia has blocked slack. If this is your case please email us (gsoc at ccextractor dot org) and we'll work out a solution with you. We really want you to participate! \n","link":"https://ccextractor.org/public/gsoc/google_summer_of_code_2019/","title":""},{"body":"GSOC 2016 Project ideas Improving GitHub CI Estimated task time: 1 month+ - Difficulty: moderate-high**\nLast year, as part of GSoC 2015, a first step towards CI on GitHub was made for the CCExtractor repository. CCExtractor possesses a huge repository with samples that are broken or were broken at some point. When adding new features the validity of those samples must be checked. At this moment we have a GitHub bot, written using python (50%), php (38%) and bash (12%). This bot [1] checks GitHub every minute for notifications, and followingly runs code changes either directly on the server (for trusted contributors) or in a VM (using Virtualbox) for all other cases.\nThe obvious better way would be to fully integrate the bot into GitHub using webhooks, like for example Jenkins [2] does. However, running unknown, potentially dangerous code on the server can not be allowed from a security point of view, hence the solution to run a virtual machine for the untrusted code, and a direct run on the server for known contributors. However, a test ran directly on the server takes about 20 minutes, but a test in VirtualBox takes over 14 hours!\nThis is caused by VirtualBox, which is virtualizing the access to the files (shared folder/samba network share), so the this task involves researching a better alternative for VirtualBox. Some interesting keywords: KVM [3], OpenVZ [4], Linux-VServer [5], ...\nAfter doing the research the chosen solution should be implemented (modifying the current code to integrate the new chosen virtualization platform), or starting from scratch. It must both be integrated with the sample platform [6] (built last year) and with the GitHub repository using webhooks [7].\n[1] https://github.com/canihavesomecoffee/ccx_gitbot [2] https://jenkins-ci.org/ [3] https://en.wikipedia.org/wiki/Kernel-based_Virtual_Machine [4] https://en.wikipedia.org/wiki/OpenVZ [5] https://en.wikipedia.org/wiki/Linux-VServer [6] https://github.com/canihavesomecoffee/ccx_submissionplatform [7] https://developer.github.com/webhooks/\nMove our website over to GitHub \u0026amp; update it Estimated task time: 1 week - Difficulty: easy**\nFor years the CCExtractor[1] website has been hosted on the SourceForge platform. With our sourcecode on GitHub, and the (recent) news about the problems with SourceForge [2][3], it would be easier \u0026amp; safer to fully move away from SourceForge.\nYour task would be to create a new github repository for this, and add a updated website to it (a new design might be nice, using bootstrap for example), and update the documentation for CCExtractor on it.\n[1] http://ccextractor.org/ [2] http://www.howtogeek.com/218764/warning-don%E2%80%99t-download-software-from-sourceforge-if-you-can-help-it/ [3] https://en.wikipedia.org/wiki/SourceForge#Controversies\nAdding metadata for caption stream for real-time repository Difficulty: not really, but a lot of work\nThere is a server applications which allows to receive caption stream from TV tuners using CCExtractor. Then, these captions can be viewed from web site in real-time.\nVideo stream from the tuners sometimes have some embedded metadata (EPG or XDS) about the current TV program (title, description, lang, category etc). This metadata is transmitted to the repository and, in turn, is shown to end-user. The problem is that not all the TV channels have these metadata, so usually all we have are channel's name (which is set manually by admin) and bare caption stream.\nWhat you have to do is to find services (online TV schedulers, whatever) which provide APIs for accessing this metadata. Then you should create a program which will fetch these metadata by specified channel name and location (country and the city), and store it in database. To speed up accessing metadata from internal repository services it should be stored in advance (lets say for a day ahead). Also, it would be awesome to get somehow icons with channels logos as well.\nIn the end, you should have a daemon program, which will fetch metadata automatically and insert it in our database. Also you should modify existing database architecture and not to break anything.\nNotification service for real-time repository Difficulty: difficult\nSometime its interesting to know when certain words were mentioned on TV. So, the idea is to create a service where users can specify these words and to receive e-mail notifications when this words were mentioned. These notifications should contain the context of these words and lead to web site where user can view all the captions from TV program and some statistics information.\nSo, this idea includes creating notification program which will read caption stream (from real-time repository) and creating web site where users can specify words and view when they were mentioned.\n","link":"https://ccextractor.org/public/gsoc/gsoc2016/","title":""},{"body":"This page has been moved here.\n","link":"https://ccextractor.org/public/gsoc/gsoc2017/ccaligner_word_by_word_audio_subtitle_synchronisation_saurabh_shrivastava_gsoc_2017/","title":""},{"body":"This page has been moved here.\n","link":"https://ccextractor.org/public/gsoc/gsoc2017/google_summer_of_code_2017_satyam_mittal/","title":""},{"body":"This page has been moved here.\n","link":"https://ccextractor.org/public/gsoc/gsoc2017/python_extension_module_for_ccextractor_diptanshu_jamgade_gsoc_2017/","title":""},{"body":"~~META: title = Google Summer of Code 2018 - Write high speed subtitle synchronization tools ~~\n**Write high speed subtitle synchronization tools **\nTool A - sync between two versions of the same footage: This is a very common use case: Suppose you have raw recording of a TV show, with commercials, etc, then use CCExtractor get the subtitles from it. Then you remove the commercials, and have a really clean recording, but the subtitles are out of sync since the timing changed the video.\nThe project is to write a tool that takes: a) The original video b) The edited video c) The subtitles for the original video\nand produces\nd) The subtitles for the edited video\nWe recommend you use FFmpeg to do the heavy lifting for the video processing and DejaVu as a reference to do the audio fingerprinting which you will need for the synchronization.\nA really important requirement is that this is a fast tool. This means that writing a script that first calls FFmpeg to generate a .wav file and then calls DejaVu to locate each segment will definitely not work (and also, it's not a Summer of Code task). You need to write a C program that uses FFmpeg libraries and reimplement the audio fingerprinting in C. This should be \u0026quot;easy\u0026quot; since for DejaVu you have the source code, an amazing explanation of how everything works, and FFmpeg libraries have FFT functions so luckily you don't need to implement them yourself.\nYou can also come up with a totally different solution that doesn't follow our suggestion as long as it achieves the goal.\nTool B - Suppose you don't have the original video, but you do have the original subtitles from it, so what you have is: a) The subtitles for the original video, which contains subtitles for commercials and possible a few minutes from the previous and following program. b) The edited version.\nDoing the sync now is more difficult as you don't have the original audio or video to compare. But you do have the audio for the edited version from which you can obtain timing for voice. For example if the subtitles for the original video contain three consecutive frames that last 3.45 seconds, 1.54 seconds and 2.34 seconds respectively, and doing audio analysis in the edited video you find 3 segments with voices with similar duration it's likely that they are a match.\nRequirements: 1) You cannot use any non open source dependency. For example, Mathlab is out, even if the run time is free. 2) Your program needs to be usable from a script, so it should be command line based. If there's time, you can definitely provide a GUI, but that's secondary to the main program. 3) High speed is really a priority. Prepare to spend time coming up with a good algorithm. 4) While GSoC is about coding, you will have to prepare really good documentation. As an example, check out DejaVu's explanation on how everything works (even if you don't use it at all, use it as a baseline of really good technical documentation). 5) Must be as portable as the libraries you use. For example FFmpeg builds in linux, windows, etc, so if you use FFmpeg then your program must also build on those platforms.\nWe will provide a fast speed server in which you can work. You don't have to use it, but keep in mind that in general video files are very large. You will need to deal with files that are several gigabytes long. If you have the bandwidth, great. Otherwise you can just work remotely on our development server.\n","link":"https://ccextractor.org/public/gsoc/highspeedsync/","title":""},{"body":"~~META: title = Google Summer of Code 2017 - Create a integrated GUI, replacing what we have ~~\nCreate a integrated GUI, replacing what we have\nThis library\nhttps://github.com/vurtun/nuklear/blob/master/Readme.md\nallows creating amazing GUIs that are portable. We currently have separate GUIs (they are different binaries that run the command line main program) for each supported platform. The job is to create a GUI that is part of the current binary and that works in Windows / Linux / OSX.\nThe library above is a suggestion. It may or may not be exactly what we need, even though it's really promising. It's your job to do the research (this should be part of your proposal, i.e. you need to tell us what library you plan to use), and come up with a good plan.\nWe will assist with integration and you probably can get away without going too deep into the current code. However, when it comes to the GUI itself, you are in the driver's seat. We haven't used this library ourselves so we're there for moral support and general peer support (when you run into problems we'll look into them together, but we won't have guru-level answers ready).\nAlso check this out.\n","link":"https://ccextractor.org/public/gsoc/integratedgui/","title":""},{"body":"~~META: title = Google Summer of Code 2018 - Detect Automatically the most interesting bits of sample videos ~~\nDetect Automatically the most interesting bits of sample videos\nWrite software that is able to detect, for some kind of videos, the most interesting bits (highlights). You can use:\n- Audio (for example, |detect |laughs)\n Video (for example, detect high speed scenes or score changes) - Subtitles  At a minimum, the following must be detected: - Goals in soccer (previous work exists; you can build on it or reimplement) - Three pointers in basketball - Jokes in sitcoms Plus any other 5 use cases you want to work on.\nUseful documents: |Deep Learning of Audio and Language Features for Humor Prediction \n","link":"https://ccextractor.org/public/gsoc/interestingbits/","title":""},{"body":"Add Japanese support Watch this video.\n  And then come with a plan :-)\nQualification tasks\nTake a look at this page.\n","link":"https://ccextractor.org/public/gsoc/japanese/","title":""},{"body":"~~META: title = Google Summer of Code 2018 - JokerTV integration ~~\nJokerTV integration As you may know, our reference TV tuner has been for a long time the amazing HDHomeRun from Silicon Dust. They (all models) are rock-solid and they are really easy to integrate with. However, they don't support DTMB (the Chinese standard).\nThis small thing is JokerTV (stand-alone version).\nYou can see in the tech specs that everything we care about is supported, and that the list of chipsets is published, and that source code for everything, including firmware, is available.\nWe are quite excited about the openness and potential of JokerTV and want to be the first to integrate with it. What should be the result of this integration?\n- CCExtractor would be able to communicate directly with JokerTV - getting the streams directly from it, as we do with the HDHomeRun. - You don't need to decode DTMB (that's a different GSoC project, possibly a summer worth of work) but your integration needs to be as region agnostic as possible. If JokerTV works everywhere, then so must JokerTV+CCExtractor. - It's likely that JokerTV included support tools are not up to par with HDHomeRun's yet. If this is the case (your proposal should show that you've done your homework and can tell us) reserve some time to work on this. - Another two major programs that could use JokerTV integration are FFmpeg and Kodi (for their live TV and DVR functionality). We love cross project ideas, including of course sending patches to their maintainers. If you think you would have time for this, give it some consideration.\nAbout getting a JokerTV - we will buy one for the student that takes on this task. We will also have a few more distributed in different regions around the world so remote testing is possible.\n__Related GitHub Issues__ Extract subtitles in a Chinese newscast\n__Mentor__ Abylay Ospan, the genius behind JokerTV himself.\nQualification tasks\nTake a look at this page.\n","link":"https://ccextractor.org/public/gsoc/jokertv/","title":""},{"body":"~~META: title = Google Summer of Code 2018 - Add support for Live TV over the internet (such as YouTube TV) ~~\nAdd support for Live TV over the internet (such as YouTube TV) A number of platforms are appearing these days to distribute local TV content over the internet. For example, YouTube now has a live TV. Hulu does, too.\nIt's still early days for these platforms - they're trying to grab the business from the cable-cutters, while (possibly, for now) providing the same functionality, which is a live TV with DVR. It's possible of course that they will offer lots of new features and they manage to replace over the air broadcasts, cable...\nAnyway, we don't know how they are implementing subtitles, and the task this summer is to\na) Do the research b) Write code that is able to create transcripts in the usual formats such as .srt\nThis code might be integrated with the current CCExtractor core or it could be a new tool. What's best depends mostly on how the subtitles are distributed. If they are embedded in transport streams then integrating with CCExtractor would be the natural option. It's part of the job to figure this out.\nWe're going to target the two major platforms that have a live TV over the internet: YouTube and Hulu.\nWe will pay for the subscriptions for both services during the coding period, and if you are currently outside the geographical areas in which these services are available, we'll provide a VPN as well.\nFeatures that we expect:\n- The system must be completely scriptable. For example, a solution that requires human intervention to start a capture session, or a browser open on a desktop is not going to work. Suppose we want the system running 24x7 on a Linux server, which might not even have a monitor. - Youtube TV supports a maximum of 6 simultaneous streams per subscription. We don't know about Hulu, but the point is that your solution must be able to maximize what we get from the subscription - if the service allows 6 streams, your solution must too. - Allow several subscriptions to be used as well, for example, if we want 12 streams, then 6x2 should work. - It goes without saying, login information should be configurable and you must be careful not to push any real information to GitHub. - Documentation must be good - we want other projects to build on this one instead of having to figure out everything from scratch.\nQualification tasks\nTake a look at this page.\n","link":"https://ccextractor.org/public/gsoc/livetvooverinternet/","title":""},{"body":"~~META: title = Google Summer of Code 2018 - Complete our OCR subsystem ~~\nComplete our OCR subsystem Useful skills/interests: Image processing, Text Localization and Binarization, Tesseract API Subtitles come in all shapes and colors. Some are text based (such as American closed-captions, as specified in CEA-608 and CEA-708, or the old European teletext). Others are bitmap based such as the European DVB. When subtitles use bitmaps they are a lot more flexible, but also a lot harder to transcribe.\nFor the Latin languages in DVB what we have works quite well. Note that while DVB is bitmap based, as least those bitmaps are separate from the main image, so you only need to OCR the bitmap to get the text.\nHowever, there's variants and cases that make things a lot more harder (and interesting):\n- Burned-in subtitles, in which they overlay the actual TV image. - Non-latin languages, such as Chinese. - Moving subtitles, such as the usual tickers on the screen that move from to side. - Subtitles with different colors, for example to distinguish between different speakers.\nBelieve it or not some of these cases are also supported already in CCExtractor, at least for some \u0026quot;good\u0026quot; conditions. But the really hard ones, are still a job in progress.\nThe heavy lifting (the OCR itself) is done by tesseract. But selecting the area to process, prefilter it so tesseract gets an input it likes and so on, it's done by our own code.\nWe need someone that likes challenges to make the whole thing work.\nWe will provide all the samples and access to a high speed server that has them so the student can work on it (optional) if a fast internet connection is not available to them.\n__Related GitHub Issues__ Extract cyrillic tickertape text in Russian from NTV Extract subtitles in a Chinese newscast GUI, Burned-in Subtitle Extraction not working jumps based on uninitialised values Process closed captions and burned-in subtitles in one pass DVB subtitles from China Corrupt or empty subtitles Terrible OCR results with Channel 5 (UK)\n__Mentor__ Abhinav Shukla (@abhinav95 on slack), which is the former Summer of Code student that worked on it last year and made an incredible job.\nQualification tasks\nTerrible OCR results with Channel 5 (UK) This task is ideal to get started, because you only need to deal with one function in one file: quantize_map() in src/lib_ccx/ocr.c\nIn addition to the samples that we already have, we would also like the creation of a dataset of a few hardsubbed (videos with burned-in subtitles) videos with the accurate timed transcripts so that we can evaluate the performance of our code on a wide variety of these real world samples. For the qualification task, this does not have to be huge. A good representative set will do fine.\nTake a look at this page for more issues.\n","link":"https://ccextractor.org/public/gsoc/ocr/","title":""},{"body":"~~META: title = Google Summer of Code 2019 - PiPot (A micro honeypot for RPi) ~~\nPiPot (A micro honeypot for RPi) PiPot was developed as part of a master thesis of one of the main contributors of CCExtractor. Due to time constraints it didn't see a lot of love the last few years, and that's where you could come in!\nThere is a \u0026quot;small\u0026quot; list of improvements that could be made to the platform, and which we'd love to see implemented, so that the platform is more usable in general.\nThe full list is available on the issues page of the main repository, but is not exhaustive. We'd also love to see some integrations with other existing honeypots.\nGetting started / Requirements The honeypot software is written in Python, so we expect good knowledge of Python. Basic HTML, Javascript \u0026amp; CSS knowledge is also required. Bash scripting knowledge will also be required for the tasks.\nWe make use of quite some libraries, and we expect you to read up on the documentation of these platforms so you know how they work in general.\nQualification If you are interested in taking up this project during GSoC, you will need to satisfy these requirements (in order of importance, not all are a necessity): - A well researched, well written project proposal. - Proof you've set up PiPot locally on a Raspberry Pi (preferred), or on your local PC. - Fixed a bug, improved installation documentation, ... (contributed something to the project). - Have chatted with the mentor(s) at least once.\nMentor(s) - Willem Van Iseghem (@canihavesomecoffee on Slack) is a former GSoC student (2014, 2015, 2016) and mentor (2017, 2018). He wrote the software for his Master thesis and is the official (and currently sole) maintainer.\n","link":"https://ccextractor.org/public/gsoc/pipot/","title":""},{"body":"Poor's man Rekognition Amazon Rekognition is a (paid) service that is able to identify objects, people, text, scenes, and activities in a picture. We want to produce a free alternative.\nWhile being able to do everything Rekognition does over the course of a summer is unrealistic, we think we should be able to kickstart the effort and get to a point where the project will be usable and attract more developers to the effort.\nLet's start with faces, and this is the actual goal: Given a set of properly tagged people (suppose for example, a number of celebrities), create an API that can be used to identify such people in other images.\nAt a minimum\n- Your code must be able to run either locally or in a cloud service - The API needs to be callable from any language (so REST, or something similar) - You need to provide a native binding to a language of your choice - You will need to provide the sample images yourself (can be taken from the internet) - For any picture, it will identify the faces there, and for each face give a list of the most likely people from the known set in order of likeness - Must be able to learn from user feedback\nVideo processing\nBuilding on the previous work, figure out a way to analyze a video and determine who is in each scene. For example if you detect a known actor in let's say, 3:05, and the scene runs until 3:17, then that actor is there from 3:05 to 3:17. Generate a text file (any format) that lists who is in each scene. If possible, don't brute force.\nNotes\n- You can use any open source library to help with the project as long as it doesn't prevent from meeting the full scope\nHow to get started\nSince this is a new project we don't have issues open on it. A good way to start, and what other students are doing, is to write a working proof of concept that shows you are capable to doing the full thing. And then come up with ideas and a plan to implement them during the summer.\nMentor\nJohannes Von Lochter \u0026lt;johannes.lochter at facens d-o-t br\u0026gt; (look him up)\n","link":"https://ccextractor.org/public/gsoc/poormanrekognition/","title":""},{"body":"~~META: title = Google Summer of Code 2018 - Project Nephos: Cloud based storage for a massive collection of TV recordings ~~\nProject Nephos: Cloud based storage for a massive collection of TV recordings\nThere's a lot of documentation on our close friend organization Red Hen (just Google them, or check out their ideas page), but for our purposes these are the basic ideas:\n- Red Hen is an informal (as in they're tied by collaboration, not contracts) group of entities, most of them large universities, from many places around the world that share resources. These resources are hardware, software, media, knowledge, source code, people, and access to people. - Everything is open, there's no NDAs in place, or proprietary software or anything like that. The one thing is that limited (to researchers and other people that can benefit from it) is access to the media repository due to concerns on copyright. - One of the things some universities do (and most want to do) is record as many local (to them) TV channels as they can and archive them. They are used for a long list of research and analysis topics, from language trends to body language analysis, to catch politics on lies and almost anything you can think of. - They use CCExtractor to generate transcripts of the media files. This is the original link between Red Hen and us, but since we met we have been collaborating on other overlapping interests.\nAs mentioned, some universities record a large number of TV channels available locally to them, so UCLA records what they can get in Los Angeles, UNav what they can get in Navarra, Spain, and so on. Currently storage is either handled in-house, or it is uploaded to UCLA, where it is stored. As pointed out, this is all done on good will, not contract, but this is a bit besides the point.\nWe've reached a point in which storing these files locally is making less and less sense. Google offers unlimited storage for organizations that use Google Apps (their professional cloud suite, with GMail, Drive, and so on) which some universities such as UNav have.\nThe project during this summer is migrate to cloud storage, which will require creating a number of tools, modifying others, figuring out the best way to handle access permissions to the files in the cloud, general organization and so on.\nSome of the must-have features are easy, for example when a recording is complete (and exists as a local file) it needs to be moved to Cloud.\nOther things will need more work. Specifically:\n- Indexing. This is not a \u0026quot;index by date\u0026quot; or other trivial thing, we index by content. - Sharing, which needs to be as flexible as possible. In general everything needs to be automatic. For example config such as \u0026quot;share all Spanish TV content with these American universities\u0026quot;, etc. - Duplication, which means that content shared with us from another instance of Nephos can be copied to our own instance of Cloud storage. - Pre and post processes, for example to convert the original format to smaller versions, or to extract subtitles.\nCurrent source code.\n","link":"https://ccextractor.org/public/gsoc/projectnephos/","title":""},{"body":"~~META: title = Google Summer of Code 2018 - Write Python bindings for CCExtractor ~~\nWrite Python bindings for CCExtractor\nExtend Python to use CCExtractor's library to access subtitles. You should export as much of CCExtractor as possible. At a minimum, it should be able to\n- Open and close input video streams. - For an open stream, get the list of programs. - For a selected program, get the subtitles in various easy to use structures. You need to provide access to the original representation (for example, if it's US TV subtitles then a grid for CEA-608, if it's European DVB subtitles then a bitmap) as well as the conversion to usual formats such as .srt.\nWhile CCExtractor itself uses its own library (lib_ccx), we are not aware of any other program using the library directly (as opposed to running CCExtractor and getting the generated file). This means - it's likely you will also need to modify the library itself to make it \u0026quot;sane enough\u0026quot; for this project.\nWe will also be prefer to have Cython code written instead of simple Python wrappers during the program as they offer better speed and compatibility with our existing codebase.\n__Related GitHub Issues__ Make the Python Scripts to run Python3 Python Bindings don't compile with build_library\n__Related Github Commits__ Make Python3 Compatible Code\nQualification tasks\nTake a look at this page.\n","link":"https://ccextractor.org/public/gsoc/pythonbindings/","title":""},{"body":"Program Flow Visualizer Introduction Read this and then come back here :-)\nThe Task We want to build a complete profiler tool. During Google Code-in we created several proofs of concept, so we know it's possible, and we also know that it's a really good idea that got popular really fast. For reference, as you can see in the article linked above, five high school students created each their own implementation (by themselves) in around one month with really impressive results.\nYou can take their existing work (it's open-source after all) and build upon it, or you can do your own thing. But of course, your product must demonstrate GSoC quality - you'll be working full-time for 3 months :-)\nIdeas  Explore use-cases other than algorithms (comment on Hacker News) Decorators to inform the debugger about the properties of user-defined data structures and classes Visualizations for more data structures: trees, linked lists, etc. Support for pausing, delays, and interactive messages, described via comments in the code Interactive web version (or just an output format) Flow control visualization, less of a focus on variables specifically (comment on Hacker News) Support for large target programs (multi-file projects) Integration with gdb and in general, support for other languages [if possible] Manual control keys (Play, pause, speed) Control flow chart (as an overview) Support for //all// types of objects in saved sessions, even those that cannot be serialized directly  This is another potential source of inspiration: https://github.com/hediet/vscode-debug-visualizer/tree/master/extension\nQualification tasks In order to qualify for our projects, you must complete a qualification task or accrue sufficient qualification points from GitHub issues.\nTake a look at this page for tasks oriented for people who are working on new projects like this one. Alternatively, you can go the traditional route of fixing GitHub issues on the main CCExtractor project, which is written in C. You can find more information about this here.\n","link":"https://ccextractor.org/public/gsoc/pythonprofiler/","title":""},{"body":"Web interface for rclone\nrclone is a fantastic cloud sync tool. As good as it is though it lacks a web interface. This is of course not a problem for geeks as rclone's popularity proves. However, it is a problem for everyone else.\nYour job is to create, possibly from scratch (feel free to look for previous efforts), the ultimate rclone web interface that makes it possible to do from it everything that should be doable of nothing that shouldn't be doable.\nWhat does that mean? It means that it should be possible to give access to your web interface to a good faith operator (for example, your mom) and not be possible for her to break anything unintentionally. This implies that roles will be necessary, so it's possible to disable certain operations to users even if we trust the users (\u0026quot;as good people\u0026quot;).\nOf course, it also means that a bad actor shouldn't be able to use your system as a way to break anything other than rclone's config, but nothing else in the host system (for example, no exec, etc). So yes, common sense :-)\nGSoC is 3 months. This is quite a bit for time for a web interface to an existing product with a healthy community, but we are quite ambitious with the scope. It's not a \u0026quot;basic\u0026quot; web interface what we want to contribute, but a complete one that becomes the reference one. Anything and everything that rclone supports your web interface must support.\nIt must also work behind a reverse proxy, by accepting the standard --baseurl parameter. For example, suppose you use Flask or any stand alone web framework that comes with its own web server and that your interface is available at\nhttp://localhost:5000\nIt must be possible to use a reverse proxy in a way that\nhttps://example.com/rclone\ncan be mapped to http://localhost:5000/rclone and it works.\nIf you have experience with frameworks then you have probably seen it. If not, do a bit of research. It's easy to implement, but you have to implement it. This is an essential requirement - users often want to use a separate web server to handle security, certificates and so on, and they don't want to open a different port of each web interface.\nNotes from Nick Craig-Wood I have quite a few ideas on rclone web GUIs. I've been gradually fleshing out the API https://rclone.org/rc/ so that it can control rclone completely.\nRclone can also just run the remote control, serve files and open your browser with\n rclone rcd --rc-serve --rc-noauth --rc-files /path/to/files\nSo that should be enough to build a remote control interface entirely with web technologies. The `--rc-server` means rclone can serve the remote files too.\nI made a very proof of concept react app (to show that the rc API was usable by react), but that is as far as I got!\nI stuck it on github here: https://github.com/ncw/rcloneguiexperiment\nThat is how I imagine development might go, but I could also imagine bundling a version of rclone with the web GUI packaged in, so you could just run `rclone gui` (or maybe even just double click) and get the web interface.\n","link":"https://ccextractor.org/public/gsoc/rcloneweb/","title":""},{"body":"Extend rclone's webui rclone webui currently supports basic plugins like a video player and a music player. This functionality could be extended to incorporate new plugins which could be added by a user on the go, and developers could develop these plugins for rclone.\nThe functionality will be something similar to Google Drive. Ex. If you want to edit a doc file, rclone webui will have a plugin for it, once you enable the plugin, you would be able to edit documents using rclone.\nDeliverables:\n1. A plugin dashboard, where you can install, remove and update plugins. 2. A plugins repository from where the plugins could be fetched into the local rclone instance. 2. The plugins should work in an isolated environment so that they cannot interfere with the system data. 3. Develop at least 3 demo plugins for demonstration. This could be a word processor, a photo editor, etc. 4. We could allow the developer to communicate with their own server and fetch data from there.\nCurrent Stack:\nrclone backend: GoLang rclone webui: Reactjs\nURLs:\nrclone GitHub: https://github.com/rclone/rclone react frontend: https://github.com/rclone/rclone-webui-react rclone forum: https://forum.rclone.org/ webui discussion thread: https://forum.rclone.org/t/beta-testing-webgui-for-rclone/11156\nQualification tasks\nTake a look at this page.\n","link":"https://ccextractor.org/public/gsoc/rcloneweb2/","title":""},{"body":"~~META: title = Google Summer of Code 2017 - A web-site to view captions in real-time ~~\nA web-site to view captions in real-time\nThere is a a web-site which allows viewing caption stream in real-time from web-browser. To fetch CC stream from TV tuner and send it to the server it uses separate application that parses CCExtractor's output. This project just has passed prove-of-concept stage, so at least you have to implement the following:\n - Administration dashboard\n - A service that would parse external database to fetch TV channels metadata and TV guides\n - A service for analyzing CC stream (extracting keywords or key phrases from a stream)\n- A service for notifying users (via email) about their specified keywords being mentioned in CC stream \n - Web site pages (based on supplied wireframes)\nhttps://github.com/rkuchumov/ccr/\n","link":"https://ccextractor.org/public/gsoc/realtimecaptionswebsite/","title":""},{"body":"~~META: title = Google Summer of Code 2018 - Real time subtitles system ~~ This is our proof of concept demo for real time subtitles.\nIt's fed in real time by a number of HDHomeRun tuners that are connected to CCExtractor, which in turn decodes the subtitles and uploads them to this system, which uses NodeJS among other things.\nRight now, only monitoring web page is implemented (the one you see in demo), which is not intended to be used by end-users. During this summer you'll have to design and implement a complete system, which should include:\n - Web pages, for displaying channels and real-time captions. UI sketches in the repository will give you ideas of which features are required. Additional features, listed below are also desired:\n * Multilanguage support (for example, if the program comes with both English and Spanish subtitles we should allow to display both)\n * Sharing URL\n * Support for all display sizes and devices (\u0026quot;responsiveness\u0026quot;)\n - Administrator dashboard which allows to mange channels, captions, monitor the states of infrastructure components. The page you see in the demo should be a part of administrator dashboard.\n- Create a subsystem for analyzing a stream of cations in real-time and presenting its current topic and/or keywords. (Checkhttps://github.com/rkuchumov/ccr/issues/13 for more details)\nWhat should I do?\n* Check repository issues page. Submitting pull requests will definitely make you stand above other students. Note that for \u0026quot;enhancement\u0026quot; tasks you can submit PR, event if there're already PRs by other students. \n * Highlight all aforementioned tasks as well as tasks from GitHub in your proposal with as much details as possible. Do not forget that we select students with the best understanding and a vision of a project.\n* Discuss the project with mentor and suggest new ideas.\n * **Don't ask questions regarding installation and usage (it works fine).** It only shows that you are incapable of reading the code and solving problems, we don't need such developers. If you think there's a bug in deployment stage, fix it and submit a pull request.\n__Mentor__ Ruslan Kuchumov (@kuchumovri on slack) is a former GSoC student (2014, 2015, 2016) and mentor (2017). He has done all the work so far so he's the best possible mentor.\nRepository Link : https://github.com/rkuchumov/ccr\n","link":"https://ccextractor.org/public/gsoc/realtimesubtitles/","title":""},{"body":"Server Application Architecture After installation, you'll have the following files in your file system:\n * /usr/bin/ccr -- Server application executable\n * /usr/bin/ccr-watchdog -- Connection watchdog script (in case you installed it)\n * /etc/init.d/ccr -- Service script file\n * /etc/init.d/ccr-watchdog -- Connection watchdog service (in case you installed it)\n * /usr/bin/ccextractor -- CCExtractor executable\n * /etc/ccr/ccr.ini -- Server application configuration file\n * /etc/ccr/db.ini -- Database connection configuration file\n * /var/www/ -- Web scripts\n * /etc/httpd/conf.d/ccr.conf -- Apache configuration file\n * /var/tmp/cce-input/ -- CCExtractor input pipes\n * /var/tmp/cce-output/ -- CCExtractor output files\n * /srv/web/ -- Server app -- web scripts buffer file\n * /srv/archive -- Received captions\nWhen you execute //ccr// command it does the following things:\n - Binds to specified port and accepts new client connections\n - For each accepted connection it forks a new process that handles client's data\n - Then it checks if client has send required packets such as password, description and BIN header.\n - If it did, adds this client to //clients// and //active_clients// tables in the database, otherwise it closes connection. Now it's ready to receive other client's data.\n - Forks CCExtractor and redirects received BIN data as the input and the output goes to ///var/tmp/cce-output/// directory\n - When CCExtractor starts to output closed captions, they are stored in:\n * ///srv/archive/// in TTXT, SRT and BIN formats. SRT is converted from TTXT by server application\n * the //programs// database table in TXT format\n * ///srv/web/// buffer files so that they can be viewed from web pages\n - Also server application is responsible for changing current program. It happens every 2 hours unless no EPG is supplied. In clients do sends EPG, then times when to change the current program is extracted from EPG events.\n - Every 3 seconds client and server sends each other keep-alive packets and close connection if they doesn't receive them for 20 sec. Server stores the timestamp of the last received keep-alive packet in //active_clients// table. It's for the case when magic happens and connection is not closed gracefully so that watchdog can remove it.\n - When connection is closed, the client is removed from //active_clients// table and its temporary files are removed form the file system\n","link":"https://ccextractor.org/public/gsoc/repository_architecture/","title":""},{"body":"Connecting to the server There main program that can be used to connect to repository server is CCExtractor. You'll need to use the following options to specify input stream, server address and and some stream information:\n - Input options:\n * **-** or **-stdin** to read video stream from standard input\n * **-s** or **--stream** to read a file that continuously growing\n * **-udp port** to read video stream from UDP port\n - Server connection:\n * **-sendto host:port** server address and port\n * **-tcpdesc description** description of what you are sending (e.g. tv station name or file name). If it isn't set, then repository will show your IP as description\n * **-tcppassword password** the password to use when connecting to repository server\nFor example, tail -f stream.ts | ccextractor -stdin -sendto example.com:3030 -tcpdesc \u0026quot;ABC\u0026quot;\nwill tell CCExtractor to read from standard input and to send captions to example.com at 3030 port with \u0026quot;ABC\u0026quot; description. Instead //tail -f stream.ts//, of course, can be any program that output video stream to standard output (stdout).\nSending a stream from HDHomeRun tuners This chapter will describe how to use //hdhomerun_config// tool to send captions to the repository. Make sure that you have it installed and working.\n - First, you'll need to pick a device ID by calling$ hdhomerun_config discover hdhomerun device 131F1846 found at 10.0.1.197 So, the device we are going to use has 131F1846 id.\n - Use the following command to scan for channels$ hdhomerun_config 131F1846 scan /tuner0 scan.log\n - The output will be send to //scan.log// file, so you can grep it to find IDs of desired channel and program. Suppose, we you to send captions from \u0026quot;CNN\u0026quot; channel and you found the following lines in //scan.log//:SCANNING: 141000000 (us-irc:17, us-cable:17) LOCK: qam256 (ss=100 snq=100 seq=100) TSID: 0x0000 PROGRAM 2101: 24 CSPAN (encrypted) PROGRAM 2102: 109 CSPN2 (encrypted) PROGRAM 2103: 51 APLw (encrypted) PROGRAM 2104: 72 TRVL WEST (encrypted) PROGRAM 2105: 483 TV One (encrypted) PROGRAM 2106: 216 NICK2 (encrypted) PROGRAM 2107: 56 CNN (encrypted) PROGRAM 2108: 80 GOLF (encrypted) PROGRAM 2109: 11 HSN (encrypted) PROGRAM 2110: 23 QVC (encrypted) PROGRAM 2111: 36 FX-W (encrypted) PROGRAM 2112: 57 HN (encrypted) PROGRAM 2113: 122 DISXD (encrypted) PROGRAM 2114: 46 LIF-W (encrypted) The number 17 (after //us-cable://) is the channel ID and the program id of \u0026quot;CNN\u0026quot; is 2107\n - Now you should tune tuner to this channel and filter CNN program:$ hdhomerun_config 131F1846 set /tuner0/channel 17 $ hdhomerun_config 131F1846 set /tuner0/program 2107\n - Finally, call the following command to send caption to the repository server:$ hdhomerun_config 131F1846 save /tuner0 - | ccextractor -stdin -quiet -sendto example.com:3030 -tcpdesc CNNThe first clause of this command shall send video stream to standard output and the second shall read it and send captions to example.com server with CNN description. //-quiet// option suppress CCExtractor output as it's sometimes messy, so all you'll see is dots printed every second by //hdhomerun_config// tool\nWorking with ATSC Digital TV This chapter describes how to send captions from ATSC transmission. Make sure that you have azap, dvbstream installed and working. More on these tools you can find at Linux TV\nSuppose the tuner is ///dev/dvb/adapter3/dvr0//, so its adapter number is 3 and scan file is located at //~/.azap/cahnnels.conf//.\n - Suppose you want to send captions from KOCE channel, and you found the following line in scan file:KOCE:129000000:QAM_256:512:0:2 It means that this channel is on 129000000 frequency and its program number in the stream is 2 (the last number in the line)\n - First, you should tune the tuner to this frequency by callingazap -a 3 -r KOCE There 3 is adapter number and KOCE is one of the channels on this freq.\n - The you should get a video stream from this channel and send to CCExtractordvbstream -f 129000000 -c 3 -o 8192 | ccextractor -stdin -pn 2 -quiet -sendto example.com:303 -tcpdesc KOCE The first clause will send video stream from 129000000 freq. from adapter #3 to the standart output without filtering (//-o 8192// option). Then CCExtractor will filter program #2 (//-pn 2// option) and send to example.com:3030 server.\nNote that in the guide above we didn't filter program using //dvbstream//, although it is possible. The reason for this is to show basic idea of scripts in //test/streaming// directory. These scripts allow you get multiple video streams from a single tuner and send them to the server. To do so, you have to:\n - Call //tunefreq.sh// script. It doesn't accept any arguments, so make sure that you set correct adapter, path to scan file variables inside it. This script will:\n - prompt frequency value to tune to and save this value in //freq// file\n - call //azap// to tune this frequency\n - output whole stream to //stream.ts// file in your working directory\n - //stream.ts// file will be truncated every 3 hours, so it won't grow too big\n - Then, from another shell you can call //ccsend.sh// script to send captions to the server. Also make sure that you edited variables in the beginning of file and set server address and scan file. This script will\n - prompt channel name to send to repository server\n - and output new content from //stream.ts// file to ccextractor\n - To test if channel has some closed captions before connecting it to the server, you can call //cctest.sh//. It works the same way, but output captions to standard output.\n","link":"https://ccextractor.org/public/gsoc/repository_clients/","title":""},{"body":"GSOC 2015 Evaluation You can find it working at http://web-1567166165.us-west-2.elb.amazonaws.com/view. Ask me personally for DNS name to connect the tuners.\nIt's working with 5 web server instances and 5 repository server app instances. It's been working for 4 days straight and 2 tuners reconnected 1 time. It's 24.08 now :)\nI've added 2 deployment guides for Amazon AWS and a guide on how to connect a client application. You call walk them thought to evaluate my project.\nMy plans regarding repository project:\n - Amazon AWS:\n - Figure out proper scaling policies. Right now scaling groups are static.\n - Although the tuners have reconnected only one time in the last 4 days, they shouldn't do it. Debugging this problems requires a lot of time\n - As load balancer creates two socket connections: client-LB and LB-instance, getnameinfo() always returns private IP which is useless.\n - Web pages:\n - Index page redesign. Most tuners doesn't have EPG, so there are a lot of empty space in the table. Probably, it'll be better to display the last CC last instead and update it dynamically.\n - PHP scripts refactoring: right now MVC pattern implementation is too general and routing stuff is messy.\n - JavaScript at the \u0026quot;view\u0026quot; page is also can be improved. Sometimes two columns overlapping each other when you remove horizontal split, it should be fixed.\n - Search should be case-insensitive. Also, it's better to add sorting and to display matches when searching by CC content.\n - Write proper docs when I finish web pages.\n - Server application:\n - Test client is a complete mess, I didn't change it from the last summer. Also I should add it to docs\n - Display function trace in error log. Although I'm not sure if it's possible :)\n - Log files rearranging. It will be convenient to displace instance IP in logs and to have separate log file for connected/disconnected clients.\n - Config files are not exactly in INI format although they have \u0026quot;.ini\u0026quot; extension. So I should change the way I parse them so that it fits INI specification\nContribution to blog I've been working on closed closed captions online repository. It consists of two main parts. The first one is a server application that is used for connecting CCExtractor instances which in their turn extracts closed captions from a video stream. The second part is a web site, that allows you to view captions in real-time i.e. as soon as they appear on TV screen. My task for this and a previous GSoC included everything from defining socket connection protocol to implementing web pages and deploying repository on a cluster.\n","link":"https://ccextractor.org/public/gsoc/repository_gsoc2015/","title":""},{"body":"Logging Repository server application can produce two log files for error and debug messages. The first one is used for logging errors that caused server to close connection or to terminate (such as \u0026quot;out of memory\u0026quot; errors). The second one is used for logging client activities and tracing system events. This log file is turned off by default.\nYou can logging behavior by changing these options:\n * **error-log** -- Path to error log file (default: /var/log/ccr-error.log)\n * **debug-log** -- Path to debug log file (default: /var/log/ccr-debug.log)\n * **verbose** -- If true, log messages will be printed to the file specified in *debug_log* (default: false).\n * **log-stderr** -- If true, all the log messages will be printed in standard output and no log files will be generated (default: false).\nLog levels Log messages are separated into the following levels:\n - FATAL -- errors that caused server to terminate\n - ERROR -- errors that caused server to close connection, but it is still able to accept new ones\n - WARNING -- warning messages like unexpected behavior or not implemented functions\n - INFO -- information about who connected and disconnected\n - DEBUG -- messages that are useful for development (including trace and blather)\n - NET -- messages on socket activities\nError log includes messages from FATAL, ERROR and WARNING levels. Debug log includes messages from all levels.\nLog format Each log line is formatted as follows: [time][level][who][where] message\n* **time** -- date and time when this line is being written to log file. Date format is specified byRFC5424 with the second precision\n * **level** -- message level described above\n * **who** -- identifies who caused this message\n * **S** -- server app itself\n * **id** -- client with specified id\n * **-1** -- client with unknown id\n * **where** -- if the level other than NET it contains filename and line in source code. If the level is NET, then on of following:\n * **S-\u0026gt;N** meaning that server send this message to client (i.e network)\n * **N\u0026lt;-S** meaning that server received this message from client\n * **message** -- the content of log line\n","link":"https://ccextractor.org/public/gsoc/repository_logs/","title":""},{"body":"Protocol specification This document describes transmission protocol between repository (server) and CCExtractor (client)\nTransmission units Client communicates with the server by sending packets of arbitrary length. In the source code they are called blocks, for some unknown reason :) These packets have the following syntax:\n - 1 byte -- Control command number -- defined protocol constant that represents packet's data\n - 10 bytes -- Packet's data length (N) -- string with decimal number \u0026gt;= 0 with leading zeroes that contains the size of packet payload.\n - N bytes -- packet payload -- packets' payload data\n - 2 bytes -- \\r\\n -- caret return and linefeed, representing the end of the packet\nThe packets control commands with their values that server accepts are listed bellow:\n - PASSWORD (2) -- the packet contains password data. It can be ignored if the server is configured with no password. But client still must supply this packet.\n - CC_DESC (4) -- the packet contains transmission description. Client is required to supply this packet even if end-user didn't specify one.\n - BIN_HEADER (5) -- the packet contains BIN header. Packets BIN_DATA and EPG_DATA are ignored until BIN_HEADER is supplied.\n - BIN_DATA (6) -- the packet contains BIN data that will processed to extract captions. This data is recognised according to presented earlier BIN_HEADER\n - EPG_DATA (7) -- the packet contains EPG data with following syntax\n - c-string (bytes ending with \\0) with start time in the \u0026quot;%Y%m%d%H%M%S %z\u0026quot; format\n - c-string with stop time in the \u0026quot;%Y%m%d%H%M%S %z\u0026quot; format\n - c-string with program title\n - c-string with program description\n - c-string with language\n - c-string with category\n - PING (55) -- keep-alive packet with no data\nIf the server receives packet with unknown control commands it shall close connection.\nServer communicates with client by sending 1 byte constants. These constants are:\n - ERROR (51) -- error happened on the server side so that it can not process client's data\n - PASSWORD (2) -- client supplied wrong password\n - PING (55) -- keep-alive constant\nClient should ignore commands that are not defined by the protocol.\nPackets transmission sequence  - After TCP connection is established, client must send these packets in specified order:\n - PASSWORD\n - CC_DESC\n - BIN_HEADER\n - Then, without waiting for server's responce client can send BIN_DATA, EPG_DATA and PING packets in arbitrary order.\n - In case client presented wrong password server closes connection and sends PASSWORD byte.\n - In case client didn't presented any required packets server closes connection and sends ERROR byte.\n - If client notices that connection is closes it can read the data left in socket buffer to get the reason why it's closed.\n - If an error occurs and server can no longer process clients' data, it shall send ERROR byte and close connection.\n - Every 3 seconds client is required to send PING packets. If server doesn't receives them in 20 sec, it closes connection without sending anything.\n - Every 3 seconds server is required to send PING packets. If client doesn't receives them in 20 sec, it may close connection and reconnect.\n","link":"https://ccextractor.org/public/gsoc/repository_protocol/","title":""},{"body":"Quick Installation Guide This is a guide for deploying repository on a single instance. For that we'll use Amazon EC2 Instance with Linux AMI 2015.03. Make sure that you opened 80, 22 and 3030 TCP ports, they will be used for Web access, SSH and to connect tv tuners.\n- First, you'll need to install packets required for compilation, Apache and MySQL servers:sudo yum localinstall -yhttp://repo.mysql.com/mysql-community-release-el6-5.noarch.rpm sudo yum install -y mysql-community-server sudo yum install -y git gcc mysql-devel httpd24 php56 php56-mysqlndFirst two command will install MySQL server of 5.6 version as current Amazon repo has 5.1 or something which won't work with this repository\n - Run MySQL server and run //mysql_secure_installation// to set root password and to remove the insecure features. Then make it run at each system bootsudo service mysqld start sudo mysql_secure_installation sudo chkconfig mysqld on\n- Download CCExtractor source code, compile and install it. The last command shall place ccextractor binary to /usr/bin/ directorygit clonehttps://github.com/CCExtractor/ccextractor cd ~/ccextractor/linux make sudo make install\n - Then clone git repository, compile and install itcd git clone https://github.com/rkuchumov/ccextractor-server cd ccextractor-server/ sudo make install\n - Create repository database and add tables:mysql -uroot \u0026lt;\u0026lt;\u0026lt; \u0026quot;CREATE DATABASE cc\u0026quot;; mysql -uroot cc \u0026lt; misc/tables.sqlIf you set root password for your database, make sure to set it using //--password=\u0026quot;pass\u0026quot;// argument\n - Install web pages by executing //web/install.sh// script:cd web/ sudo ./install.sh\n - Edit ///etc/ccr/db.ini// config file to set data base user, and password. This setting will be used by server applicationdb-user = \u0026quot;root\u0026quot; db-password = \u0026quot;pass\u0026quot; If you didn't set root password, leave //db-password// empty.\n - Edit the following lines in ///etc/httpd/conf.d/ccr.conf// to set database user and password for web pages:SetEnv CC_DB_USER cc_ro SetEnv CC_DB_PASSWORD cc-read-only-user-passwordSet CC_DB_USER variable to your db user name, i.e. //root// and set password in CC_DB_PASSWORD. If your db user doesn't have any password, just remove this line.\n - Edit ///etc/httpd/conf/httpd.conf// and set //DocumentRoot// variable to \u0026quot;/var/www/public\u0026quot;. In two places in the file. I'll fix it later :)\n - Start and enable Apache server:sudo service httpd start sudo chkconfig httpd on\n - Start and enable repository server application:sudo service ccr start sudo chkconfig ccr on\n - That's it. You can access CC Repository from web browser. To connect the tuner to it use CCExtractor with //-sendto// option. Servers will listen for connections on 3030 port. Received closed captions will be stored in ///srv/archive/// directory.\n","link":"https://ccextractor.org/public/gsoc/repository_quick_install/","title":""},{"body":"Roku reference channel Roku is currently the most common media streamer. It's cheap and neutral (it's not in any \u0026quot;fight\u0026quot;). Unfortunately, there aren't any good open source channels, so if you want to start your own you have to start from scratch. We want to fix that by creating the \u0026quot;reference\u0026quot; source code for a generic channel. We will send a free Roku to our student for development.\nWhat makes a good Roku channel?\nFor the playback itself Roku provides a basic system in which you have the usual things such as play/store, fast-forward and so on. But there's no default context menu, the progress bar is horrible and looks really bad...\nOrganization must be flexible and complete. Don't assume that things belong in just one place. For example you may want to have a section of Python tutorials, one of AI videos, one of videos in Spanish and so on. Of course there's videos that belong in all three places.\nThe home page must be well designed and pleasant to the eye. It must be easy to navigate.\nRecommendations, last played, search, settings, etc, must be easy to find and by themselves need to be good. Note that the recommendation themselves belong in a backend and you don't need to implement the actual backend: You need to implement the connection to such backend though.\nYou also need to support \u0026quot;activation\u0026quot;, which is the process in which the user links his Roku to an account existing in the system, for example to get access (case of a non-free channel) or custom recomendations.\nYour job is the Roku channel itself, but you must provide a backend skeleton at the very least to support all the channel features.\nQualification tasks\nTake a look at this page.\n","link":"https://ccextractor.org/public/gsoc/rokuchannel/","title":""},{"body":"TBD\n","link":"https://ccextractor.org/public/gsoc/rule-engine/","title":""},{"body":"Subtitle Downloader Technical Documentation This page contains how the service modules were coded and also how to add support for a new service.\nMain Module This module is responsible for detecting the type of service module to be used and calls the appropriate service module. A simple string search for the service name is done on the input URL to find the type of service. Errors are handled accordingly.\nHulu We first require the page source of the video. The function createSoupObject() is responsible for this. For this purpose we use the requests module. We parse the HTML with the help of BeautifulSoup library. The getTitle function returns the title of the video. This is also used for naming the file. The title is present in the Soup Object. Example -\nWe then require the contentID of the video. This is also available in the HTML Source. This is one of the methodologies to get the content ID. If this fails the alternative method will be called. In the Beautiful soup text it can be found that every video has this parameter.  \u0026quot;content_id\u0026quot;: \u0026quot;60535322\u0026quot;\nSo we first use '\u0026quot;'(quotes) as the delimiter and split the text. Then access the content ID from the returned list. The function getSmiSubtitlesLink returns the SMI subtitle link based on the contentID. The XML Link for any subtitle video is :\n http://www.hulu.com/captions.xml?content_id=CONTENTID\nIf multiple languages are present we give the user an option to enter their choice. We then convert the SMI URL to a VTT URL as follows - http://assets.huluim.com/captions/380/60601380_US_en_en.smi ---\u0026gt; http://assets.huluim.com/captions_webvtt/380/60601380_US_en_en.vtt Then the subtitles are converted from VTT to SRT format in the standard way.\nYouTube We first require the page source of the video. The function createSoupObject() is responsible for this. For this purpose we use the requests module. We parse the HTML with the help of BeautifulSoup library. The getTitle function returns the title of the video. This is also used for naming the file.\n VIDEO NAME - YouTube  The function getRawSubtitleLink returns the Raw Link which is in encoded format. This is still an incomplete URL. The variable UglyString contains the complete URL. The link is present in the BeautifulSoup. We now prompt the user to choose the desired language from the available choices. The available subtitle language choices are extracted from the UglyString. Based on the chosen language, the corresponding language code is indexed from the language dictionary. This language code is appended to the decoded Link. This final URL contains the subtitles as an XML file. Now, the XML file is converted to .srt file using BeautifulSoup function calls. Amazon The subtitle URL for Amazon is present in this URL -\n\u0026quot;PreURL\u0026quot;:\u0026quot;https://atv-ps.amazon.com/cdp/catalog/GetPlaybackResources?\u0026quot;,\n \u0026quot;asin\u0026quot; : \u0026quot;\u0026quot; ,\n \u0026quot;consumptionType\u0026quot; : \u0026quot;Streaming\u0026quot; ,\n \u0026quot;desiredResources\u0026quot; : \u0026quot;SubtitleUrls\u0026quot; ,\n \u0026quot;deviceID\u0026quot; : \u0026quot;b63345bc3fccf7275dcad0cf7f683a8f\u0026quot; ,\n \u0026quot;deviceTypeID\u0026quot; : \u0026quot;AOAGZA014O5RE\u0026quot; ,\n \u0026quot;firmware\u0026quot; : \u0026quot;1\u0026quot; ,\n \u0026quot;marketplaceID\u0026quot; : \u0026quot;ATVPDKIKX0DER\u0026quot; ,\n \u0026quot;resourceUsage\u0026quot; : \u0026quot;ImmediateConsumption\u0026quot; ,\n \u0026quot;videoMaterialType\u0026quot; : \u0026quot;Feature\u0026quot; ,\n \u0026quot;operatingSystemName\u0026quot; : \u0026quot;Linux\u0026quot; ,\n \u0026quot;customerID\u0026quot; : \u0026quot;\u0026quot; ,\n \u0026quot;token\u0026quot; : \u0026quot;\u0026quot; ,\n \u0026quot;deviceDrmOverride\u0026quot; : \u0026quot;CENC\u0026quot; ,\n \u0026quot;deviceStreamingTechnologyOverride\u0026quot; : \u0026quot;DASH\u0026quot; ,\n \u0026quot;deviceProtocolOverride\u0026quot; : \u0026quot;Https\u0026quot; ,\n \u0026quot;deviceBitrateAdaptationsOverride\u0026quot; : \u0026quot;CVBR,CBR\u0026quot; ,\n \u0026quot;titleDecorationScheme\u0026quot; : \u0026quot;primary-content\u0026quot;\nThe primary parameters we need to get are ASIN ID, customerID and TOKEN. These are obtained from the config file. The config file is generated from the setup.py file. The setup.py file takes the users login and password and generates the config file. The ASINID is taken from the URL directly.\n https://www.amazon.com/dp/B019DSWVYC/?autoplay=1\nNow, add the parameters to the dictionary and generate the final URL. The final URL will look something like this -\n https://atv-ps.amazon.com/cdp/catalog/GetPlaybackResources?\u0026amp;consumptionType=Streaming\u0026amp;titleDecorationScheme=primary-content\u0026amp;firmware=1\u0026amp;marketplaceID=ATVPDKIKX0DER\u0026amp;resourceUsage=ImmediateConsumption\u0026amp;deviceTypeID=AOAGZA014O5RE\u0026amp;videoMaterialType=Feature\u0026amp;token=6463643hhhdfhdhf7374747\u0026amp;deviceBitrateAdaptationsOverride=CVBR,CBR\u0026amp;operatingSystemName=Linux\u0026amp;deviceProtocolOverride=Https\u0026amp;deviceID=b63345bc3fccf7275dcad0cf7f683a8f\u0026amp;deviceStreamingTechnologyOverride=DASH\u0026amp;asin=B0141BACGU\u0026amp;desiredResources=SubtitleUrls\u0026amp;customerID=A1234GH2343\u0026amp;deviceDrmOverride=CENC\n \nThis is where the Subtitle URL is present. We get a JSON response from this URL and it contains a subtitle URL with .dfxp format. We request that subtitle URL and download the subtitles. With BeautifulSoup and Python regex we convert this dfxp to .srt format. (File - Amazon_XmlToSrt.py)\nBBC We first need to extract the episode ID from the URL. Sample URL -\n http://www.bbc.co.uk/iplayer/episode/p03rkqcv/shakespeare-lives-the-works\n \nThe episode ID is p03rkqcv. The episode PID and episode Title(for naming the file) are present in the URL -\n http://www.bbc.co.uk/programmes/\u0026lt;episode_id\u0026gt;.xml\nThe subtitle URL is present in the following link -\n http://open.live.bbc.co.uk/mediaselector/5/select/version/2.0/mediaset/pc/vpid/\nThe PID is nothing but the episode PID obtained above. There are multiple PID's present. So, we try all the URL's until the page request is successful. If the request is successful we get the subtitle link by parsing the XML page using Beautiful Soup. The subtitles obtained are in XML format. They are converted to .srt by using BeautifulSoup function calls and regex. The conversion takes place in the file Bbc_XmlToSrt.py\nCrunchyRoll This is one of the methodologies to get the subtitles ID. In the Beautiful soup text it can be found that every video has this parameter. \n Subtitles:    \n English (US),\n  \n العربية,\n  \n Italiano, \n  Deutsch\n \n \n ~~~ We need to obtain all the SSID's. We return all the id's as a list along with the respective Language title attached. For the above HTML we should have this - \\[\\['206027', 'English (US)'\\], \\['206015', 'العربية'\\], \\['206733', 'Italiano'\\], \\['206033', 'Deutsch'\\]\\] We prompt the user to choose the language and based on the choice, we append the ID from the list obtained above. A sample subtitle URL, where a script\\_id(206027) has been appended to the base URL :  https://www.crunchyroll.com/xml/?req=RpcApiSubtitle_GetXml\u0026amp;subtitle_script_id=206027\n \nThe encrypted subtitles are extracted from the above URL. The decryption of these subtitles has been taken from another Open Source software : youtube-dl.\nNetflix The user needs to input his username and password of Netflix in the userconfig.ini file. Netflix requires login to download the subtitles.\nWe use python-selenium browser to automate the process. The first step is to login to Netflix with the config file information. Chrome WebDriver is used as the driver for selenium. After a successful login from selenium browser, we request for the video URL. The chrome Network tab gives a list of resources fetched from the server. We use the command :\n return window.performance.getEntries();\nThis command returns all the fetched URL's. It was observed that all the Netflix videos had this sub-string in common and it was unique. /?o So we query for /?o and let the browser fetch the resources until we find such a URL. If we do not find the URL before the time out, we exit the application. If such a URL is found we save the URL and follow the standard procedure. We request the URL using requests module and save the file. The module //Netflix_XmlToSrt.py// is used to convert XML to .srt format.\nFOX We first require the page source of the video. The function createSoupObject() is responsible for this. For this purpose we use the requests module. We parse the HTML with the help of BeautifulSoup library.\nThe video URL follows a specific standard throughout. http://www.fox.com/watch/684171331973/7684520448 We need to split and return \u0026quot;684171331973\u0026quot;. This is the required contentID.\nThis is the alternative method to obtain the contentID. In the soup text there is a meta tag which also contains the video URL. This is helpful in case the user inputs a shortened URL.\n ~~~ As stated above we split the URL and return the require contentID, //684171331973// The other parameters required for obtaining the subtitle URL are also present in the HTML page source. The required script content looks like this- \n jQuery.extend(Drupal.settings, {\u0026quot;\u0026quot;:...............});\n ` *We add everything to a new string after encountering the first \u0026quot;{\u0026quot;.`\\ ` *Remove the last parentheses and the semi-colon to create a valid JSON. ---- ');'` The JSON has the standard format and the required parameters follow this naming. The json content : `{\u0026quot;foxProfileContinueWatching\u0026quot;:{\u0026quot;showid\u0026quot;:\u0026quot;empire\u0026quot;,\u0026quot;showname\u0026quot;:\u0026quot;Empire\u0026quot;},..............` `\u0026quot;foxAdobePassProvider\u0026quot;: {......,\u0026quot;videoGUID\u0026quot;:\u0026quot;2AYB18\u0026quot;}}` We use the json module to parse the json and extract the parameters namely //showid// , //showname// , //videoGUID// Sample Subtitle Links - ` `[`http://static-media.fox.com/cc/sleepy-hollow/SleepyHollow_3AWL18_660599363942.srt`](http://static-media.fox.com/cc/sleepy-hollow/SleepyHollow_3AWL18_660599363942.srt)\\ ` `[`http://static-media.fox.com/cc/sleepy-hollow/SleepyHollow_3AWL18_660599363942.dfxp`](http://static-media.fox.com/cc/sleepy-hollow/SleepyHollow_3AWL18_660599363942.dfxp) The standard followed is - ` `[`http://static-media.fox.com/cc/[showid]/showname_videoGUID_contentID.srt`](http://static-media.fox.com/cc/%5Bshowid%5D/showname_videoGUID_contentID.srt)\\ ` `[`http://static-media.fox.com/cc/[showid]/showname_videoGUID_contentID.dfxp`](http://static-media.fox.com/cc/%5Bshowid%5D/showname_videoGUID_contentID.dfxp) Some Subtitle URL's follow this standard - ` `[`http://static-media.fox.com/cc/[showid]/showname_videoGUID.dfxp`](http://static-media.fox.com/cc/%5Bshowid%5D/showname_videoGUID.dfxp)\\ ` `[`http://static-media.fox.com/cc/[showid]/showname_videoGUID.srt`](http://static-media.fox.com/cc/%5Bshowid%5D/showname_videoGUID.srt) So we store both URL's and check for both the varieties. We request both the varieties of URL and save the subtitles file when a successful request is returned. ### General rules Each service has a unique way of fetching the subtitles from the server. We can get to know the methodology by following some steps - ` *The easiest way is to first open the Developer tools in Chrome/Firefox and check for XHR requests. Generally we find the subtitle URL's here.`\\ ` *The next step is to find out a general pattern in the subtitle URL's of that particular service.`\\ ` *If a pattern is found, it is most likely that we can request the subtitle page by forming the URL's from the required parameters. `\\ ` *Generally, the parameters can be found in the HTML page source. We need to search for them and query the URL.`\\ ` *Sometimes the required parameters for the URL are found in some other links in JSON format. A quick check of the fetched JSON resources will reveal the availability of them.`\\ ` *For services such as Netflix, the parameters have some kind of hashing in them which is difficult to decrypt. In such cases we can use selenium browser and search for keywords like **.srt**, **.dfxp**, **cc**, **sub**`\\ ` *By checking for multiple videos we can find out common sub-strings in the subtitle URLs. These common sub-strings(have to be unique) can be used for querying the resources from selenium browser.`\\ ` *In most cases, the subtitle URL is fetched only if the user is logged in. So we first need to setup login and then go to the video URL in the WebDriver.`\\ ` *The subtitles can then be downloaded from the URLs. ` If you are a developer and want to add support for new services or fix bugs please feel free to send a pull request or contact me for further assistance. --------------------------------------------------------------------------------------------------------------------------------------------------------- ","link":"https://ccextractor.org/public/gsoc/subtitle_extractor_technical_docs/","title":""},{"body":"SwagLyrics-For-Spotify You can find the project at GitHub.\nYou can find a list of important issues here.\nGetting started / Requirements The software is written in Python, so we expect good knowledge of Python. Basic HTML, Javascript \u0026amp; CSS knowledge is also required. You should be able to demonstrate that you possess the skills to successfully implement your proposal.\nWe make use of quite some libraries to support all platforms, and we expect you to read up on the documentation of these platforms so you know how they work in general.\nQualification If you are interested in taking up this project during GSoC, you will need to satisfy these requirements (in order of importance, not all are a necessity): - A well researched, well written project proposal. - Proof you've set up SwagLyrics locally and can set up an instance of the issue-maker for development. - Fixed a bug, improved existing features, solved issues, ... (contributed something to the project). - Have chatted with the mentor(s) at least once.\nMentor(s) - Aadi Bajpai (@aadibajpai on Slack) is a former GCI winner (2017) and mentor (2018, 2019). He wrote the software and is the official (and currently sole) maintainer.\n","link":"https://ccextractor.org/public/gsoc/swaglyrics/","title":""},{"body":"Timeline ^ Start ^ End ^ What ^ Who ^ | April 27th | May 25th | Community bonding period *Complete personal information in this wiki *Prepare accounts for everyone in all systems *Synchronize plans | Everyone | | May 25th | | GSoC official date to start coding, initial payments. | Everyone | | May 25th | | CCExtractor bug hunting start. Fix as many issues as we can from GitHub's issue tracker before we start adding new features. Everyone must spend around one week on this as it will help a lot getting used to the code base. Veteran students are in charge of the most difficult bugs. | CCExtractor Devs. | | June 6th | | New CCExtractor release shipped. No new features, just bug fixes. | Carlos | | June 26th | July 3rd | gsoc/ Mid-terms evaluations | Everyone | | August 17th | | gsoc/ Soft pencil downs | Everyone | | August 21th | August 28th| gsoc/ Firm pencil downs, final evaluations | Everyone |\n","link":"https://ccextractor.org/public/gsoc/timeline/","title":""},{"body":"Vote counter and reporter Introduction\nYes, we've just seen it again in Iowa, but it's not really a new thing or a new need: Use of electronic voting, counting and reporting is becoming the norm, and so are the problems and lack of trust in the process.\nWe need to do something.\nYour job\nYour job is to design and implement an universal tool that can be trusted by everybody to help with voting, counting and reporting in any election.\nUniversal means that it be made to work (with configuration of course) for any kind of voting or election, be it for a party candidate for a major election to a simple class delegate at your university.\nTrust will come from its open source nature which makes the code auditable.\nVoting means that your system can be used by the voters to well, vote. This is probably the hardest part to get right as you need to somehow verify the voters identity.\nCounting means that for those elections (which are probably all the political ones) in which the votes are counted after everybody has votes it must be possible for the people that are doing the counting to update their counts in real time and most importantly compare their counts in real time: The way it works, at least in some countries, is that after the electoral place closes, the ballot box is opened and the counting starts. That counting is done by several people (possibly selected randomly from the registered voters) but there are interested parties (such as party representatives) verifying that everything is done correctly. Those representatives of course are also keeping their own tallies, and at the end of the counting they must match the official count.\nIt goes in the interest of the process that everybody involved can see the official tally and everybody's else.\nReporting means that after the counting is over the results can be reported to different places: Depending on who is doing the counting (meaning the user of you application) that reporting will go to their party, to the press, to an \u0026quot;upstream\u0026quot; counting place, or several or those at the same time.\nYour system will have a mobile frontend that must be written in Flutter (which generates Android and iOS native aps).\nIt will also have a backend that can be written in anything, but it must be scalable. For example, a PHP backend is a non-starter. Think of using a massively scalable cloud service as the core of your backend. Remember that your application will have an extremely high usage during a short period of time and then it's over.\nInteresting read.\nFinally, this system is not supposed to replace paper. We need the paper trail. It's essential.\nQualification tasks\nTake a look at this page.\nYour proposal should also include reports regarding scalability and fault tolerance of your chosen tech stack. A list of stacks and their performance comparison for the same application can be made from RealWorld.io\n","link":"https://ccextractor.org/public/gsoc/votecounter/","title":""},{"body":"Welcome This is CCExtractor's GSOC 2015 Wiki.\nRed Hen has another document system (generic, not GSoC-specific), please ask Mark or Francis for access. It is fine to create Red Hen pages here (by anyone) if it's found to be more convenient.\nAbout this wiki:\n Anyone with access can edit existing pages and create new ones. It is expected to contain all relevant information. If it's not here it doesn't exist :-) It will eventually contain sensitive information (such as passwords), therefore make sure your own access credentials to the wiki are not shared with 3rd parties. We use dokuwiki. It's quite easy to use, but you should check out its documentation before you start editing.  DEPRECATED, WE USE HUGO AND GITHUB PAGES NOW  ","link":"https://ccextractor.org/public/gsoc/welcome_to_summer_of_code_2015/","title":""},{"body":"Please visit Welcome to Summer of Code 2015 :-) it's still relevant.\n","link":"https://ccextractor.org/public/gsoc/welcome_to_summer_of_code_2016/","title":""},{"body":"Enable automated testing on windows and other general sample platform improvements\nThe sample platform has been a good way to test regression tests, but still lacks windows support. It's been foreseen, but unfinished. It should be finished, so we can ensure it's working both on Linux and Windows. Besides that, there are some things that need to be finished. This task thus encompasses:\na) Windows support b) FTP upload support c) Improved error detection d) Other small listed improvements on the issue tracker\n","link":"https://ccextractor.org/public/gsoc/windowstesting/","title":""},{"body":"~~META: title = Google Summer of Code 2017 - Do word by word subtitle-audio sync ~~\nDo word by word subtitle-audio sync\nThe usual subtitles files, such as .srt, do a line by line sync - meaning the subtitles appear when the person starts talking, says a few words, then the line disappears and a new one appears, etc.\n1 00:02:17,440 --\u0026gt; 00:02:20,375 Senator, we're making our final approach into Coruscant.\nIn this .srt example, at minute 2, second 17 those two lines of text appear and then they disappear at 2:20.\nThe task is to tag each individual word as is being spoken. This implies audio analysis. While in principle it doesn't seem terrible hard (since you just need to distinguish between individual words for which you at least have an ordered list) keep in mind that some times subtitles don't match audio 100%. For those words that do match, you need to provide a perfect audio-subtitle sync. For those words in the subtitle files that don't appear in the audio (this is a corner, yet possible, case) add some indicator. Finally for those words in the audio that don't appear in the subtitles, add a different indicator.\nFocus on the challenging parts of the project, which is the sync itself. You can assume that the subtitle format is always .srt and don't deal with additional formats, since conversion tools exists. Similarly, you can assume that the audio is a .wav file and forget about dealing with video formats. FFmpeg can deliver a raw wav from almost any stream which is more than enough.\nThe solution needs to work in real time, meaning that it must be possible to pipe the subtitles and audio data into your program and get the word-by-word sync'ed version has it happens. So things like double pass are out of the question.\nAs a suggestion, take a look at this. You don't have to use it (you can if you want), but it's worth checking out for ideas and concepts.\n","link":"https://ccextractor.org/public/gsoc/wordbywordsync/","title":""},{"body":"DokuWiki  DokuWiki is a simple to use and highly versatile Open Source wp\u0026gt;wiki software that doesn't require a database. It is loved by users for its clean and readable wiki:syntax. The ease of maintenance, backup and integration makes it an administrator's favorite. Built in access controls and authentication connectors make DokuWiki especially useful in the enterprise context and the large number of doku\u0026gt;plugins contributed by its vibrant community allow for a broad range of use cases beyond a traditional wiki.\nRead the DokuWiki Manual to unleash the full power of DokuWiki.\nDownload DokuWiki is available at https://download.dokuwiki.org/\nRead More All documentation and additional information besides the syntax description is maintained in the DokuWiki at www.dokuwiki.org.\nAbout DokuWiki\n*A`` ``feature`` ``list :!:\n*Happy`` ``Users\n*Who`` ``wrote`` ``about`` ``it\n*What`` ``Bloggers`` ``think\n*Compare`` ``it`` ``with`` ``other`` ``wiki`` ``software\nInstalling DokuWiki\n*System`` ``Requirements\n*Download`` ``DokuWiki :!:\n*Change`` ``Log\n*How`` ``to`` ``install`` ``or`` ``upgrade :!:\n*Configuration\nUsing DokuWiki\n*Wiki`` ``Syntax\n*The`` ``manual :!:\n*Frequently`` ``Asked`` ``Questions`` ``(FAQ)\n*Glossary\nCustomizing DokuWiki\n*Tips`` ``and`` ``Tricks\n*How`` ``to`` ``create`` ``and`` ``use`` ``templates\n*Installing`` ``plugins\n*Development`` ``Resources\nDokuWiki Feedback and Community\n*Subscribe`` ``to`` ``the`` ``newsletter :!:\n*Join`` ``the`` ``mailing`` ``list\n*Check`` ``out`` ``the`` ``user`` ``forum\n*Talk`` ``to`` ``other`` ``users`` ``in`` ``the`` ``IRC`` ``channel\n*Submit`` ``bugs`` ``and`` ``feature`` ``wishes\n*Some`` ``humble`` ``thanks\nCopyright 2004-2020 (c) Andreas Gohr \u0026lt;andi@splitbrain.org\u0026gt;((Please do not contact me for help and support -- use the doku\u0026gt;mailinglist or forum instead)) and the DokuWiki Community\nThe DokuWiki engine is licensed under GNU General Public License Version 2. If you use DokuWiki in your company, consider donating a few bucks ;-).\nNot sure what this means? See the FAQ on the Licenses.\n","link":"https://ccextractor.org/wiki/dokuwiki/","title":""},{"body":"Formatting Syntax doku\u0026gt;DokuWiki supports some simple markup language, which tries to make the datafiles to be as readable as possible. This page contains all possible syntax you may use when editing the pages. Simply have a look at the source of this page by pressing \u0026quot;Edit this page\u0026quot;. If you want to try something, just use the playground page. The simpler markup is easily accessible via quickbuttons, too.\nBasic Text Formatting DokuWiki supports bold, //italic//, __underlined__ and monospaced texts. Of course you can __//combine//__ all these.\nDokuWiki supports **bold**, //italic//, __underlined__ andmonospaced texts.\n Of course you can **__//combine//__** all these.\nYou can use ~subscript~ and ^superscript^, too.\nYou can use~subscript~and^superscript^, too.\nYou can mark something as deleted as well.\nYou can mark something asdeleted as well.\nParagraphs are created from blank lines. If you want to force a newline without a paragraph, you can use two backslashes followed by a whitespace or the end of line.\nThis is some text with some linebreaks Note that the two backslashes are only recognized at the end of a line or followed by a whitespace this happens without it.\n This is some text with some linebreaks\\\\ Note that the\n two backslashes are only recognized at the end of a line\\\\\n or followed by\\\\ a whitespace \\\\this happens without it.\nYou should use forced newlines only if really needed.\nLinks DokuWiki supports multiple ways of creating links.\nExternal External links are recognized automagically: http://www.google.com or simply www.google.com - You can set the link text as well: This Link points to google. Email addresses like this one: \u0026lt;andi@splitbrain.org\u0026gt; are recognized, too.\n DokuWiki supports multiple ways of creating links. External links are recognized\nautomagically:http://www.google.com or simply www.google.com - You can set\nlink text as well:This`` ``Link`` ``points`` ``to`` ``google. Email\n addresses like this one: \u0026lt;andi@splitbrain.org\u0026gt; are recognized, too.\nInternal Internal links are created by using square brackets. You can either just give a pagename or use an additional link text.\n Internal links are created by using square brackets. You can either just give\napagenameor use an additionallink`` ``text.\nWiki pagenames are converted to lowercase automatically, special characters are not allowed.\nYou can use some:namespaces by using a colon in the pagename.\nYou can usesome:namespaces by using a colon in the pagename.\nFor details about namespaces see doku\u0026gt;namespaces.\nLinking to a specific section is possible, too. Just add the section name behind a hash character as known from HTML. This links to this Section.\nThis links tothis`` ``Section.\nNotes:\n* Links toexisting`` ``pagesare shown in a different style fromnonexisting ones.\n* DokuWiki does not usewp\u0026gt;CamelCaseto automatically create links by default, but this behavior can be enabled in thedoku\u0026gt;config file. Hint: If DokuWiki is a link, then it's enabled.\n * When a section's heading is changed, its bookmark changes, too. So don't rely on section linking too much.\nInterwiki DokuWiki supports doku\u0026gt;Interwiki links. These are quick links to other Wikis. For example this is a link to Wikipedia's page about Wikis: wp\u0026gt;Wiki.\nDokuWiki supportsdoku\u0026gt;Interwiki links. These are quick links to other Wikis.\nFor example this is a link to Wikipedia's page about Wikis:wp\u0026gt;Wiki.\nWindows Shares Windows shares like this are recognized, too. Please note that these only make sense in a homogeneous user group like a corporate wp\u0026gt;Intranet.\nWindows Shares likethis are recognized, too.\nNotes:\n * For security reasons direct browsing of windows shares only works in Microsoft Internet Explorer per default (and only in the \u0026quot;local zone\u0026quot;).\n* For Mozilla and Firefox it can be enabled through different workaround mentioned in theMozilla`` ``Knowledge`` ``Base. However, there will still be a JavaScript warning about trying to open a Windows Share. To remove this warning (for all users), put the following line in conf/lang/en/lang.php(more details atlocalization): \u0026lt;code - conf/lang/en/lang.php\u0026gt;\n\u0026lt;?php /**\n* Customization of the english language file\n* Copy only the strings that needs to be modified\n*/\n$lang['js']['nosmblinks'] = ''; ~~~\nImage Links You can also use an image to link to another internal or external page by combining the syntax for links and images (see below) like this:\n \n\nPlease note: The image formatting is the only formatting syntax accepted in link names.\nThe whole image and link syntax is supported (including image resizing, internal and external images and URLs and interwiki links).\nFootnotes You can add footnotes ((This is a footnote)) by using double parentheses.\n You can add footnotes ((This is a footnote)) by using double parentheses.\nSectioning You can use up to five different levels of headlines to structure your content. If you have more than three headlines, a table of contents is generated automatically -- this can be disabled by including the string ~~NOTOC~~ in the document.\nHeadline Level 3 Headline Level 4 Headline Level 5  ==== Headline Level 3 ====\n === Headline Level 4 ===\n == Headline Level 5 ==\nBy using four or more dashes, you can make a horizontal line:\n Media Files You can include external and internal images, videos and audio files with curly brackets. Optionally you can specify the size of them.\nReal size:\nResize to given width:\nResize to given width and height((when the aspect ratio of the given width and height doesn't match that of the image, it will be cropped to the new ratio before resizing)):\nResized external image:\nReal size: \nResize to given width: \nResize to given width and height:\nResized external image: \nBy using left or right whitespaces you can choose the alignment.\n{{ wiki:dokuwiki-128.png}}\n{{ wiki:dokuwiki-128.png }}\n {{ wiki:dokuwiki-128.png}}\n \n {{ wiki:dokuwiki-128.png }}\nOf course, you can add a title (displayed as a tooltip by most browsers), too.\n{{ wiki:dokuwiki-128.png |This is the caption}}\n {{ wiki:dokuwiki-128.png |This is the caption}}\nFor linking an image to another page see #Image Links above.\nSupported Media Formats DokuWiki can embed the following media formats directly.\n| Image | gif, jpg, png | | Video | webm, ogv, mp4 | | Audio | ogg, mp3, wav | | Flash | swf |\nIf you specify a filename that is not a supported media format, then it will be displayed as a link instead.\nBy adding ?linkonly you provide a link to the media without displaying it inline\n \nThis is just a link to the image.\nFallback Formats Unfortunately not all browsers understand all video and audio formats. To mitigate the problem, you can upload your file in different formats for maximum browser compatibility.\nFor example consider this embedded mp4 video:\n \nWhen you upload a video.webm and video.ogv next to the referenced video.mp4, DokuWiki will automatically add them as alternatives so that one of the three files is understood by your browser.\nAdditionally DokuWiki supports a \u0026quot;poster\u0026quot; image which will be shown before the video has started. That image needs to have the same filename as the video and be either a jpg or png file. In the example above a video.jpg file would work.\nLists Dokuwiki supports ordered and unordered lists. To create a list item, indent your text by two spaces and use a * for unordered lists or a - for ordered ones.\n * This is a list\n * The second item\n * You may have different levels\n * Another item\n - The same list but ordered\n - Another item\n - Just use indention for deeper levels\n - That's it\n  * This is a list\n * The second item\n * You may have different levels\n * Another item\n - The same list but ordered\n - Another item\n - Just use indention for deeper levels\n - That's it\n Also take a look at the [FAQ on list items](doku\u0026gt;faq:lists). ##### Text Conversions DokuWiki can convert certain pre-defined characters or strings into images or other text or HTML. The text to image conversion is mainly done for smileys. And the text to HTML conversion is used for typography replacements, but can be configured to use other HTML as well. #### Text to Image Conversions DokuWiki converts commonly used [wp\\\u0026gt;emoticons](wp\u0026gt;emoticon) to their graphical equivalents. Those [doku\\\u0026gt;Smileys](doku\u0026gt;Smileys) and other images can be configured and extended. Here is an overview of Smileys included in DokuWiki: ` * 8-) %% 8-) %%`\\ ` * 8-O %% 8-O %%`\\ ` * :-( %% :-( %%`\\ ` * :-) %% :-) %%`\\ ` * =) %% =) %%`\\ ` * :-/ %% :-/ %%`\\ ` * :-\\ %% :-\\ %%`\\ ` * :-? %% :-? %%`\\ ` * :-D %% :-D %%`\\ ` * :-P %% :-P %%`\\ ` * :-O %% :-O %%`\\ ` * :-X %% :-X %%`\\ ` * :-| %% :-| %%`\\ ` * ;-) %% ;-) %%`\\ ` * ^_^ %% ^_^ %%`\\ ` * :?: %% :?: %%`\\ ` * :!: %% :!: %%`\\ ` * LOL %% LOL %%`\\ ` * FIXME %% FIXME %%`\\ ` * DELETEME %% DELETEME %%` #### Text to HTML Conversions Typography: [DokuWiki](DokuWiki) can convert simple text characters to their typographically correct entities. Here is an example of recognized characters. -\\\u0026gt; \\\u0026lt;- \\\u0026lt;-\\\u0026gt; =\\\u0026gt; \\\u0026lt;= \\\u0026lt;=\\\u0026gt; \\\u0026gt;\\\u0026gt; \\\u0026lt;\\\u0026lt; \\-- \\-\\-- 640x480 (c) (tm) (r) \u0026quot;He thought 'It's a man's world'\\...\u0026quot; `-\u0026gt; \u0026lt;- \u0026lt;-\u0026gt; =\u0026gt; \u0026lt;= \u0026lt;=\u0026gt; \u0026gt;\u0026gt; \u0026lt;\u0026lt; -- --- 640x480 (c) (tm) (r)` `\u0026quot;He thought 'It's a man's world'...\u0026quot;` The same can be done to produce any kind of HTML, it just needs to be added to the [pattern file](doku\u0026gt;entities). There are three exceptions which do not come from that pattern file: multiplication entity (640x480), 'single' and \u0026quot;double quotes\u0026quot;. They can be turned off through a [config option](doku\u0026gt;config:typography). ##### Quoting Some times you want to mark some text to show it's a reply or comment. You can use the following syntax: \u0026lt;code\u0026gt; I think we should do it \\\u0026gt; No we shouldn't \\\u0026gt;\\\u0026gt; Well, I say we should \\\u0026gt; Really? \\\u0026gt;\\\u0026gt; Yes! \\\u0026gt;\\\u0026gt;\\\u0026gt; Then lets do it! ~~~ I think we should do it \\\u0026gt; No we shouldn't \\\u0026gt;\\\u0026gt; Well, I say we should \\\u0026gt; Really? \\\u0026gt;\\\u0026gt; Yes! \\\u0026gt;\\\u0026gt;\\\u0026gt; Then lets do it! ##### Tables DokuWiki supports a simple syntax to create tables. \\^ Heading 1 \\^ Heading 2 \\^ Heading 3 \\^ | Row 1 Col 1 | Row 1 Col 2 | Row 1 Col 3 | | Row 2 Col 1 | some colspan (note the double pipe) || | Row 3 Col 1 | Row 3 Col 2 | Row 3 Col 3 | Table rows have to start and end with a *|* for normal rows or a *\\^* for headers. ` ^ Heading 1 ^ Heading 2 ^ Heading 3 ^`\\ ` | Row 1 Col 1 | Row 1 Col 2 | Row 1 Col 3 |`\\ ` | Row 2 Col 1 | some colspan (note the double pipe) ||`\\ ` | Row 3 Col 1 | Row 3 Col 2 | Row 3 Col 3 |` To connect cells horizontally, just make the next cell completely empty as shown above. Be sure to have always the same amount of cell separators! Vertical tableheaders are possible, too. | \\^ Heading 1 \\^ Heading 2 \\^ \\^ Heading 3 | Row 1 Col 2 | Row 1 Col 3 | \\^ Heading 4 | no colspan this time | | \\^ Heading 5 | Row 2 Col 2 | Row 2 Col 3 | As you can see, it's the cell separator before a cell which decides about the formatting: ` | ^ Heading 1 ^ Heading 2 ^`\\ ` ^ Heading 3 | Row 1 Col 2 | Row 1 Col 3 |`\\ ` ^ Heading 4 | no colspan this time | |`\\ ` ^ Heading 5 | Row 2 Col 2 | Row 2 Col 3 |` You can have rowspans (vertically connected cells) by adding *%%:::%%* into the cells below the one to which they should connect. \\^ Heading 1 \\^ Heading 2 \\^ Heading 3 \\^ | Row 1 Col 1 | this cell spans vertically | Row 1 Col 3 | | Row 2 Col 1 | ::: | Row 2 Col 3 | | Row 3 Col 1 | ::: | Row 2 Col 3 | Apart from the rowspan syntax those cells should not contain anything else. ` ^ Heading 1 ^ Heading 2 ^ Heading 3 ^`\\ ` | Row 1 Col 1 | this cell spans vertically | Row 1 Col 3 |`\\ ` | Row 2 Col 1 | ::: | Row 2 Col 3 |`\\ ` | Row 3 Col 1 | ::: | Row 2 Col 3 |` You can align the table contents, too. Just add at least two whitespaces at the opposite end of your text: Add two spaces on the left to align right, two spaces on the right to align left and two spaces at least at both ends for centered text. \\^ Table with alignment \\^\\^\\^ | right| center |left | |left | right| center | | xxxxxxxxxxxx | xxxxxxxxxxxx | xxxxxxxxxxxx | This is how it looks in the source: ` ^ Table with alignment ^^^`\\ ` | right| center |left |`\\ ` |left | right| center |`\\ ` | xxxxxxxxxxxx | xxxxxxxxxxxx | xxxxxxxxxxxx |` Note: Vertical alignment is not supported. ##### No Formatting If you need to display text exactly like it is typed (without any formatting), enclose the area either with *%%%%'' tags or even simpler, with double percent signs ''\\\u0026lt;nowiki\\\u0026gt;%%*. This is some text which contains addresses like this: http://www.splitbrain.org and **formatting**, but nothing is done with it. The same is true for %%//\\_\\_this\\_\\_ text// with a smiley ;-)%%. ` `\\ ` This is some text which contains addresses like this: http://www.splitbrain.org and **formatting**, but nothing is done with it.`\\ ` `\\ ` The same is true for %%//__this__ text// with a smiley ;-)%%.` ##### Code Blocks You can include code blocks into your documents by either indenting them by at least two spaces (like used for the previous examples) or by using the tags *%%\u0026lt;code\u0026gt;%%* or *%%\u0026lt;file\u0026gt;%%*. ` This is text is indented by two spaces.` `This is preformatted code all spaces are preserved: like \u0026lt;-this` \u0026lt;file\u0026gt; This is pretty much the same, but you could use it to show that you quoted a file. \u0026lt;/file\u0026gt; Those blocks were created by this source: ` This is text is indented by two spaces.` ` `\u0026lt;code\u0026gt;\\ ` This is preformatted code all spaces are preserved: like \u0026lt;-this`\\ ` `~~~ ` `\u0026lt;file\u0026gt;\\ ` This is pretty much the same, but you could use it to show that you quoted a file.`\\ ` `\u0026lt;/file\u0026gt; #### Syntax Highlighting [wiki:DokuWiki](wiki:DokuWiki) can highlight sourcecode, which makes it easier to read. It uses the [GeSHi](http://qbnz.com/highlighter/) Generic Syntax Highlighter \\-- so any language supported by GeSHi is supported. The syntax uses the same code and file blocks described in the previous section, but this time the name of the language syntax to be highlighted is included inside the tag, e.g. *\\\u0026lt;code java\\\u0026gt;* or *\\\u0026lt;file java\\\u0026gt;*. \u0026lt;code java\u0026gt; /** `* The HelloWorldApp class implements an application that`\\ `* simply displays \u0026quot;Hello World!\u0026quot; to the standard output.`\\ `*/` class HelloWorldApp { ` public static void main(String[] args) {`\\ ` System.out.println(\u0026quot;Hello World!\u0026quot;); //Display the string.`\\ ` }` } ~~~ The following language strings are currently recognized: //4cs 6502acme 6502kickass 6502tasm 68000devpac abap actionscript3 actionscript ada aimms algol68 apache applescript apt\\_sources arm asm asp asymptote autoconf autohotkey autoit avisynth awk bascomavr bash basic4gl batch bf biblatex bibtex blitzbasic bnf boo caddcl cadlisp ceylon cfdg cfm chaiscript chapel cil c\\_loadrunner clojure c\\_mac cmake cobol coffeescript c cpp cpp-qt cpp-winapi csharp css cuesheet c\\_winapi dart dcl dcpu16 dcs delphi diff div dos dot d ecmascript eiffel email epc e erlang euphoria ezt f1 falcon fo fortran freebasic freeswitch fsharp gambas gdb genero genie gettext glsl gml gnuplot go groovy gwbasic haskell haxe hicest hq9plus html html4strict html5 icon idl ini inno intercal io ispfpanel java5 java javascript jcl j jquery julia kixtart klonec klonecpp kotlin latex lb ldif lisp llvm locobasic logtalk lolcode lotusformulas lotusscript lscript lsl2 lua m68k magiksf make mapbasic mathematica matlab mercury metapost mirc mk-61 mmix modula2 modula3 mpasm mxml mysql nagios netrexx newlisp nginx nimrod nsis oberon2 objc objeck ocaml-brief ocaml octave oobas oorexx oracle11 oracle8 oxygene oz parasail parigp pascal pcre perl6 perl per pf phix php-brief php pic16 pike pixelbender pli plsql postgresql postscript povray powerbuilder powershell proftpd progress prolog properties providex purebasic pycon pys60 python qbasic qml q racket rails rbs rebol reg rexx robots roff rpmspec rsplus ruby rust sas sass scala scheme scilab scl sdlbasic smalltalk smarty spark sparql sql sshconfig standardml stonescript swift systemverilog tclegg tcl teraterm texgraph text thinbasic tsql twig typoscript unicon upc urbi uscript vala vbnet vb vbscript vedit verilog vhdl vim visualfoxpro visualprolog whitespace whois winbatch wolfram xbasic xml xojo xorg\\_conf xpp yaml z80 zxbasic// There are additional [advanced options](doku\u0026gt;syntax_highlighting) available for syntax highlighting, such as highlighting lines or adding line numbers. #### Downloadable Code Blocks When you use the *%%\u0026lt;code\u0026gt;%%* or *%%\u0026lt;file\u0026gt;%%* syntax as above, you might want to make the shown code available for download as well. You can do this by specifying a file name after language code like this: `\u0026lt;file php myexample.php\u0026gt;` `\u0026lt;?php echo \u0026quot;hello world!\u0026quot;; ?\u0026gt;` \u0026lt;/file\u0026gt; \\\u0026lt;file php myexample.php\\\u0026gt; \\\u0026lt;?php echo \u0026quot;hello world!\u0026quot;; ?\\\u0026gt; \u0026lt;/file\u0026gt; If you don't want any highlighting but want a downloadable file, specify a dash (*-*) as the language code: *%%\\\u0026lt;code - myfile.foo\\\u0026gt;%%*. ##### Embedding HTML and PHP You can embed raw HTML or PHP code into your documents by using the ''%% \u0026lt;html\u0026gt; \\%%'' or *%%\u0026lt;php\u0026gt;%%* tags. (Use uppercase tags if you need to enclose block level elements.) HTML example: \u0026lt;code\u0026gt; \u0026lt;html\u0026gt; This is some \u0026lt;span style=\u0026quot;color:red;font-size:150%;\u0026quot;\u0026gt;inline HTML\u0026lt;/span\u0026gt; \u0026lt;/html\u0026gt; \u0026lt;HTML\u0026gt; And this is some block HTML \u0026lt;/HTML\u0026gt;  This is some inline HTML   And this is some block HTML  PHP example:   echo 'The PHP version: '; echo phpversion(); echo ' (generated inline HTML)';   echo '\n  The same, but inside a block level element:  '; echo '  '.phpversion().'  '; echo '   ';  ~~~  echo 'The PHP version: '; echo phpversion(); echo ' (inline HTML)';   echo '\n  The same, but inside a block level element:  '; echo '  '.phpversion().'  '; echo '   ';  Please Note: HTML and PHP embedding is disabled by default in the configuration. If disabled, the code is displayed instead of executed.\nRSS/ATOM Feed Aggregation DokuWiki can integrate data from external XML feeds. For parsing the XML feeds, SimplePie is used. All formats understood by SimplePie can be used in DokuWiki as well. You can influence the rendering by multiple additional space separated parameters:\n^ Parameter ^ Description ^ | any number | will be used as maximum number items to show, defaults to 8 | | reverse | display the last items in the feed first | | author | show item authors names | | date | show item dates | | description| show the item description. If HTML is disabled all tags will be stripped | | nosort | do not sort the items in the feed | | //n//[dhm] | refresh period, where d=days, h=hours, m=minutes. (e.g. 12h = 12 hours). |\nThe refresh period defaults to 4 hours. Any value below 10 minutes will be treated as 10 minutes. wiki:DokuWiki will generally try to supply a cached version of a page, obviously this is inappropriate when the page contains dynamic external content. The parameter tells wiki:DokuWiki to re-render the page if it is more than //refresh period// since the page was last rendered.\nBy default the feed will be sorted by date, newest items first. You can sort it by oldest first using the reverse parameter, or display the feed as is with nosort.\nExample:\n \nControl Macros Some syntax influences how DokuWiki renders a page without creating any output it self. The following control macros are availble:\n^ Macro ^ Description | | %%~~NOTOC~~%% | If this macro is found on the page, no table of contents will be created | | %%~~NOCACHE~~%% | DokuWiki caches all output by default. Sometimes this might not be wanted (eg. when the %%%% syntax above is used), adding this macro will force DokuWiki to rerender a page on every call |\nSyntax Plugins DokuWiki's syntax can be extended by Plugins. How the installed plugins are used is described on their appropriate description pages. The following syntax plugins are available in this particular DokuWiki installation:\n~~INFO:syntaxplugins~~\n","link":"https://ccextractor.org/wiki/syntax/","title":""},{"body":"Welcome to your new DokuWiki Congratulations, your wiki is now up and running. Here are a few more tips to get you started.\nEnjoy your work with DokuWiki, -- the developers\nCreate your first pages Your wiki needs to have a start page. As long as it doesn't exist, this link will be red: :start.\nGo on, follow that link and create the page. If you need help with using the syntax you can always refer to the syntax page.\nYou might also want to use a sidebar. To create it, just edit the :sidebar page. Everything in that page will be shown in a margin column on the side. Read our FAQ on sidebars to learn more.\nPlease be aware that not all templates support sidebars.\nCustomize your Wiki Once you're comfortable with creating and editing pages you might want to have a look at the configuration settings (be sure to login as superuser first).\nYou may also want to see what plugins and templates are available at DokuWiki.org to extend the functionality and looks of your DokuWiki installation.\nJoin the Community DokuWiki is an Open Source project that thrives through user contributions. A good way to stay informed on what's going on and to get useful tips in using DokuWiki is subscribing to the doku\u0026gt;newsletter.\nThe DokuWiki User Forum is an excellent way to get in contact with other DokuWiki users and is just one of the many ways to get support.\nOf course we'd be more than happy to have you getting involved with DokuWiki.\n","link":"https://ccextractor.org/wiki/welcome/","title":""},{"body":"The sample platform was developed during GSoC '15 and overhauled during GSoC '16. In GSoC '17 another student added support for the Windows part, as well as some bugfixes. The student continued his work during GSoC '18, and will mentor this year. Last year a new student did some improvements and bugfixes.\nThis GCi edition we came to the conclusion that for new contributors, there are a bunch of drawbacks in the current system that make it no longer viable to continue to run the platform in it's current form.\nThe two main issues are: - Long runtime if a lot of commits/PR's are opened. This is because there is only one instance per OS available. - Unclear what the tests were being compared against. We should be able to have multiple approved versions and tell the user if the result deviates from those known ones.\nWith a lot of different cloud offerings available and the launch of GitHub actions we want to iterate on the design of the Sample Platform, moving the infrastructure from a single dedicated server to a scalable service that can cope with the variations in load.\nThis will need an upfront survey of the existing functionality, followed by discussions with the mentor on how to implement this.\nFeatures that will need to be implemented for certain are: - A coordinating platform that receives the call for actions, triggers the machines, displays results, ... - Scalable Linux/Mac/Windows machines that can execute the regression tests (currently 180GB of samples!) - Deep integration with the GitHub Actions that should be run first (creating Linux, Windows, Mac builds), so that no time is wasted if there are compiler errors or no code changes. - Watch this video. Disregard that it's about the Rust community - it's the CD/CI part on it that is important to us. That's what we want.\nGetting started / Requirements The Sample Platform is written in Python, so we expect good knowledge of Python. The new project is not necessarily python-based, but the choice should be made based on maintainability (unit testing) and availability of third-party API's and libraries.\nQualification If you are interested in taking up this project during GSoC, you will need to satisfy these requirements (in order of importance, not all are a necessity): - A well researched, well written project proposal. This should include a monthly cost prediction based on expected runtime's, disk storage used, ... A comparison between multiple providers (e.g. Azure, GCP, AWS, Packet) must be included. - Have chatted with the mentor(s) at least once. - Fixed a bug, improved installation documentation, ... (contributed something to the project). There are some issues in the tracker labeled issues labeled GSoC-proposal-task for this purpose. - Proof you've set up the Sample Platform locally.\nAdditional information not necessarily well organized :-)  For each sample we currently have one \u0026quot;good\u0026quot; output. That's not really correct. Changes in code might produce minor changes in the output (in the order of a few milliseconds). For each sample we'll need to have a set of correct outputs (possibly with a \u0026quot;correctness score\u0026quot;). - When a pull-request is checked, our system now reports the number of \u0026quot;broken\u0026quot; samples, meaning how many samples are producing an incorrect output according to our \u0026quot;good output\u0026quot; list. This however does not help much determining how the output changes for this specific PR. Instead, the system needs to report the difference between the code before and after the changes in the PR, which is much more useful. - We'll also need a way for final users to send test their own files against the current version so they don't need us to release a new CCExtractor version that could fix something that is broken for them. - It should be possible for users to get a binary compiled by the new system, particularly for Windows (in linux we don't have this problem since the typical way to install CCExtractor is just to build from source). Note that this build is already happening, so don't worry much if you have zero interest on Windows :-) You can use what we already have in order to build. - We currently run all the tests for each PR. This is overkill. Instead, we should have different sets of tests, for example \u0026quot;only MP4 files\u0026quot;, or only \u0026quot;teletext\u0026quot;, and so on, and the developer should be able to decide which tests he needs to run his PR on (or maybe none, for example if he just edited the help screen). - One of the reasons we're \u0026quot;going cloud\u0026quot; (as opposed to continue to run in one server) is the ability to scale and parallelize. It must be possible to check several PRs at the same time, different platforms, and so on. - We need to add a \u0026quot;regression finder\u0026quot; feature that works (and possibly uses) like git bisect: Give a specific sample find which specific commit changed the output.  Mentor(s)  Willem Van Iseghem (@canihavesomecoffee on Slack) is a former GSoC student (2014, 2015, 2016) and mentor (2017, 2018, 2019). He started the project and is the official maintainer.  ","link":"https://ccextractor.org/public/gsoc/sampleplatform/","title":" Google Summer of Code 2020 - The sample platform / Continuous integration revisited"},{"body":"CCExtractor Development is an informal (meaning we're not incorporated anywhere) organization that exists to coordinate the development efforts of the volunteers that contribute to the software and to manage our participation in specific events such as Google Summer of Code and Code-In.\nThe following video is a contribution from Manveer Singh Basra, a Code-In 2016 student:\n  ","link":"https://ccextractor.org/public/general/about_the_org/","title":"About CCExtractor Development"},{"body":"What can do you with Rust?\nWhy the Rust language is on the rise\nMy first impressions of Rust\nUseful reads From Python into Rust\ninto_rust() : Screencasts for learning Rust!\nStanford course on Rust\nComparing C and Rust network protocol exercises\nVectors and Hash Maps\nBig Data Benchmarks\nJourney to Async/Await\nRust once and share it with Android, iOS and Flutter \nProblems (hint: we use these resources ourselves for tasks) Thread on reddit\nRust examples and exercises\nPaid courses (we will buy them for students that get the rewards by doing tasks)\nRust in motion\n","link":"https://ccextractor.org/public/general/rust_resources/rust/","title":"About Rust"},{"body":"This page contains how the service modules were coded and also how to add support for a new service.\nModule Information ActivityExtractor.py This module is responsible for processing the parameters passed through the command line and calling the appropriate streaming service.\nIt passes the streaming service a dictionary containing credentials required to complete the process The dictionary is formatted like this:\n parameters = { 'url': self.url, 'email': self.email, 'password': self.password, 'user': self.user } url: The url the driver initially navigates to. email: The email required to log into the service. password: The password associated with the email. user: (Only required for Netflix) The profile name the user wishes to retrieve viewing activity from.\ncommon.py Contains modules common to all services.\noutput_activity(SERVICE, activity_list) Module to output activity into a .txt file. Accepts 2 parameters 'SERVICE' and 'activity_list': SERVICE: Name of the service calling the function. activity_list: List of viewing activity extracted from the streaming service.\nhulu.py Gets viewing activity from Hulu.\n get_activity() Called from the Main Module. It's main purpose is to initialize the process and call login_hulu()\n login_hulu() First this function creates an instance of Chrome and passes potential arguments to the driver. It then navigates to www.hulu.com and logs in with the user credentials. Then calls navigate_site()\n navigate_site() The main purpose of this function is to navigate to the 'History' page on Hulu.\nnavigate_pages() Depending on the length of the user's viewing history there may be multiple pages of viewing history. This function calls get_page_activity() for every page of viewing history. Then calls common.output_activity().\nget_page_activity() Gets all the viewing activity on the current viewing history page. Also displays a progress bar to the user.\namazon.py Gets viewing activity from Amazon.\nget_activity() Called from the Main Module. It's main purpose is to initialize the process and call login_amazon()\nlogin_amazon() First this function creates an instance of Chrome and passes potential arguments to the driver. It then navigates to https://www.amazon.com/gp/sign-in.html and logs in with the user credentials. It then navigates to the viewing history page by passing a url to the driver. Calls navigate_pages()\nnavigate_pages() Depending on the length of the user's viewing history there may be multiple pages of viewing history. This function calls get_page_activity() for every page of viewing history. Then calls common.output_activity().\nget_page_activity() Gets all the viewing activity on the current viewing history page.\nnetflix.py Gets viewing activity from Netflix.\nget_activity() Called from the Main Module. It's main purpose is to initialize the process and call login_netflix()\nlogin_amazon() First this function creates an instance of Chrome and passes potential arguments to the driver. It then navigates to https://www.netflix.com/Login and logs in with the user credentials. It then calls get_active_profile()\nget_active_profile() Selects user profile based on profile name present in parameters['user']. Calls navigate_site()\nnavigate_site() Calls hover_click() then clicks the 'Viewing Activity' link once hover_click() has navigated to the user's account page. Then calls scroll_to_bottom()\nhover_click() Hovers on the profile icon in the top right corner of the Netflix homepage. Then clicks on 'Your Account' on the dropdown menu that appears. Returns True or False depending on whether the process was successful.\nscroll_to_bottom() Depending on the length of the user's viewing activity Netflix displays only a portion of it. In order to have Netflix display the full list this function is called. Scrolls to the bottom of the page and waits for Netflix to load the next dynamic page of activity. This may be repeated multiple time until all of the activity is displayed. Calls get_page_activity()\nget_page_activity() Gets all viewing activity from the page. Displays a progress bar to the user. Calls common.output_activity()\nNew Service Instructions In order to add a new service to the platform, follow these steps.\nInstructions 1. Add your service and it's parameters to the file 'userconfig.ini'\nFollow this format when adding your service:\n[SERVICE_NAME] url = service_login_page_url email = test@email.com password = test\n2. Create a .py file for your service.\nTake a look at hulu.py, amazon.py or netflix.py as a reference. Your file must have a class containing all of the functions required to login and get viewing activity.\nThe class should be named like 'SERVICE_NAMEActivityExtractor'. Example: NetflixActivityExtractor Your class's init() function needs to accept an argument that will contain the parameters which ActivityExtractor.py will pass. Here is the general format:\n def __init__(self, parameters): self.parameters = parameters self.driver = None ... The main things your function should accomplish:\n Log into streaming service Navigate to viewing activity page Retrieve viewing activity Display progress bar (if possible) Call common.output_activity() to output viewing activity into a .txt file  common.output_activity() accepts 2 parameters. The first is the name of the viewing service, the second is a list containing all of the viewing activity. Make user to 'import common' to use the function.\n3. Add you service into ActivityExtractor.py.\nIn 'ActivityExtractor.py', create an import statement to import your service class from your service file. It should be something like this:\nfrom SERVICE_NAME import SERVICE_NAMEActivityExtractor\nNext you have to add your service into supported_services. In the ActivityExtractor, the init() function has a dictionary named 'self.supported_services'. Add your service into the dictionary following the format of the other services. It should look something like this:\n self.supported_services = { 'amazon': AmazonActivityExtractor, 'hulu': HuluActivityExtractor, 'netflix': NetflixActivityExtractor, 'SERVICE_NAME': SERVICENAMEActivityExtractor } 4. Test the program with your service and report any errors.\nIf your service worked successfully create a pull request to the repository and it'll be added. If any errors are thrown that you can't solve yourself, create an issue in the repository and we'll try helping you out.\n5. Add your service to this documentation page.\nContact Carlos to get login credentials for this page and add your service following the format of the other streaming services.\nFor bug fixes create an issue on the repository\n For any other inquiries contact me at m13basra@gmail.com  ","link":"https://ccextractor.org/public/codein/activity_extractor_technical_docs/","title":"Activity Extractor Technical Documentation"},{"body":"Our Google Summer of Code Students are hard at work, but they are also creative writers who document their journey and adventure while developing their projects. Here you can find many blog posts linking to their blog posts where they describe the process on how it is to work for CCExtractor and Google Summer Of Code\nGoogle Summer of Code 2020  Aadi Bajpai(@aadibajpai) is working on SwagLyrics  Google Summer of Code Phase 1   Pulkit Mishra(@pulkit) is doing Poor Man’s Rekognition  Google Summer of Code - Chronicles GSoC Chronicles — Only Time will Tell GSoC Chronicles — Best Kept Code    Google Summer of Code 2019  Artem Fedoskin(@thelastpolaris) with his project Poor Mans Rekognition  GSoC 2019 Starts! GSoC 2019 — Community Bonding Period  GSoC 2019 — Choosing the Right Structure GSoC 2019 — Choosing the Right License and building the DL Rig GSoC 2019 — Working on Face Detection GSoC 2019 — Facial Recognition and First Evaluations GSoC 2019 — Polishing Face Detection and working on Web App GSoC 2019 — Web App and Second Evaluations GSoC 2019 — Continuing Working on Web App *GSoC 2019 — Poor Man’s Rekognition   Amit Kumar(@pymit) working also on Poor Mans Rekognition  GSoC’19 with CCExtractor Development week 1 | GSoc’19 | CCExtractor Development week 2| GSoc’19 | CCExtractor Development week 3 | GSoC’19 | CCExtractor Development week 4 | GSoC’19 | CCExtractor Development week 5| GSoc’19 | CCExtractor Development week 6\u0026amp;7 | GSoC’19 | CCExtractor Development Final Phase | GSoC’19 | CCExtractor Development Final Work Submission | GSoC’19 | CCExtractor Development   Faiz Khan and Poor Mans Rekognition  Google Summer of Code.! 2019 (my story and opinion) Technical details of my project (Google summer of code) Week-1, Poor man Rekognition REPORT 1: 4th Week. Report 2 Upgrade Face and eye detection using OpenCV. Report 3 Report 4: FINAL   Sarfaraz Iraqui(@sziraqui) also with his project Poor Mans Rekognition:  Not The Normal GSoC Journey   Shivam Jha(@thealphadollar) is working on the Sample Platform  https://thealphadollar.github.io/experience/2019/05/17/gsoc19-0.html|    GSoC'19 [0]: Congratulations And Let's Begin]]\n Chris Wang has the goal of improving Swag Lyrics with autosynch  GSoC 2019 Phase 1: Vocal Isolation GSoC 2019 Phase 2: Hyphenation \u0026amp; Alignment GSoC 2019 Phase 3: Optimization   Suyash Bajpai is developing co-oCCur a High speed subtitle synchronization tool:  00: And now my watch begins!]] https://sypai.github.io/GSoC-00-Bonding-period-ends-\u0026amp;-Coding-begins-!|GSoC [01]: Bonding period ends \u0026amp; Coding begins! ]] https://sypai.github.io/GSoC-02-Basic-needs-fulfilled!|GSoC [02]: Basic needs fulfilled! ]] GSoC : Final Work Submission!    Chaitanya Bankanhal goal is to make a Web UI for Rclone  Google summer of Code ‘19 RClone WebUI PHASE I File Structure Overview for RClone WebUI React Creating a new widget   Mohsin Mustafa(@buoyantbird) project is Poor Man Rekognition:  First Evaluation Report Second Evaluation Report Final Evaluation Report    Google Summer of Code 2018  Archit Matur(@achie27) did work on FabBits  Building FabBits : GSoC with CCExtractor #1 Building FabBits : GSoC with CCExtractor #2 Building FabBits : GSoC with CCExtractor #3 Building FabBits : GSoC with CCExtractor #4 Building FabBits : GSoC with CCExtractor — Final   Shivam Jha(@thealphadollar) and Nephos  01: Fuel For The Fire]] 02: Making Bonds, And Breaking Codes]] 03: Building The Base]] 04: Writing Tests, Getting Evaluated!]] 05: What Works, Makes Me Jump]] 06: Making It Through Second Evaluations]] 07: Winding Up]]   Aaditya Nair and his work with Nephos  GSoC The Beginning GSOC Update Week 1 and Week 2 GSOC Update Week 3 and Week 4 GSOC Update Week 5 and Week 6 GSOC Update Week 7 and Week 8 GSOC Update Weeks 9, 10 and 11   Saurbah Shah with the aim to improve the OCR Subsystem  Selection in GSoC 2k18    ","link":"https://ccextractor.org/public/blog_posts_our_students/","title":"Blog Posts from our Students"},{"body":"Developed under Google Summer of Code, 2017 with CCExtractor Development By Saurabh Shrivastava\nBlog entry for final submission : (https://saurabhshri.github.io/gsoc-final-submission/)\n Introduction The usual subtitle files (such as SubRips) have line by line synchronisation in them i.e. the subtitles containing the dialogue appear when the person starts talking and disappears when the dialogue finishes. This continues for the whole video. For example :\n1274 01:55:48,484 -\u0026gt; 01:55:50,860 The Force is strong with this one\nIn the above example, the dialogue #1274 - The Force is strong with this one appears at 1:55:48 remains in the screen for two seconds and disappears at 1:55:50.\nThe aim of my GSoC project was to build a tool for word by word synchronisation of subtitles with audio present in the video by tagging each individual word as it is spoken, similar to that in karaoke systems. I have named my project CCAligner as it conveniently lays out it's basic functionality.\nE.g.\nThe [6948484:6948500] Force [6948501:6948633] is [6948634:6948710] strong [6948711:6949999] with [6949100:6949313]\nIn the above example each word from subtitle is tagged with beginning and ending timestamps based on audio.\n  CCAligner makes use of automatic speech recognition to analyse audio and recognise words to perform alignment. The project comprises of both user friendly tool and developer friendly API.\nProject Related Links   Project repository on Github: https://github.com/saurabhshri/CCAligner\n  Project readme : https://github.com/saurabhshri/CCAligner/blob/master/README.adoc\n  Project documentation : https://github.com/saurabhshri/CCAligner/blob/master/docs/\n  My blog (includes weekly GSoC posts) : https://saurabhshri.github.io\n  Milestones and deliverable checklist : https://saurabhshri.github.io/gsoc/\n  Project link on official GSoC web-app : https://summerofcode.withgoogle.com/projects/#5589068587991040\n  Project proposal : https://github.com/saurabhshri/saurabhshri.github.io/blob/master/GSoC/\n  Mentors : @cfsmp3 and @AlexBratosin2001\n  The project was built by me individually. All the external libraries and code used are credited wherever due.\nTechnical Documentation All the technical details are commented in the codes and the documentation is available in the readme of the repository (linked above). Code is properly commented and the variables, classes and other components are named properly in Camel Case for easier understanding of the code. Find compiling, installing, usage instructions and docs here :\n https://github.com/saurabhshri/CCAligner  Additional Work In addition to my main project, I also worked on creating a single header SubRip subtitle parser library in C++ and contributing to various open source projects, including, but not limited to CCExtractor, Sample-Platform, AutoEdit2, Rhubarb Lip Sync, CMUSphinx.\n Created a single header SubRip subtitle parser library in C++. This served as a core in CCAligner subtitle handling. It has very huge number of options available, and is very simple to use.    Project repository : https://github.com/saurabhshri/simple-yet-powerful-srt-subtitle-parser-cpp\n  Documentation : https://github.com/saurabhshri/CCAligner/tree/master/docs\n  Improving existing CCExtractor features, fixing issues and help in PR and code reviews.   All my commits to CCExtractor repository : https://github.com/CCExtractor/ccextractor/commits?author=saurabhshri  Improving CCExtractor's sample-platform, fixing and reporting issues, and help in PR and code reviews.   All my commits to Sample-Platform repository : https://github.com/canihavesomecoffee/sample-platform/commits?author=saurabhshri  Link to my Github profile : https://github.com/saurabhshri  Some Demostrations   Karaoke Demo 2 [Ted Talk]\n  Karaoke Demo 3 [Cartoon Show]\n  Karaoke Demo 4 [Discussion Video]\n  Transcription Demo [Reality Show]\n  Third party libraries and dependencies All the third party libraries are located in src/lib_ext and along with their individual licenses.\n  PocketSphinx : PocketSphinx is a lightweight speech recognition engine. It is portable and is used in ASR based alignment. (https://github.com/cmusphinx/pocketsphinx)\n  SphinxBase : Basic libraries as well as some common utilities for manipulating acoustic feature and audio files. This is used by PocketSphinx. (https://github.com/cmusphinx/sphinxbase)\n  srtparser.h : srtparser.h is a single header, simple and powerful C++ srt subtitle parsing library that allows to easily handle, process and manipulate srt subtitle files. (https://github.com/saurabhshri/simple-yet-powerful-srt-subtitle-parser-cpp)\n  webRTC : WebRTC is a free, open project that provides browsers and mobile applications with Real-Time Communications (RTC) capabilities via simple APIs. It is used to perform VAD in the project. (https://webrtc.org)\n  Known Issues / Future Work Needed The project is in it's very early stage and is constantly evolving. The available functions, usage instructions et cetera are expected to refactor over time. Feel free to contribute and improve the project. Currently, officially only US English is supported. For other languages and accents, a proper trained acoustic model could be supplied and experimented with. Text tokenisation within the program needs improvement. Feel free to raise any issue in the repository's issue tracker : https://github.com/saurabhshri/ccaligner/issues\nRead More More information and news related to project could be found at the links attached above and would be posted from time to time on my blog : https://saurabhshri.github.io\n","link":"https://ccextractor.org/public/gsoc/2017/saurabh/","title":"CCAligner : Word by Word Audio Subtitle Synchronisation"},{"body":"The first 1-2 weeks are to be spent fixing bugs and closing issues in GitHub. This applies to all CCExtractor students that are going to be working on the core tool (that's almost everyone). This serves some purposes:\n It's the best way to see first-hand what the problems are :-) It will let you get used to the code. It will give us a reliable version that is fun to work with  The following table should be populated before the start of the coding period. You can either select your own bugs (just edit the table and add yourself) or they can be assigned to you :-)\nThe veteran students (Anshul, Ruslan, Willem) are expected to do the hard ones unless someone else do them first.\nWhen you start working a bug please write it here. Don't wait until it's fixed to avoid the situation in which two people happen to work on the same thing unintentionally. Working on a bug and not being able to actually fix it is OK. Ask for help or discuss it in the mailing list so others can help you figure it out.\n   ID Details Who Status     136 Garbling in Tivo samples Ruslan Open   157 3 new samples that don't work Oleg Resolved   151 DVB subtitles from TNT (France) Oleg Support Required   158 CEA-708 is not supported at all for MP4 Oleg Resolved   172 alternate subtitles missing Oleg Support Required   284 Issues with ISDB (Brazil) support Abhinav Open   286 Missing subtitles in a Korean broadcast Abhinav Open   279 Can't extract DVB subtitles from a Spanish channel Abhinav Open   131 Seeking DVD using the IFO file Abhinav Open   139 Case fixing in teletext Abhinav Fixed   353 High Memory Consumption Abhinav Fixed   359 Teletext page number in -UCLA Abhinav Fixed   354 Excessive XDS Notices Shruti Fixed   285 No Preview in 0.78 and 0.79 Abhishek Resolved   304 Premature end of file. Abhishek Open   356 Premature end of file (2) Abhishek Open   315 File Flushing issue Abhishek Resolved   345 Ability to Rotate Files Abhishek Open   713 One out of two Korean DTV TS not showing output Siddharth Open    ","link":"https://ccextractor.org/public/gsoc/ccextractor_bug_hunt/","title":"CCExtractor bug hunt"},{"body":"Current version: 0.88 (May 21st, 2019)\nCCExtractor's source code\nCLI Source code full\nCLI Source code without Windows blobs (reduced size)\nWindows GUI Source code (Windows only; requires Visual Studio)\nCross platform GUI\nWindows binaries\nWindows binaries (just the GUI and the command line programs, without installation)\nWindows installer, first attempt with InstallShield - if it doesn't work just use the zipped binaries above\nNote: Starting with 0.84 we're bundling two binaries for the main program: With and without OCR. The reason is that the OCR (needed to convert the bitmap based European DVB subtitles into .srt, and also DVD) has its own dependencies, which may or may not be available in the user system. So if you don't need the OCR and don't feel like fighting with dependencies just use the non-OCR version which has no external dependencies and should work fine in everything from XP up.\nAbout the Windows installer, we used to generate .msi installers but that seems to be discontinued by Microsoft - Visual Studio generates them with an expired certificate which causes warnings. We've prepared a new installer using InstallShield. Please report issues if any. Things we are already aware of:\nIt doesn't check for NET 2.0 being present, because it's too old. However we're still targeting it because for now we don't need anything advanced and NET 2.0 works in XP. If you are wondering why we care about XP it's because it's the last OS that supports some ancient hardware that is still in use that cannot be replaced for a number of reasons. - It says \u0026quot;Unknown publisher\u0026quot;, because we currently don't have a code signing certificate. - You need to uninstall any previous version before installing, it cannot just update, even if all it would take is just to overwrite files.\nMac\nHomebrew package (3rd party, not maintained by the CCExtractor team)\nAdditional software written by the team\nUser Documentation for Subtitle Downloader \nUser Documentation for Activity Extractor \nCCAligner - Word by Word Audio Subtitle Synchronisation Tool and API\nDependencies\nVisual C++ Redistributable Packages for Visual Studio 2013 (this might be needed to run CCExtractor 0.70 and above in XP).\nDependencies for the full CCExtractor version (with FFmpeg, OCR, etc) (they are included in the distribution packages but we have them separately for convenience).\n","link":"https://ccextractor.org/public/general/downloads/","title":"CCExtractor downloads"},{"body":"In 2014 Willem wrote a nice tool that allows you to compare CCExtractor's output between versions to make sure code changes didn't break things. This tool has been expanded in t he past two years to cover more scenario's, as well as offering better integration.\nAll changes must be validated using this tool. As of 2016, it is fully integrated (using a webhook) with GitHub, so if you make a Pull Request, you should be able to see if you broke anything or not.\nPull Requests that break things severely won't be accepted (due to the way the test suite compares the results, minor changes in timing are also indicated as failures, while they don't necessarily have to be).\nGitHub integration As mentioned above, as part of GSoC 2016 a full integration was made with GitHub. This means that just as with other integrations, the regression test suite will now run automatically when you create a Pull Request or if you make a commit on the repository.\n When creating a pull request (PR), the next steps happen:\n Test get queued (another one might be running that needs to finish first) The platform kicks off the test suite: Your code gets locally merged with the current master branch The result is compiled The test suite runs the tests on the compiled binary  Several individual steps (preparation, building, compiling, ...) are being reported back to the PR on GitHub, while the detailed overview is available by clicking on the \u0026quot;details\u0026quot; (as can be seen in the image below):\n This link will take you to the detail page of the test, where you can check the status of the test in general, as well as the results for each category.\nHow to run your own tests on fork If you want to run your own tests on your fork commit with selected regression tests and platforms, Follow these steps:\n Ask for tester/contributor role from Willem. You can see your role here. After role access, link your github profile in Manage account page. You can run your own tests here. You have to enter commit hash of the fork repository.After that you need to select platforms and regression tests. Test Status is displayed on same page.  Obtaining individual regression samples If you are aware your coding changes are going to break a specific sample, you can always download the sample from the platform to test your code changes locally. This has the advantage that you can test faster, as the complete test suite takes about 30-60 minutes to complete.\nMedia-info for the samples is also available (both partially visible on the sample detail page, as fully visible after downloading).\nHow to use the testing tool manually If you have access to the dev server at gsocdev3.ccextractor.org, or have downloaded all the samples, you can run the test tool manually. This has the benefit that you can test just single categories, or specific samples only, whereas the GitHub integration does all the available tests.\nThe easiest way to test all the current samples against your own version of CCExtractor is using a shell script that does most of the work for you: /repository/newRepository/TestSuite/runAllTests CCExtractorLocation ReportLocation\nThe CCExtractorLocation is the location of your CCExtractor build that you want to test (against the latest official CCX version). The ReportLocation is optional (if omitted, the reports will be stored under your name in a subfolder of Willem's public_html folder).\nIf you want to have more configuration options, you can create your own config or test files (there is a sample config at /repository/newRepository/TestSuite/sampleconfig.xml and for a sample test file you can look in the folders), and then call the ccextractortester bash script (located at /repository/newRepository/TestSuite/ccextractortester) with the appropriate parameters.\nIf you want to know the available parameters that can be passed to the test suite, use the --help argument.\nBugs, requests, etc. are welcome on the GitHub page of the test suite: https://github.com/canihavesomecoffee/ccx_testsuite\n","link":"https://ccextractor.org/public/gsoc/ccextractor_regression_testing/","title":"CCExtractor regresssion testing / GitHub bot"},{"body":"This page is a compilation of the most important tasks from everyone's proposals. Those of you that are going to be working on the same things please talk among yourselves.\nAdd tasks and edit as needed.\nWe know that there were some proposals that included the exact same tasks. We preferred to pick the best students and not just the best proposals for each task. If you find yourself in a situation in which someone else is doing what you were planning to do, just replace that task with even a more interesting one :-) Don't get frustrated by this overlap. We are aware of it.\nGSOC 2016 tasks    Task Who Depends Planned dates Status Mentor notes     Preprocessing burned in white subtitles Abhinav  by Week 4 Done    Generating basic timed output files Abhinav  by Week 5 Done    Adding support for colored and styled hard subtitles Abhinav  by Week 7 In Progress    New user options and cascaded classifier Abhinav Working system for all types of subtitles by Week 10 In Progress    Test suite integration of Hardsubx Abhinav Completion of above tasks by Week 12 Not started     GSOC 2015 tasks    Task Who Depends Planned dates Status Mentor notes     Real time translation with Apertium Nurendra   Finished    Real time translation with Google Translate Nurendra   Finished    Statistics of Stock Prices and their dependence on Twitter-mentions, TV-mentions Nurendra Real time uploading (Ruslan)  Finished    Extension of test suite Willem   Finished (for now)    Sample submission and testing platform Willem   In progress    GitHub bot Willem   Finished (for now)    Complete support for EIA-708 Anshul   Not started    Implement Multi-Program Anshul   Complete    Multi-language Forced Alignment Sai   Not started    Real time translation with Google Translate Oleg   In Progress    Implement Multi-Program Oleg   Not started    Complete support for EIA-708 Oleg   Not started    Oleg: Please focus on Japanese support (and other non-Latin languages since Anshul will be finishing the decoder itself Linux GUI Oleg  Not started    Oleg: Anshul has already something started, please coordinate with him OSX GUI Oleg  Not started    Networking - server side Ruslan   Not started    Networking - client side Ruslan   Not started    Complete refactoring Ruslan   Not started    Commercial detection Vasanth   Finished     ","link":"https://ccextractor.org/public/gsoc/ccextractor_tasks/","title":"CCExtractor tasks"},{"body":"Developed under Google Summer of Code, 2018 with CCExtractor Development By Saurabh Shrivastava\nBlog entry for final submission :(https://saurabhshri.github.io/gsoc-2018-final-submission)\n Introduction The aim of the project is to create an easy to use web application that can be hosted on a web-server for subtitle extraction using CCExtractor. The idea is simple -- the users do not need to install CCExtractor on their own machine, they can directly use the web application to process their files anytime, anywhere. It would also serve as an easy interface for first-time developers (notably GSoC and GCI students) to experience the extraction process.\nThe high-level workflow for this project basically involves obtaining files from the user along with suitable parameters, passing them to the CCExtractor, processing the files, obtaining output file and making it available for download. Other things include, but is not limited to, user management, file management, record maintenance, multiple CCExtractor binary options, and API.\nProject Related Links   Project repository on Github: https://github.com/saurabhshri/ccextractor-web\n  Project readme : https://github.com/saurabhshri/ccextractor-web/blob/development/README.adoc\n  Project documentation : https://github.com/saurabhshri/ccextractor-web/blob/development/docs/\n  Project link on official GSoC web-app : https://summerofcode.withgoogle.com/projects/#5789900830408704\n  Mentors : @canihavesomecoffee and @alexbrt\n  The project was built by me individually with the invaluable help from my mentors. All the external libraries and code used are credited wherever due.\nTechnical Documentation All the technical details are commented in the codes and the documentation is available in the readme of the repository (linked above). Code is properly commented and the variables, classes and other components are named properly in CamelCase for easier understanding of the code. Find compiling, installing, usage instructions and docs here : https://github.com/saurabhshri/ccextractor-web\nKnown Issues / Future Work Needed The project is in its very early stage and is constantly evolving. The available functions, usage instructions et cetera are expected to refactor over time. Feel free to contribute and improve the project. Currently, files could only be uploaded from a user's file system. In future, I would like to add the capability to add files from cloud storage like Google Drive and add batch processing. Feel free to raise any issue in the repository's issue tracker : https://github.com/saurabhshri/ccextractor-web/issues\nRead More More information and news related to the project could be found at the links attached above and would be posted from time to time on my blog : https://saurabhshri.github.io\n","link":"https://ccextractor.org/public/gsoc/2018/saurabh/","title":"CCExtractor Web : A web application for subtitle extraction through CCExtractor."},{"body":"Welcome to CCExtractor CCExtractor Development is an informal (meaning we're not incorporated anywhere) organization that exists to coordinate the development efforts of the volunteers that contribute to the software and to manage our participation in specific events such as Google Summer of Code and Code-In.\nThis website is still in beta, you might come across formatting errors or pages not found. Please report them on slack.  To get in touch with us, join our slack channel. Most CCExtractor developers hang out in a slack team. You're welcome to request an invitation here  Read the DocsHere for GSoC'21?\n ","link":"https://ccextractor.org/","title":"CCExtractor's home page"},{"body":"CEA-708 is the latest standart for ATSC DTV closed captioning. DTVCC (DTV Closed Captions) decoding and output was improved by Oleg during this summer. Along with major refactoring, more control commands support was added. Now ccextractor can handle 16 bit encoded captions in DTVCC streams, so lots of non-latin languages symbols could be extracted. Output to popular subtitles formats such as SAMI, Transcript and Timed transcript was added. Colored and styled captions will be extracted with information about it (where applies). Rolling up DTVCC support was also implemented.\nTechnical Details Work done is based on CEA-708-D specification.\nRe-encoding characters is done using iconv. To make it work on Windows, win-iconv implementation is used.\nTo check what encodings/charsets are supported by iconv, visit libiconv website\nHow to use There is a -svc (or --service) argument, that enables processing of DTVCC. Arguments' value is a comma delimited numbers of streams, e.g. \u0026quot;1,3,62\u0026quot;. If it is known that one of the services contains 16-bit characters, then you can pass charset or encoding right after service number, e.g. \u0026quot;1[EUC-KR],3[EUC-CN],62\u0026quot;.\nIf you don't know what services source video file contains, or you would like to extract all existing, you can pass \u0026quot;all\u0026quot; as an arguments' value. To specify charset or encoding pass \u0026quot;all[CHARSET]\u0026quot;.\nSo, for example, to extract DTVCC from Korean sample, run:\n$ ./ccextractor mbc.ts -svc 1[EUC-KR]\nHow to evaluate Try to extract captions from files located in Korean708D, Cristiano708 and Cristiano708_2 directories on ccextractors' ftp server. Korean samples store captions in EUC-KR encoding, so specify charset in services argument: -svc 1[EUC-KR].\n","link":"https://ccextractor.org/public/gsoc/olegkisselef_cea_708/","title":"CEA-708"},{"body":"CCExtractor's main program is console based. There's a GUI for Windows, as well as provisions so other programs can easily interface with CCExtractor, but the heavy lefting is done by a command line program (that can be called by scripts so integration with larger processes is straightforward).\nRunning CCExtractor without any parameter will display a help screen with all the options. As of version 0.88 the help screen is as follows:\nCCExtractor 0.88, Carlos Fernandez Sanz, Volker Quetschke. Teletext portions taken from Petr Kutalek's telxcc -------------------------------------------------------------------------- Originally based on McPoodle's tools. Check his page for lots of information on closed captions technical details. (http://www.theneitherworld.com/mcpoodle/SCC_TOOLS/DOCS/SCC_TOOLS.HTML) This tool home page: http://www.ccextractor.org Extracts closed captions and teletext subtitles from video streams. (DVB, .TS, ReplayTV 4000 and 5000, dvr-ms, bttv, Tivo, Dish Network, .mp4, HDHomeRun are known to work). Syntax: ccextractor [options] inputfile1 [inputfile2...] [-o outputfilename] To see This Help Message: -h or --help File name related options: inputfile: file(s) to process -o outputfilename: Use -o parameters to define output filename if you don't like the default ones (same as infile plus _1 or _2 when needed and file extension, e.g. .srt). -cf filename: Write 'clean' data to a file. Cleans means the ES without TS or PES headers. -stdout: Write output to stdout (console) instead of file. If stdout is used, then -o can't be used. Also -stdout will redirect all messages to stderr (error). -pesheader: Dump the PES Header to stdout (console). This is used for debugging purposes to see the contents of each PES packet header. -debugdvbsub: Write the DVB subtitle debug traces to console. -ignoreptsjumps: Ignore PTS jumps (default). -fixptsjumps: fix pts jumps. Use this parameter if you experience timeline resets/jumps in the output. -stdin: Reads input from stdin (console) instead of file. You can pass as many input files as you need. They will be processed in order. If a file name is suffixed by +, ccextractor will try to follow a numerical sequence. For example, DVD001.VOB+ means DVD001.VOB, DVD002.VOB and so on until there are no more files. Output will be one single file (either raw or srt). Use this if you made your recording in several cuts (to skip commercials for example) but you want one subtitle file with contiguous timing. Output file segmentation: -outinterval x output in interval of x seconds --segmentonkeyonly -key: When segmenting files, do it only after a I frame trying to behave like FFmpeg Network support: -udp port: Read the input via UDP (listening in the specified port) instead of reading a file. -udp [host:]port: Read the input via UDP (listening in the specified port) instead of reading a file. Host can be a hostname or IPv4 address. If host is not specified then listens on the local host. -udp [src@host:]port: Read the input via UDP (listening in the specified port) instead of reading a file. Host and src can be a hostname or IPv4 address. If host is not specified then listens on the local host. -sendto host[:port]: Sends data in BIN format to the server according to the CCExtractor's protocol over TCP. For IPv6 use [address]:port -tcp port: Reads the input data in BIN format according to CCExtractor's protocol, listening specified port on the local host -tcppassword password: Sets server password for new connections to tcp server -tcpdesc description: Sends to the server short description about captions e.g. channel name or file name Options that affect what will be processed: -1, -2, -12: Output Field 1 data, Field 2 data, or both (DEFAULT is -1) Use --append to prevent overwriting of existing files. The output will be appended instead. -cc2: When in srt/sami mode, process captions in channel 2 instead of channel 1. -svc --service N1[cs1],N2[cs2]...: Enable CEA-708 (DTVCC) captions processing for the listed services. The parameter is a comma delimited list of services numbers, such as \u0026quot;1,2\u0026quot; to process the primary and secondary language services. Pass \u0026quot;all\u0026quot; to process all services found. If captions in a service are stored in 16-bit encoding, you can specify what charset or encoding was used. Pass its name after service number (e.g. \u0026quot;1[EUC-KR],3\u0026quot; or \u0026quot;all[EUC-KR]\u0026quot;) and it will encode specified charset to UTF-8 using iconv. See iconv documentation to check if required encoding/charset is supported. In general, if you want English subtitles you don't need to use these options as they are broadcast in field 1, channel 1. If you want the second language (usually Spanish) you may need to try -2, or -cc2, or both. Input formats: With the exception of McPoodle's raw format, which is just the closed caption data with no other info, CCExtractor can usually detect the input format correctly. To force a specific format: -in=format where format is one of these: ts -\u0026gt; For Transport Streams. ps -\u0026gt; For Program Streams. es -\u0026gt; For Elementary Streams. asf -\u0026gt; ASF container (such as DVR-MS). wtv -\u0026gt; Windows Television (WTV) bin -\u0026gt; CCExtractor's own binary format. raw -\u0026gt; For McPoodle's raw files. mp4 -\u0026gt; MP4/MOV/M4V and similar. m2ts -\u0026gt; BDAV MPEG-2 Transport Stream mkv -\u0026gt; Matroska container and WebM. mxf -\u0026gt; Material Exchange Format (MXF). -ts, -ps, -es, -mp4, -wtv, -mkv and -asf/--dvr-ms can be used as shorts. Output formats: -out=format where format is one of these: srt -\u0026gt; SubRip (default, so not actually needed). ass/ssa -\u0026gt; SubStation Alpha. ccd -\u0026gt; Scenarist Closed Caption Disassembly format scc -\u0026gt; Scenarist Closed Caption format webvtt -\u0026gt; WebVTT format webvtt-full -\u0026gt; WebVTT format with styling sami -\u0026gt; MS Synchronized Accesible Media Interface. bin -\u0026gt; CC data in CCExtractor's own binary format. raw -\u0026gt; CC data in McPoodle's Broadcast format. dvdraw -\u0026gt; CC data in McPoodle's DVD format. mcc -\u0026gt; CC data compressed using MacCaption Format. txt -\u0026gt; Transcript (no time codes, no roll-up captions, just the plain transcription. ttxt -\u0026gt; Timed Transcript (transcription with time info) g608 -\u0026gt; Grid 608 format. smptett -\u0026gt; SMPTE Timed Text (W3C TTML) format. spupng -\u0026gt; Set of .xml and .png files for use with dvdauthor's spumux. See \u0026quot;Notes on spupng output format\u0026quot; null -\u0026gt; Don't produce any file output report -\u0026gt; Prints to stdout information about captions in specified input. Don't produce any file output -srt, -dvdraw, -sami, -webvtt, -txt, -ttxt and -null can be used as shorts. Options that affect how input files will be processed. -gt --goptime: Use GOP for timing instead of PTS. This only applies to Program or Transport Streams with MPEG2 data and overrides the default PTS timing. GOP timing is always used for Elementary Streams. -nogt --nogoptime: Never use GOP timing (use PTS), even if ccextractor detects GOP timing is the reasonable choice. -fp --fixpadding: Fix padding - some cards (or providers, or whatever) seem to send 0000 as CC padding instead of 8080. If you get bad timing, this might solve it. -90090: Use 90090 (instead of 90000) as MPEG clock frequency. (reported to be needed at least by Panasonic DMR-ES15 DVD Recorder) -ve --videoedited: By default, ccextractor will process input files in sequence as if they were all one large file (i.e. split by a generic, non video-aware tool. If you are processing video hat was split with a editing tool, use -ve so ccextractor doesn't try to rebuild the original timing. -s --stream [secs]: Consider the file as a continuous stream that is growing as ccextractor processes it, so don't try to figure out its size and don't terminate processing when reaching the current end (i.e. wait for more data to arrive). If the optional parameter secs is present, it means the number of seconds without any new data after which ccextractor should exit. Use this parameter if you want to process a live stream but not kill ccextractor externally. Note: If -s is used then only one input file is allowed. -poc --usepicorder: Use the pic_order_cnt_lsb in AVC/H.264 data streams to order the CC information. The default way is to use the PTS information. Use this switch only when needed. -myth: Force MythTV code branch. -nomyth: Disable MythTV code branch. The MythTV branch is needed for analog captures where the closed caption data is stored in the VBI, such as those with bttv cards (Hauppage 250 for example). This is detected automatically so you don't need to worry about this unless autodetection doesn't work for you. -wtvconvertfix: This switch works around a bug in Windows 7's built in software to convert *.wtv to *.dvr-ms. For analog NTSC recordings the CC information is marked as digital captions. Use this switch only when needed. -wtvmpeg2: Read the captions from the MPEG2 video stream rather than the captions stream in WTV files -pn --program-number: In TS mode, specifically select a program to process. Not needed if the TS only has one. If this parameter is not specified and CCExtractor detects more than one program in the input, it will list the programs found and terminate without doing anything, unless -autoprogram (see below) is used. -autoprogram: If there's more than one program in the stream, just use the first one we find that contains a suitable stream. -multiprogram: Uses multiple programs from the same input stream. -datapid: Don't try to find out the stream for caption/teletext data, just use this one instead. -datastreamtype: Instead of selecting the stream by its PID, select it by its type (pick the stream that has this type in the PMT) -streamtype: Assume the data is of this type, don't autodetect. This parameter may be needed if -datapid or -datastreamtype is used and CCExtractor cannot determine how to process the stream. The value will usually be 2 (MPEG video) or 6 (MPEG private data). -haup --hauppauge: If the video was recorder using a Hauppauge card, it might need special processing. This parameter will force the special treatment. -mp4vidtrack: In MP4 files the closed caption data can be embedded in the video track or in a dedicated CC track. If a dedicated track is detected it will be processed instead of the video track. If you need to force the video track to be processed instead use this option. -noautotimeref: Some streams come with broadcast date information. When such data is available, CCExtractor will set its time reference to the received data. Use this parameter if you prefer your own reference. Note: Current this only affects Teletext in timed transcript with -datets. --noscte20: Ignore SCTE-20 data if present. --webvtt-create-css: Create a separate file for CSS instead of inline. -deblev: Enable debug so the calculated distance for each two strings is displayed. The output includes both strings, the calculated distance, the maximum allowed distance, and whether the strings are ultimately considered equivalent or not, i.e. the calculated distance is less or equal than the max allowed.. -anvid --analyzevideo Analyze the video stream even if it's not used for subtitles. This allows to provide video information. --no-timestamp-map Use this flag to disable the X-TIMESTAMP-MAP header for WebVTT Levenshtein distance: When processing teletext files CCExtractor tries to correct typos by comparing consecutive lines. If line N+1 is almost identical to line N except for minor changes (plus next characters) then it assumes that line N that a typo that was corrected in N+1. This is currently implemented in teletext because it's where samples files that could benefit from this were available. You can adjust, or disable, the algorithm settings with the following parameters. -nolevdist: Don't attempt to correct typos with Levenshtein distance. -levdistmincnt value: Minimum distance we always allow regardless of the length of the strings.Default 2. This means that if the calculated distance is 0,1 or 2, we consider the strings to be equivalent. -levdistmaxpct value: Maximum distance we allow, as a percentage of the shortest string length. Default 10%.0 For example, consider a comparison of one string of 30 characters and one of 60 characters. We want to determine whether the first 30 characters of the longer string are more or less the same as the shortest string, i.e. whether the longest string is the shortest one plus new characters and maybe some corrections. Since the shortest string is 30 characters and the default percentage is 10%, we would allow a distance of up to 3 between the first 30 characters. Options that affect what kind of output will be produced: -chapters: (Experimental) Produces a chapter file from MP4 files. Note that this must only be used with MP4 files, for other files it will simply generate subtitles file. -bom: Append a BOM (Byte Order Mark) to output files. Note that most text processing tools in linux will not like BOM. This is the default in Windows builds. -nobom: Do not append a BOM (Byte Order Mark) to output files. Note that this may break files when using Windows. This is the default in non-Windows builds. -unicode: Encode subtitles in Unicode instead of Latin-1. -utf8: Encode subtitles in UTF-8 (no longer needed. because UTF-8 is now the default). -latin1: Encode subtitles in Latin-1 -nofc --nofontcolor: For .srt/.sami/.vtt, don't add font color tags. --nohtmlescape: For .srt/.sami/.vtt, don't covert html unsafe character -nots --notypesetting: For .srt/.sami/.vtt, don't add typesetting tags. -trim: Trim lines. -dc --defaultcolor: Select a different default color (instead of white). This causes all output in .srt/.smi/.vtt files to have a font tag, which makes the files larger. Add the color you want in RGB, such as -dc #FF0000 for red. -sc --sentencecap: Sentence capitalization. Use if you hate ALL CAPS in subtitles. --capfile -caf file: Add the contents of 'file' to the list of words that must be capitalized. For example, if file is a plain text file that contains Tony Alan Whenever those words are found they will be written exactly as they appear in the file. Use one line per word. Lines starting with # are considered comments and discarded. --kf: Censors profane words from subtitles. --profanity-file \u0026lt;file\u0026gt;: Add the contents of \u0026lt;file\u0026gt; to the list of words that. must be censored. The content of \u0026lt;file\u0026gt;, follows the same syntax as for the capitalization file -sbs --splitbysentence: Split output text so each frame contains a complete sentence. Timings are adjusted based on number of characters . -unixts REF: For timed transcripts that have an absolute date instead of a timestamp relative to the file start), use this time reference (UNIX timestamp). 0 =\u0026gt; Use current system time. ccextractor will automatically switch to transport stream UTC timestamps when available. -datets: In transcripts, write time as YYYYMMDDHHMMss,ms. -sects: In transcripts, write time as ss,ms -UCLA: Transcripts are generated with a specific format that is convenient for a specific project, feel free to play with it but be aware that this format is really live - don't rely on its output format not changing between versions. -latrusmap Map Latin symbols to Cyrillic ones in special cases of Russian Teletext files (issue #1086) -xds: In timed transcripts, all XDS information will be saved to the output file. -lf: Use LF (UNIX) instead of CRLF (DOS, Windows) as line terminator. -df: For MCC Files, force dropframe frame count. -autodash: Based on position on screen, attempt to determine the different speakers and a dash (-) when each of them talks (.srt/.vtt only, -trim required). -xmltv mode: produce an XMLTV file containing the EPG data from the source TS file. Mode: 1 = full output 2 = live output. 3 = both -xmltvliveinterval x: interval of x seconds between writing live mode xmltv output. -xmltvoutputinterval x: interval of x seconds between writing full file xmltv output. -xmltvonlycurrent: Only print current events for xmltv output. -sem: Create a .sem file for each output file that is open and delete it on file close. -dvblang: For DVB subtitles, select which language's caption stream will be processed. e.g. 'eng' for English. If there are multiple languages, only this specified language stream will be processed (default). -ocrlang: Manually select the name of the Tesseract .traineddata file. Helpful if you want to OCR a caption stream of one language with the data of another language. e.g. '-dvblang chs -ocrlang chi_tra' will decode the Chinese (Simplified) caption stream but perform OCR using the Chinese (Traditional) trained data This option is also helpful when the traineddata file has non standard names that don't follow ISO specs -quant mode: How to quantize the bitmap before passing it to tesseract for OCR'ing. 0: Don't quantize at all. 1: Use CCExtractor's internal function (default). 2: Reduce distinct color count in image for faster results. -oem: Select the OEM mode for Tesseract. Available modes : 0: OEM_TESSERACT_ONLY - the fastest mode. 1: OEM_LSTM_ONLY - use LSTM algorithm for recognition. 2: OEM_TESSERACT_LSTM_COMBINED - both algorithms. Default value depends on the tesseract version linked : Tesseract v3 : default mode is 0, Tesseract v4 : default mode is 1. -mkvlang: For MKV subtitles, select which language's caption stream will be processed. e.g. 'eng' for English. Language codes can be either the 3 letters bibliographic ISO-639-2 form (like \u0026quot;fre\u0026quot; for french) or a language code followed by a dash and a country code for specialities in languages (like \u0026quot;fre-ca\u0026quot; for Canadian French). -nospupngocr When processing DVB don't use the OCR to write the text as comments in the XML file. -font: Specify the full path of the font that is to be used when generating SPUPNG files. If not specified, you need to have the default font installed (Helvetica for macOS, Calibri for Windows, and Noto for other operating systems at their ) default location ) -italics: Specify the full path of the italics font that is to be used when generating SPUPNG files. If not specified, you need to have the default font installed (Helvetica Oblique for macOS, Calibri Italic for Windows, and NotoSans Italic for other operating systems at their ) default location ) Options that affect how ccextractor reads and writes (buffering): -bi --bufferinput: Forces input buffering. -nobi -nobufferinput: Disables input buffering. -bs --buffersize val: Specify a size for reading, in bytes (suffix with K or or M for kilobytes and megabytes). Default is 16M. -koc: keep-output-close. If used then CCExtractor will close the output file after writing each subtitle frame and attempt to create it again when needed. -ff --forceflush: Flush the file buffer whenever content is written. Options that affect the built-in 608 closed caption decoder: -dru: Direct Roll-Up. When in roll-up mode, write character by character instead of line by line. Note that this produces (much) larger files. -noru --norollup: If you hate the repeated lines caused by the roll-up emulation, you can have ccextractor write only one line at a time, getting rid of these repeated lines. -ru1 / ru2 / ru3: roll-up captions can consist of 2, 3 or 4 visible lines at any time (the number of lines is part of the transmission). If having 3 or 4 lines annoys you you can use -ru to force the decoder to always use 1, 2 or 3 lines. Note that 1 line is not a real mode rollup mode, so CCExtractor does what it can. In -ru1 the start timestamp is actually the timestamp of the first character received which is possibly more accurate. Options that affect timing: -delay ms: For srt/sami/webvtt, add this number of milliseconds to all times. For example, -delay 400 makes subtitles appear 400ms late. You can also use negative numbers to make subs appear early. Notes on times: -startat and -endat times are used first, then -delay. So if you use -srt -startat 3:00 -endat 5:00 -delay 120000, ccextractor will generate a .srt file, with only data from 3:00 to 5:00 in the input file(s) and then add that (huge) delay, which would make the final file start at 5:00 and end at 7:00. Options that affect what segment of the input file(s) to process: -startat time: Only write caption information that starts after the given time. Time can be seconds, MM:SS or HH:MM:SS. For example, -startat 3:00 means 'start writing from minute 3. -endat time: Stop processing after the given time (same format as -startat). The -startat and -endat options are honored in all output formats. In all formats with timing information the times are unchanged. -scr --screenfuls num: Write 'num' screenfuls and terminate processing. Options that affect which codec is to be used have to be searched in input If codec type is not selected then first elementary stream suitable for subtitle is selected, please consider -teletext -noteletext override this option. -codec dvbsub select the dvb subtitle from all elementary stream, if stream of dvb subtitle type is not found then nothing is selected and no subtitle is generated -nocodec dvbsub ignore dvb subtitle and follow default behaviour -codec teletext select the teletext subtitle from elementary stream -nocodec teletext ignore teletext subtitle NOTE: option given in form -foo=bar ,-foo = bar and --foo=bar are invalid valid option are only in form -foo bar nocodec and codec parameter must not be same if found to be same then parameter of nocodec is ignored, this flag should be passed once, more then one are not supported yet and last parameter would taken in consideration Adding start and end credits: CCExtractor can _try_ to add a custom message (for credits for example) at the start and end of the file, looking for a window where there are no captions. If there is no such window, then no text will be added. The start window must be between the times given and must have enough time to display the message for at least the specified time. --startcreditstext txt: Write this text as start credits. If there are several lines, separate them with the characters \\n, for example Line1\\nLine 2. --startcreditsnotbefore time: Don't display the start credits before this time (S, or MM:SS). Default: 0 --startcreditsnotafter time: Don't display the start credits after this time (S, or MM:SS). Default: 5:00 --startcreditsforatleast time: Start credits need to be displayed for at least this time (S, or MM:SS). Default: 2 --startcreditsforatmost time: Start credits should be displayed for at most this time (S, or MM:SS). Default: 5 --endcreditstext txt: Write this text as end credits. If there are several lines, separate them with the characters \\n, for example Line1\\nLine 2. --endcreditsforatleast time: End credits need to be displayed for at least this time (S, or MM:SS). Default: 2 --endcreditsforatmost time: End credits should be displayed for at most this time (S, or MM:SS). Default: 5 Options that affect debug data: -debug: Show lots of debugging output. -608: Print debug traces from the EIA-608 decoder. If you need to submit a bug report, please send the output from this option. -708: Print debug information from the (currently in development) EIA-708 (DTV) decoder. -goppts: Enable lots of time stamp output. -xdsdebug: Enable XDS debug data (lots of it). -vides: Print debug info about the analysed elementary video stream. -cbraw: Print debug trace with the raw 608/708 data with time stamps. -nosync: Disable the syncing code. Only useful for debugging purposes. -fullbin: Disable the removal of trailing padding blocks when exporting to bin format. Only useful for for debugging purposes. -parsedebug: Print debug info about the parsed container file. (Only for TS/ASF files at the moment.) -parsePAT: Print Program Association Table dump. -parsePMT: Print Program Map Table dump. -dumpdef: Hex-dump defective TS packets. -investigate_packets: If no CC packets are detected based on the PMT, try to find data in all packets by scanning. Teletext related options: -tpage page: Use this page for subtitles (if this parameter is not used, try to autodetect). In Spain the page is always 888, may vary in other countries. -tverbose: Enable verbose mode in the teletext decoder. -teletext: Force teletext mode even if teletext is not detected. If used, you should also pass -datapid to specify the stream ID you want to process. -noteletext: Disable teletext processing. This might be needed for video streams that have both teletext packets and CEA-608/708 packets (if teletext is processed then CEA-608/708 processing is disabled). Transcript customizing options: -customtxt format: Use the passed format to customize the (Timed) Transcript output. The format must be like this: 1100100 (7 digits). These indicate whether the next things should be displayed or not in the (timed) transcript. They represent (in order): - Display start time - Display end time - Display caption mode - Display caption channel - Use a relative timestamp ( relative to the sample) - Display XDS info - Use colors Examples: 0000101 is the default setting for transcripts 1110101 is the default for timed transcripts 1111001 is the default setting for -ucla Make sure you use this parameter after others that might affect these settings (-out, -ucla, -xds, -txt, -ttxt ...) Communication with other programs and console output: --gui_mode_reports: Report progress and interesting events to stderr in a easy to parse format. This is intended to be used by other programs. See docs directory for. details. --no_progress_bar: Suppress the output of the progress bar -quiet: Don't write any message. Notes on the CEA-708 decoder: While it is starting to be useful, it's a work in progress. A number of things don't work yet in the decoder itself, and many of the auxiliary tools (case conversion to name one) won't do anything yet. Feel free to submit samples that cause problems and feature requests. Notes on spupng output format: One .xml file is created per output field. A set of .png files are created in a directory with the same base name as the corresponding .xml file(s), but with a .d extension. Each .png file will contain an image representing one caption and named subNNNN.png, starting with sub0000.png. For example, the command: ccextractor -out=spupng input.mpg will create the files: input.xml input.d/sub0000.png input.d/sub0001.png ... The command: ccextractor -out=spupng -o /tmp/output -12 input.mpg will create the files: /tmp/output_1.xml /tmp/output_1.d/sub0000.png /tmp/output_1.d/sub0001.png ... /tmp/output_2.xml /tmp/output_2.d/sub0000.png /tmp/output_2.d/sub0001.png ... Burned-in subtitle extraction: -hardsubx : Enable the burned-in subtitle extraction subsystem. NOTE: The following options will work only if -hardsubx is specified before them:- -tickertext : Search for burned-in ticker text at the bottom of the screen. -ocr_mode : Set the OCR mode to either frame-wise, word-wise or letter wise. e.g. -ocr_mode frame (default), -ocr_mode word, -ocr_mode letter -subcolor : Specify the color of the subtitles Possible values are in the set {white,yellow,green,cyan,blue,magenta,red}. Alternatively, a custom hue value between 1 and 360 may also be specified. e.g. -subcolor white or -subcolor 270 (for violet). Refer to an HSV color chart for values. -min_sub_duration : Specify the minimum duration that a subtitle line must exist on the screen. The value is specified in seconds. A lower value gives better results, but takes more processing time. The recommended value is 0.5 (default). e.g. -min_sub_duration 1.0 (for a duration of 1 second) -detect_italics : Specify whether italics are to be detected from the OCR text. Italic detection automatically enforces the OCR mode to be word-wise -conf_thresh : Specify the classifier confidence threshold between 1 and 100. Try and use a threshold which works for you if you get a lot of garbage text. e.g. -conf_thresh 50 -whiteness_thresh : For white subtitles only, specify the luminance threshold between 1 and 100 This threshold is content dependent, and adjusting values may give you better results Recommended values are in the range 80 to 100. The default value is 95 An example command for burned-in subtitle extraction is as follows: ccextractor video.mp4 -hardsubx -subcolor white -detect_italics -whiteness_thresh 90 -conf_thresh 60 --version : Display current CCExtractor version and detailed information. Error: (This help screen was shown because there were no input files) Issues? Open a ticket here https://github.com/CCExtractor/ccextractor/issues ","link":"https://ccextractor.org/public/general/command_line_usage/","title":"Command line usage"},{"body":"The commercial detection system identifies and reports the location of commercials in a given segment of TV recording. Once a database of commercials is created using the interface provided, it is able to achieve a detection accuracy of 100%. There is a command line interface which takes as input a video and outputs the location and contents of each of the commercials. The person who is maintaining the system can then seek through the video and classify parts of the video using a web interface. Once this is done, another command is executed which updates the database with the ads classified by the maintainer. Usually, with good maintenance, the system is able to detect all the commercials on TV.\nFormats Input video All formats accepted by ffmpeg. Popularly MPEG, MP4, AVI, MKV.\nOutput txt file The program by default creates a file called output.txt. This can be changed by editing src/constants.py. The format of the file is as follows:\nstart - end = Name of content\nEg:\n00:00:38 - 00:00:53 = ad by jeopardy 00:00:53 - 00:01:06 = ad by jerome's Working of the entire system The system works based on the concept of audio fingerprinting. The main logic is, fingerprint the audio of the regions initially hand picked and marked by the user. Store these fingerprints in a database. To identify commercials on an unknown stream of video, we obtain the audio for the given video file. We scan through the audio to detect matching fingerprints in the database. We store these matched segments as commercials in the output and the undetected segments as \u0026quot;Unclassified\u0026quot;. A sample output from the system is as below.\n00:01:39 - 00:02:09 = ad by honda 00:02:09 - 00:02:16 = ad by eye witness news 00:02:16 - 00:04:19 = unclassified 00:04:19 - 00:04:48 = ad by hbo 00:04:48 - 00:05:04 = ad by el polo loco 00:05:04 - 00:05:34 = ad by Northrop grumman 00:05:34 - 00:06:05 = ad by TobaccoFreeCa.com Now, it is seen that section 2:16 till 4:19 is unclassified. If a human could watch this segment of the video then the person can tag this segment correctly. Such an option is provided by the web interface (to seek to the required portion of the video and tag the content). Once all such unclassified regions are viewed by the human another command has to be executed, which updates the database with these new commercials.\nGenerating the database To start the system, one has to create a file for a given video which has the list of commercials which are present in the video. This file has to be manually created by watching the video. The format of the file, should match the format of the output file as shown above. Once this is ready, the database is generated with the help of the following command.\npython main.py -g labels.txt video.mpg\nWhere labels.txt should contain the location and the content of the commercials in video.mpg. The program updates the database only if a commercial having the same name is not already present in the database.\nThis part of the program, requires the directories data/, data/audio and data/video to be present. The commercials found in those regions are stored in data/video, their corresponding audio, for fingerprinting purpose, stored in data/audio. The files are created in serial order of the commercials found.\nAnother file called commercial.csv is also created. This file contains a visual view of the database in excel form. It is best to not edit this file, since the creation of the output file by the system relies on the order of the contents in this file.\nNote:When running generate for the first time, see to that there is no file called commercials.csv, the tables songs and fingerprints in dejavu detabase are empty and in db/audio and db/video, there is only file \u0026quot;.temp\u0026quot;. If all of these conditions are not met, then it leads to errors\nDetection of commercials The detection of commercials for a given video is done by first obtaining the audio of the video. The audio by default is named temp.wav. It is a single channel audio file. This file is automatically deleted when the program finishes execution. The audio-fingerprinting method obtains a 100% match with just 4 seconds of audio sample obtained from any location of the commercial. VIDEO_GAP, VIDEO_SPAN are two parameters which decide how this analysis should be done. VIDEO_SPAN, how much of the audio is to be taken. VIDEO_SPAN, how much of the audio to be skipped for analysis. The following command runs the detection on the video\npython main.py -r video.mpg\nThe command creates a file called output.txt in the same directory where the command was executed. If such a file already exists, then it over writes that file.\nManually classifying content The most basic way to tag unclassified content would be to edit output.txt and run the steps to populate the database again. But this is a cumbersome procedure so there is an interface provided to make the entire procedure easy. The interface can be seen using the following commands.\npython main.py -l output.txt video.mpg\nBy default this command searches for output.txt in the current working directory of the terminal, it assumes that this file corresponds to video.mpg and starts a local server where contents can easily be tagged. To change the default setting of output.txt, change the variable name OUTPUT in constants.py.\nTo start the web interface, we have to run gunicorn as a daemon, this is done in start_server.sh present in src/web. Run the shell script as follows in src/web:\n chmod +x start_server.sh ./start_server.sh This makes gunicorn, run on port 127.0.0.1:8000.\nIn the web interface, there is are seek and edit buttons. \u0026quot;seek\u0026quot; seeks the video to the required starting point of the block and edit allows the user to edit the tag given to that block. Once done tagging the content, one may chose to click on \u0026quot;Save changes\u0026quot;. This saves the changes made and stores it in output.txt. After the changes have been saved, to make the update in the database, run the following command.\npython main.py -g output.txt video.mpg\nThis concludes all the features of the system.\nWhen tagging unclassified content, if it is a commercial, it should start with \u0026quot;ad\u0026quot;, this helps the system detect it is a commercial so that it can fingerprint it in the database.\nNote: The ads currently present in the database at any time can be viewed by navigating to the folder db/video.\nCommon unnoticeable bugs Check if all the versions of the software comply with the system requirements mentioned on the github page. Even if it does not comply, the program will run, but the output will be erroneous. One example is, most ubuntu 12.04 distributions come with ffmpeg installed, but it is version 1.8. This version of ffmpeg has a different way of decoding the video, so even though no errors pop up, the output will be wrong.\nNote about the proposal The GSOC proposal I wrote stated that I would incorporate both audio based and video based methods into the system , theoretically this should give better user interface since the entire video is divided into blocks, which is more easy for the user to deal with.\nI implemented the entire thing as per the proposal and it turned out that it became more work for the user since the video+audio based classification method of dividing the video into blocks gave an accuracy of only 94%. Even though this accuracy is great, that 6% of blocks this misses adds a lot more work to the user. Which is why I decided to create a new branch for this part of the code and keep the neat part in the master branch. The master branch hence has code which is more user friendly.\nWeb interface of the system The web interface appears as follows, the interface is made as similar to the current interface for tagging content in Red Hen Labs. http://www.redhenlab.org/home/tutorials-and-educational-resources/how-to-use-the-online-tagging-interface.\nThe figure below, shows the first screen when the interface is opened.\nWe can go to each of the labels and edit in place, changes will be made immediately through AJAX. '+' button is used to split a label into two parts. When we click on that button, we get an image, that looks similar to this.\nDeploying the system on your local machine Installing dependencies This is done by running dependencies.sh file. Please edit the file for the corresponding architecture of your machine(x86 or amd64).\nGeneral configurations All configuration can be done by editing the file constants.py. There is no need in general to edit this file, however, when you are running the system for the first time, you will have to do the following.\n Create a mysql database named dejavu(preferably) Edit the variable \u0026quot;CONFIG\u0026quot; in constants.py to reflect the username, password of the database, also the name of the database too. An example of the config variable is as follows:   CONFIG = { \u0026quot;database\u0026quot;: { \u0026quot;host\u0026quot;: \u0026quot;127.0.0.1\u0026quot;, #The default mysql IP \u0026quot;user\u0026quot;: \u0026quot;root\u0026quot;, #Username of mysql \u0026quot;passwd\u0026quot;: \u0026quot;pass\u0026quot;, #Password of mysql \u0026quot;db\u0026quot;: \u0026quot;dejavu\u0026quot; #Name of the database just created } } Configuring the web server I found that deploying the django app on Nginx + Gunicorn is the easiest, Apache gave rise to too many bugs and lighttpd gave some fastcgi bugs which I could not resolve. The following are the steps to follow to deploy your own server.\nsudo nano /etc/nginx/sites-enabled/nginx.conf\nNow, in the config file type the following:\n server { listen 89; #Can be changed accordingly access_log /new/path/to/access.log; error_log /new/path/to/error.log; location /static { root /path/to/CommercialDetection/src/web/output/; } location / { proxy_pass [http://127.0.0.1:8000](http://127.0.0.1:8000); #Communicate with gunicorn. } } Once this is done, we restart the server.\nsudo service nginx restart\n**Note:The above config file cannot be copied as is, the paths have to be specified. It is best to keep CommercialDetection in /var/www/ where it is accessible to nginx **\nEvaluating the system The system contains a manually tagged database of 60 commercials. The database can be built by running generate on data/filename.txt with the corresponding filename.mpg in RawFilesWithCommercials. It detects all the commercials for 2015-04-28_0100_US_KABC_Eyewitness_News_6PM.mpg, since this was the video that was tested on innumerable number of times during development you can expect the best result from this.\nThe channels KABC and CBC have been used for generating ads. The remaining channels serve as a good ground for testing the system.\nThe system can be thoroughly evaluated by doing the following:\n First clone the system from git Run dependencies.sh (If not done already) Run 'generate' on the videos using the labels provided in data/ = This will build a database, which can be verified by looking at the database dejavu. Run 'recognize' on any video. Run 'Manually tagging ads' on the same video, with the output file obtained. Label at least one new commercial, to test the web interface. Also, verify the working of the buttons. Now, the button \u0026quot;save changes\u0026quot; will save the changes in labels.txt Run generate on labels.txt to get new commercials into the db. The content of the db can be viewed through commercials.csv.  Blog report A commercial detection system was built, which obtained 100% detection of commercials. The system detects the location and the content of ads in any stream of video, regardless of the content being being broadcast and other transmission noise in the video. An online interface was built along with the system to allow regular maintenance.\n","link":"https://ccextractor.org/public/gsoc/2016/vasanth/","title":"Commercial detection"},{"body":"Dependencies  The Python extension module for Python module has additional dependencies in comparison to the dependencies of CCExtractor. The documentation about the dependencies of CCExtractor can be accessed here. However, for compiling of the Python extension module for CCExtractor, the user needs to compile the following two dependencies:  SWIG  SWIG is used for generating the wrappers for C code in CCExtractor as well as for generating the module. The user needs to install SWIG or else the compilation of Python extension module will fail. For, compiling the source, the user can find useful resources here. For standard installation, for Ubuntu, the user can do  sudo apt-get install swig (This has been tested on ubuntu-16.04 (xenial)).\nPython-dev package  The Python-dev package is used by Python Extension module for accessing the functions and definitions made in C-API for accessing Python functions and other functionality. The user needs to install this package in addition to SWIG. The installation procedure is highly OS dependent and hence left at the user-end for exploration.  Installing the extension module (This section is for contributors who want to compile the extension module without installing)\n After the user has successfully installed the dependencies as stated in the above section, then the user can proceed to install the extension module via PyPI with the command:  sudo pip install ccextractor or pip install ccextractor --user\n For installation in virtual environment however, the user may use  pip install ccextractor\nCompiling the extension module (This section is for contributors who want to compile the extensionmodule without installing)\n For compiling the Python extension module, the user is needed to get a clone of the main repository for CCExtractor. The following are the exact steps to be followed after the clone of the main repository has been obtained by the user. cd api (changing the current working directory to api directory) ./build_library (running the build_library script)  The entire compilation procedure is taken care of by the build_library script.\n After the compilation is successful, then the user would have ccextractor.py module along with _ccextractor.so in the api directory. Then the user can import this module. However, the point to be noted here is that the extension module has not been installed on the user system. It has just been compiled. So the user needs to import this module only from the api directory.  PyPI module (This section is for contributors who want to upload the package to PyPI)\n The PyPI module that has been uploaded has many things added to the CCExtractor code tree and all of this can be found here (branch - manifest_file). The contributor is advised to use the documentation at An Introduction to Distutils and its subsequent parts to understand this section. The overall strategy or steps that have been followed to generate the distribution for being uploaded to PyPI is as follows:`  Adding files to distribution and generating the distribution  All the files that are needed to be included in the package distribution are to be added the MANIFEST file as done here. For understanding the syntax used in MANIFEST file the user can check this documentation. After the MANIFEST file has been written properly, the user can generate the distribution package by the command  python setup.py sdist\n This command would generate the distribution on the basis of MANIFEST file and place in the dist/ directory as a .tar.gz file until specified otherwise by the user. One thing to mention about the MANIFEST file is that it can only include files/folders from the folder it is defined within. It cannot include directories/files from parent directory or any other child directory. However, in the MANIFEST file I used, I have added the symlink to src main src directory so that the source code can be added to the package distribution via the MANIFEST file.  An analysis of the setup.py file used  The setup.py has been used to install the Python module on the user system. To understand what all the parameters mean in setup the user must refer to this documentation. The cmdclass defined at line is a very important part of the script as it internally makes call to the scripts included in package_build_scripts. A point to note is that this directory is used to include the scripts into the package distribution via the MANIFEST file. The scripts in package_build_scripts are the scripts which do the actual compilation of the source code to required python module and shared object. The user is advised to refer to build_library_package and build_api_package to understand how to compilation process takes place. The user may also refer to this documentation for understanding how the build scripts work. For any modifications made to the build scripts, viz, build_library and build_api corresponding modifications are to be made to the scripts included in package_build_scripts so that the compilation does not fail while installing the Python extension module. The ccextractor.i used in the package_build_scripts is an interface file used by SWIG to generate the wrapper codes. This is an essential part and should always be present with the distribution.  Uploading to PyPI  For uploading the extension module to Python, I have followed the exact steps mentioned at here The GitHub repository which I used to host the tar as mentioned in the above link could be found here However, there is no mandatory rule to continue hosting the source distribution from the same repository. If a user feels that a newer version for CCExtractor’s extension module is ready to be shipped, then he can follow the same steps from the link mentioned in first point of this section. In those steps, he can create a self-owned public repository and upload the module to PyPI.  ","link":"https://ccextractor.org/public/gsoc/python_extension_module_compilation_documentation_gsoc_17/","title":"Compiling the Python Extension module for CCExtractor"},{"body":"Note to GSoC applicants: Yes, you can use them. That's what open source is for. But if you decide to base on work on any of these: 1) Contact the original developer(s) and share your plan. They may be able to help you, but it's just a courtesy. 2) You proposal should consider that you are not starting from scratch. 3) Make sure you keep original credits intact, even in the cases where the license allows you to remove them. 4) Make sure you share your work with the original author.\nVideodigest: Automatic Video Summaries\nVideogrep\nSome More Videogreping With Python\nVideoparts\nC-SPAN Excerpts\nCinemini\naeneas is a Python/C library and a set of tools to automagically synchronize audio and text (aka forced alignment).\nlachesis automates the segmentation of a transcript into closed captions (CCs).\nThis example demonstrates how to generate GIFs from automatically determined video highlights\nPytube is a Python library (and command line tool) to download Youtube videos, including subtitles.\n","link":"https://ccextractor.org/public/general/coollinkswithsubfs/","title":"Cool external projects that use subtitles or do sorcery with a video stream "},{"body":"CCExtractor Cross-platform Qt GUI lets users not familiar with CLI to extract subtitles. Oleg implemented the application using Qt framework, what makes possible to run it on Linux/Unix/MacOSX/Windows desktop platforms. Design of the application is based on previous windows-only version, but it was a bit redesigned to follow \u0026quot;Extracting subtitles has never been so easy\u0026quot; concept and be as user-friendly as possible. Some options were also added according to latest ccextractors' features.\n    How to build and run Qt version \u0026gt;= 5.0 is required to build the application. There are two ways to build it: Using Qt Creator IDE and qmake automation build system. Download and install Qt Creator IDE for your platform. Open the project file and click \u0026quot;run\u0026quot;. This will build and run application. If you want to build it from console, run:\nqmake make After the application build process finishes, move the ccextractor binary file (named \u0026quot;ccextractor\u0026quot; on Unix/Linux/Mac, \u0026quot;ccextractor.exe\u0026quot; on Windows) into the directory that contains the GUI's binary.\nHow to use GUI  Main window has 5 areas:\n Main menu. Exit an application or check the about box. Source selection area. Pick up input files or set stream url using one of tabs: Files (add/remove files to/from a list), Filesystem (browse filesystem and select one or more files) and Network (set url and port for UDP streams). Summary area. Nothing could be edited by user in this area. Just a brief summary of options selected. It is impossible to show all options selected, so the most critical could be seen here. Quick options area. If ccextractor supports any options, that GUI doesn't support, you can type these options in Additional options field and they will be passed to ccextractor. Execution area. Click Extract button to launch extraction process, Options button to edit options in Options window. After extraction process is finished, Log button becames enabled, so you can view the log in a default text file viewer.  ","link":"https://ccextractor.org/public/gsoc/olegkisselef_qt_gui/","title":"Cross-platform Qt GUI"},{"body":"Commits All my work done during GSoC commited to the mainstream master branch can be found here.\nTechnical Documentation The technical documentation on how the code is structured as well as installation is available here.\nAbout the Project DVD Subtitle Extraction My project was to add support for DVD subtitles. CCExtractor had support for DVD Closed Caption however new DVDs contain DVD subtitles instead of the older DVD Closed Captions. I have added support such that supplying a VOB file normally to CCExtractor works to extract the DVD Subtitles. DVD subtitles extraction works by filtering out the subtitle frames from the video stream and obtaining the RLE encoded bitmap based subtitles, which are then provided to Tesseract for OCR recognition.\nA part of my project was to support CEA-708 subtitles. It is a closed captioning standard used in the US and Canada. CCExtractor has support for CEA-708 but it is not complete.\nOther Work In addition to the project, I worked on bug fixes and other features. All my merged pull requests can be found here.\nInitially, Vob files were new to me and to understand their data arrangement I wrote a program which is in another repository.\nKnown Issues and Future Work I hope to continue to add improvements to DVD subtitles extraction as well as CCExtractor.\n There is no support for IFO files at the moment. IFO files contain information regarding the data in the DVD. I hope to add support for IFO files pretty soon. Episode selection is not supported. To be added with IFO files.  ","link":"https://ccextractor.org/public/gsoc/2016/rishabh/","title":"DVD Subtitle Extraction"},{"body":"Overview This project was done as a part of GSoC 2016. DVD subtitles extraction works by filtering out the subtitle frames from the video stream and obtaining the RLE encoded bitmap based subtitles, which are then provided to Tesseract for OCR recognition.\nDependencies  Tesseract (OCR library by Google) Leptonica (C Image processing library)  The instructions for compilation along with the OCR can be found in the CCExtractor docs at docs/OCR.txt. General usage instructions can be found in the help screen of CCExtractor.\nCode Structure The DVD subtitle decoder is contained in the dvd_subtitle_decoder.c file and houses all required functions. The subtitles frames are selected from rest of the video and audio frames in general_loop.c and the process_spu() function receives only the subtitle packet in the buffer.\nThe structure DVD_Ctx has the context for the DVD subtitles while ctrl_seq has data of the control packet. The function process\\_spu() checks for and creates a usable packet as some data might be spread over multiple packets.\nNow we need the data in the control sequence which is handled by decode_packet(). Data from the control sequence including start and stop time, size of the subtitle, color, alpha and address of bitmap are extracted and stored in ctrl_seq.\nNow we need to obtain the bitmap (via get_bitmap()). The bitmaps however are Run-Length Encoded (RLE) and are interlaced such that alternate lines follow each other. This is handled by providing first one half of the bitmap, followed by the other to rle_decode to account for the interlacing as well. At the end we get a clean bitmap which is then sent to the OCR invoked in write_dvd_sub().\n","link":"https://ccextractor.org/public/gsoc/dvd_subtitles_technical_documentation_gsoc_16/","title":"DVD Subtitles Technical Documentation"},{"body":"Developed under Google Summer of Code, 2017 with CCExtractor Development By Satyam Mittal\n Introduction The CCExtractor Sample Platform manages a test suite bot, sample upload and more. This platform allows for a unified place to report errors, submit samples, view existing samples and more. The sample platform has been a good way to test regression tests, but still lacks windows support. It needs some improvements that are listed on issue tracker.\nThe main aim of the project is to extend the support of sample platform to windows. The focus of the project would be to add some add-on features to sample platform such as FTP upload support, improved error detection and github integration that helps user to have a single place to upload,view samples and associated test results.\n Detailed Description/Timeline  Windows Support FTP Upload Support Github Integration Improved error detection Other small listed improvements on the issue tracker   Original​ ​ Vs​ ​ Achieved​ ​ Goals  Windows CI Testing: Now Windows Testing Support has been added and it is done in parallel to linux testing. After addition of Windows Support, It will help to report errors of running ccextractor on windows and to check samples supported on windows of various PRs. FTP support: It has been added and working properly. Using FTP, a user can perform a mass upload to a server, not having to worry about repeatedly having to re browse for files and re-upload them using one form. User can easily upload large files using FTP. Github integration: Now Users can connect their github account to sample platform that enables them to report issue regarding a sample. They can see the list of issues and their status (active/closed) through sample platform. Waiting time feature: Users will see the estimated waiting for each test on sample platform while test is in queue. They don't have to sit on the platform for whole time. They could take a leap and come after estimated time. Media info: Now Platform will hide the sample info that has no media info or just partial media info. Improved Error Detection:  Improved mimetype checks: I have added a back-end check for file upload through mimetype prediction. However It will not be 100% accurate. But safer than just frontend check. Cmake, builddebug, autoconf scripts: Now I have added different build checks whether they are successful or not.   Auto-update of test progress: While the test runs, it automatically updates the page on transition from preparation-\u0026gt;building-\u0026gt;testing-\u0026gt;completed. Maintenance Mode: Added maintenance mode such that admin can easily make put virtual machines under maintenance mode and can make changes in it without taking care of future tests. Documentation: All changed set has been properly documented. I have added pydocs from methods and inline comments. I have followed pep8 while adding pull request. Unittesting: This needs to be done.   Project Related Links  Github Project repository: https://github.com/canihavesomecoffee/sample-platform Project documentation : https://github.com/canihavesomecoffee/sample-platform/blob/master/README.md Project Proposal: https://docs.google.com/document/d/1BEE4wh7wSyGYLQPU3f5jUotSHqfDQ__za1xMt6NNvNs/edit?usp=sharing Official GSoC Project Link: https://summerofcode.withgoogle.com/projects/#5205435270299648 Mentor: Willem Van Iseghem My blog (updates on weekly basis): https://satyammittal.wordpress.com/ Hosted Project Server Link: https://sampleplatform.ccextractor.org/   Contributions[Commits/PRs] All my commits to the repository can be found here: Commits\nAll my pull requests to the repository can be found here: Pull Requests\n Other Works I keep on fixing new bugs/issues raised in issue tracker time to time. I will try my best to have smooth functioning of the sample platform.\n What I have learned Doing​ ​this​ ​project​ ​is​ ​a ​lot​ ​fun​ ​with​ ​a lot​ ​of​ ​things​ ​to​ ​learn.​ ​The​ ​number​ ​of​ ​such​ ​things​ ​is​ ​more than​ ​I ​​can​ ​even​ ​write​ ​but​ ​summing​ ​up​ ​all​ ​this​ ​the​ ​major​ ​things​ ​which​ ​I ​learn​ ​includes​ ​ :\n I have been contributing in CCextractor testing platform from last 5-6 months and the journey has been great, I have learned a lot from working in different modules and also got an opportunity to discover many concepts behind some modules. The project help me how to work in a team and in systematic way. Putting​ your​ doubts​ in​ front​ ​of​ ​others​ ​as​ ​during​ ​this​ ​period​ ​a number​ of​ errors​ ​will​ ​come and​ ​you​ ​should​ ​have​ ​to​ ​ convey​ ​what​ ​you​ ​want​ ​to​ ​say​ ​to​ ​others,​ ​seems​ ​easy​ ​but​ ​not​ ​that for​ ​me​ ​atleast. Importance​ ​of​ ​indentation​ ​and​ ​documentation​ ​as​ ​during​ ​this​ ​period​   Known Issues/ Future Work  There are still some issues listed in issue tracker. I ​ have a good understanding of how the current CCextractor’s Testing platform works. I could track down the cause of the bugs quickly. I would like to fix them. Since the part of work that I have done in CCextractor's Sample Platform was done with altmost care according to my knowledge, therefore I would try to remove any bug in part of my code reported by someone else or encountered by me.   Addendum I am doing my 3rd year of graduation. I will keep contributing to the sample platform. Apart from that, I will try to become active contributor of main repository. I would like to seek the opportunity to do 2nd time GSoC with the CCextractor.\n Contact Details If you have any doubts or suggestions you can contact me anytime you want. Here are the details :\nEmail address : satyammittalid@gmail.com\nGithub : satyammittal\nBlog: Wordpress\nSlack : bashtech\n Thanks ","link":"https://ccextractor.org/public/gsoc/2017/satyam/","title":"Enable automated testing on windows and other general sample platform improvements"},{"body":"Deluge\nDeluge is a popular BitTorrent client. It's popular because it's quite efficient and performs really well compared to alternatives, but its web interface is terrible and the desktop UI is not great.\nHowever it does have a good plugin system and writing proper alternatives with Flutter is possible and not painful, so let's go for it.\nThe goal is to write a flutter-based interface (web and mobile).\nStart by installing deluge and its current web UI so get a feeling of how it looks like, and come up with a good replacement UI.\nRead the documentation to find out which part of Deluge don't yet have a UI counterpart at all.\nFlood\nFlood is a monitoring service for various torrent clients. It's a Node.js service that communicates with your a torrent client and serves a decent web UI (in React) for administration.\nFlood backend can communicate with different clients. However, it exposes one common set of API. This allows developers of an integration to support multiple torrent clients via Flood's API. On the other hand, Flood allows developers of a torrent client to quickly set up a functional UI and get supported by integrations.\nAdditionally, Flood supports advanced features like filesystem browsing, content streaming and RSS.\nFlood's API is well documented and typed. It uses simple HTTP and JSON. For instance, see POST /api/torrents/add-urls endpoint and AddTorrentByFileOptions type.\nHead maintainer of Flood, jesec, is one of the mentors. He can provide help if you have troubles setting up Flood or encountered issues with Flood's API.\nYour job\nThe job is to extend Flutter app to support Deluge and/or Flood.\nYou should work with your peer, whose goal may be different from yours, to find a way to support multiple API integrations in one application. You can check out how Flood did it.\n","link":"https://ccextractor.org/public/gsoc/flutter-more-clients/","title":"Extend the app to support more torrent clients"},{"body":"Documentation for my project can be seen here.\nDescription My project was to add the capability of extracting burned-in (hard) subtitles from videos to CCExtractor. As of now, CCExtractor works by only extracting caption data in the video if it is present in specific structures in the stream, and skips the actual video data (pixels) completely. However a lot of videos have hard subtitles burned into them, extracting which is a computer vision problem, and something which CCExtractor did not earlier have the capability to process.\n","link":"https://ccextractor.org/public/gsoc/2016/abhinav/","title":"Extract hard-coded subtitles from video streams"},{"body":"Note: This procedure may or may not be legal in your country, depending on whether they consider it fair use. I own the DVD used in the tutorial and I am not going to distribute anything from it, plus I live in a country where this sounds reasonable, so I believe I am in the safe side. But your mileage may vary.\nThis tutorial was written years ago. Probably better tools exist already to do the same thing.\nThis tutorial will teach you how to go from a DVD in your shelf to a transcript of its closed captions. Basically there are these steps:\nInstall DVDDecrypter (a program to extract the DVD data from the physical DVD). You only need to do this once. Install CCExtractor (our beloved program; it gets the data from the previous step and extracts the closed caption track). You only need to do this once. Use DVDDecrypter to extract the DVD data into your hard disk. Use CCExtractor to extract the closed caption track from the DVD data.\nAs an example, I will be using the movie Merlin. Remember that DVD subtitles and closed captions are two different things. Closed captions come from the NTSC (USA and Canada) TV world, and they are usually prevent in DVDs from TV shows, documentaries, old movies and so on. If you buy a brand new DVD with a film from last year it's unlikely to have closed captions - it will have DVD subtitles, which require different tools to extract. Many tutorials exist on DVD subtitle extraction.\n1 - Install DVDDecrypter As explained before, DVDDecrypter is the tool we will use to copy the DVD data from the physical DVD into the hard disk. DVDDecrypter reads the DVD, decrypts it (so other tools can actually use the data) and writes it to the hard disk. There are other tools that do the same thing, so you can use whichever you prefer. DVDDecrypter is free, use to use, and does a good job, so it's the one I use regularly.\nFirst, download DVDDecrypter, which is available from this page. You can get the file directly here. Depending on your browser, it may ask you whether you want to run the program, or save it, etc.\n Run it if possible directly, or save it somewhere and run it later if your browser insists.\nIf you are using Internet Explorer it might warn you about the file not being signed, and ask you again if you want to run it:\n Say yes. If you are running Vista it will show you yet another window to reconfirm you haven't changed your mind. I couldn't get a snapshot but it you are a Vista user you have seen that windows a billion times anyway. The installation program starts. All defaults are correct, so the only thing you need to do is say Next at every chance. A screenshot of all screens follows:\n   When asked about whether you want DVDDecrypter to check for new versions say no. The program is no longer being maintained so it will never find a new version anyway.\n The installation ends. In the last screen you have an option to start DVDDecrypter inmediately. Since we are going to install CCExtractor now, uncheck the box.\n 2 - Install CCExtractor CCExtractor is the program that does the actual work of getting the closed caption text from the data. It supports DVDs as well as many other formats. This is its home page (you probably know that already). Follow the link \u0026quot;Download Windows installer\u0026quot; (I don't link to the installer directly because it's updated from time to time and the link would be out of date soon). As before, run the installer if possible or save and run later if needed.\n       3 - Extract the data from the DVD using DVDDecrypter Insert the DVD in the DVD player if you haven't done it already. Most likely it will start making noise for a few seconds, until Windows is done analyzing it. Wait for the noise to stop (so it's ready) and then start DVDDecrypter, either by clicking on its icon (on your desktop) our by selecting it in the program menu (Start -\u0026gt; Programs -\u0026gt; DVD Decrypter -\u0026gt; DVD Decrypter). Initially the screen looks like this (assuming DVDDecrypter detects the DVD correctly - if not you may have to select the correct drive from the combo box):\n The first time, go to the settings area (Tools -\u0026gt; Settings). There are a lot of things there but the default settings are fine, except for the file splitting. We don't want the output video to be split in several files (the only exception would be if your hard drive couldn't handle large files). Having all the output in one file makes things easier later.\nSo go to the settings area as explained, and the select the \u0026quot;IFO mode\u0026quot; tab. In file splitting choose \u0026quot;None\u0026quot; from the combox box and then press OK. Done with the settings.\n Back to the main screen, you can see that there's a \u0026quot;Destination\u0026quot; that DVD Decrypter automatically sets. You may need to choose a different folder. For me that directory is OK (F:\\MERLIN\\VIDEO_TS). Notice too that all the files in the DVD are selected. If were trying to get the data from say, one specific episode of a TV show (where usually there are 4 episodes or so in each DVD) we would have to guess which file is correct. Since this is a complete movie, we're going to get all the files, so we leave the selection as is.\nOK, so we press the large 'Decrypt' button (see below) and DVD Decrypter does its magic.\n   File selection\nTake a look at the destination directory:\n The VOB files are the actual video data. In DVDs, they usually have more stuff that just the movie. For example, the chapter selection video is there. In order to get a clean transcript, you need to tell CCExtractor which files to use. Usually the right files are easy to spot. In this example, you can see that the file VTS_01_0.VOB is 330 Mb long, while VTS_01_1.VOB is 1 Gb, VTS_02_2.VOB is one Gb too, etc. This is a clear indicator that it is not part of the same video stream. In order to verify it, we just play the file with any DVD capable player:\n This is indeed the chapter selection video, which we don't want. Just to make sure, we start playing VTS_01_1.VOB, which should be the actual start of the movie:\n Indeed it is.\n4 - Extract the transcript with CCExtractor Open CCExtractor, by click on its desktop icon or by selecting it from the program menu (Start -\u0026gt; Programs -\u0026gt; CCExtractor -\u0026gt; CCExtractorGUI).\n Now, open Windows Explorer if you didn't have it already, and choose the files VTS_01_1.VOB up to VTS_01_01_8.VOB (so all of them except the one we already know not to be part of the movie):\n Drag and drop the files from Windows Explorer to CCExtractor:\n Now you can see that CCExtractor has queued the files:\n You can notice that CCExtractor has a lot of tabs with lots of options. The good news is that the default settings are OK, so you don't need to worry about them. The one thing you may want to change is the output format in the Output tab. By default it exports to .srt, which is the standard format that most players support. Suppose you want a plain transcript with no timing information. Just check the .txt option (transcript):\n Finally, go to the Execution tab and press Start: screen-shot You can see the progress:\n Once CCExtractor finishes, a file with the same name as the first file in the input is created in the same directory (this can all be changed in the settings). In this case, the file is called VTS_01_1.txt (note that it ends with .txt instead of .VOB). Here's the contents (the first 10 lines):\nONCE UPON A TIME... NO, NO, THAT'S NOT THE WAY TO START. YOU'LL THINK THIS IS A FAIRY TALE, AND IT ISN'T. IT HAS ELEMENTS OF A FAIRY TALE-- DRAGONS, ELVES GRIFFINS, FAIRIES AND SO ON-- AND IT HAS MAGIC. NOW, IN MY DAY, We're done.\n","link":"https://ccextractor.org/public/gsoc/extract_from_dvd/","title":"Extracting closed captions from a DVD step by step tutorial"},{"body":"Videos contain plethora of contextual information. For example, in a movie there are fighting scenes, sentimental scenes, romantic scenes, and many others. In a cricket match, there are wickets, sixes, fours et cetera. With the advent of the data-driven age, amateurs, researchers, and organisations alike require some specific part of this contextual information for their needs; maybe for creating a highlights reel of a sports match or mining data from movies for their machine learning models. This makes parts of certain types of videos very useful. FabBits tries to automate finding them. Following are the things it will be able to detect -\n Action sequences in movies/shows - ✅ Summary of movies/shows - ✅ Actor-specific scenes in movies/shows - ✅ Jokes in sitcoms - ✅ Slo-mos in Sports - ❌ Goals in Soccer - ✅ Goal misses in Soccer - ⭕ Three pointers in Basketball - ✅  Links Project repo - github.com/achie27/FabBits Blog posts - medium.com/@achie27 Samples - Drive folder\nRequirements You need the following things to run FabBits-\n Python3 OpenCV - Used for image and video processing Moviepy - Used for video editing and audio processing PyQt5 - Used to make the GUI Scipy  - Used for audio processing Tesserocr - Used for, well, OCR Pillow - Used to preprocess images for OCR The python dependencies can be installed by running -   pip3 install scipy pip3 install opencv-python pip3 install moviepy pip3 install pyqt5 pip3 install Pillow pip3 install tesserocr or if you are the Anaconda kind -\n conda install -c conda-forge scipy conda install -c conda-forge opencv conda install -c conda-forge moviepy conda install -c anaconda pyqt conda install -c conda-forge pillow conda install -c simonflueckiger tesserocr Usage Run the main GUI by -\npython3 main.py\nTo find your FabBit of choice -\n Click MOVIES or SPORTS button for their respective use-cases Select the use-case from the sidebar A pop-up dialog will ask for the actor if actor-specific scene was chosen Click on Choose File to select the input video Click on Find FabBits Move the slider in the blue areas, which are the extracted FabBits, and play the video Click on Save FabBits to save the extracted stuff into a video file  You can also run the respective files of use-cases to get their FabBit, like - python3 goal_detector.py soccer_match.mp4\nReferences All the references can be found listed in the repository's readme.\n","link":"https://ccextractor.org/public/gsoc/2018/achie27/","title":"FabBits"},{"body":"Tutorials Building a portfolio website\nGame of Life with Flutter\n12 Useful libraries to support development using flutter\nFlutter Tutorial: Real Estate App\nFlutter Tutorial: Courses App\nHandwriting number recognizer with Flutter and Tensorflow (part I)\nA very sexy Flutter template app with great focus on UI\n60 Days Of Flutter : Building a Messenger from Scratch\nHotel Booking App UI\nChatBot in Flutter using DialogFlow \nRoadmap To Become A Flutter Developer (Resources for Beginners)\n","link":"https://ccextractor.org/public/general/flutter_resources/flutter/","title":"Flutter Resources"},{"body":"This page is currently being written (a bit every day, actively) so new developers that want to join us don't have to learn the basics from scratch.\nWe often get questions about how to get started with our code. The most important thing would be: Don't try to read and understand every file, because it's pointless and there's no need. While it's definitely not the linux kernel, CCExtractor's code is not trivial, and it's been written by a number of people during a long time. Often, that people was learning as they went, and it shows in parts of the code.\nHowever, it's important to have a general idea of how things are organized so you know where to look for things and how to add new features.\nThis page tries to explain the most important concepts and introduces the important files in the core CCExtractor tool. Note that we have additional tools such as our regression test platform, or the real time subtitle database. Those will be explained in their own pages.\nCCExtractor is written in C. If you are a C++ developer that will have pretty much zero impact in your ability to contribute, because the really important differences are abstracted in functions anyway. Sure we don't have classes and our I/O is different, but that's really not a big deal here - you will need to understand file formats anyway, or how to read specification documents. None of that depends on the language of choice.\nCCExtractor reads binary streams (a stream may be a file, but it can also be data coming from network - so don't assume) and writes subtitle files.\nContainer formats The usual audio/video streams come in a number of variants. You know how in files you have .avi, .mkv, .mp4, .mpeg and so on? Those are container formats, because they \u0026quot;contain\u0026quot; the parts of the media: Video, audio and subtitles. Each of those have some limitations, but in general, the contain format doesn't specify how each part of the media is encoded. You can have a .mkv (Matroska) that contains the video encoded as MPEG-2, or H264, etc, then the audio as MP3, or AAC and so on.\nIn TV broadcast, the typical container is the Transport Stream (.ts). A Transport Stream can carry more than one TV program (for example, BBC One, BBC Two and BBC News), each of them with its own video, audio, and subtitles (and for each, maybe more than one language).\nStreaming services such as iTunes uses .mp4.\nThe parts of CCExtractor that handle the containers are called demuxers. A demuxer is capable of reading a specific container and return parts of it.\nSubtitles Our input streams are files that contain subtitles. These subtitles can be encoded in a different ways depending on the country they come from or the technology used to make the recording. Focusing on recordings made from a TV broadcast, we have:\nCEA-608, which is the “old” format used in North America. It comes from the analog days of NTSC, but while the transmission was analog, in the end you have 2 bytes (that's digital) of subtitle data in each frame, and that's the one thing that is important to keep in mind. You don't need to bother understanding the analog part of the transmission, because what we process is just those two bytes.\nBy the way, in North America those subtitles that you can turn on and off are called closed captions.\nCEA-708, is the “new” format used in North America. It's all digital, and because when it was designed the TVs were a lot better, they had much more bandwidth for subtitles, they have lots more capabilities.\nTeletext, is the old format in Europe. It's still around, but it's quickly being replaced with DVB.\nDVB is the current format in Europe. It's a bitmap based format, which means that instead of characters being transmitted it's images (for example, for “CCExtractor” you would have the representation of the letters in graphics format, not one byte for each letter as you could expect). This makes DVB more capable, but also a lot harder to transcript to text, since a OCR is required.\nISDB is the format used in Brazil.\nIn CCExtractor, the parts of code responsible for handling the different subtitle formats are called decoders.\nCombination of containers and subtitle formats As explained, subtitles come in a number of encodings, and they can be carried in different containers. So you can have subtitles encoded in CEA-608 inside a .ts or a .mp4. And you can also have a .ts file or a .mp4 that contains subtitles in CEA-608 and DVB.\nOnce you have the subtitle data it doesn't matter where it came from (what the container type is). Similarly, when processing a container, it doesn't matter what type of subtitles are there.\nReading the containers The first thing that we do is identify (unless the user specified it manually) the type of container we're going to process. This is done by reading the first bytes and figuring it out for ourselves.\nThis happens in the function\nvoid detect_stream_type (struct ccx_demuxer *ctx)\nwhich is in the file stream_functions.c\nThat function (please check the code) sets the type format (best guess; identifying without fault is a lot harder than you'd think, but that's not important for an introduction) for the context (more on contexts later).\nOnce we know what type of stream we're processing we know which demuxer to use to read it.\nWe have demuxers for Transport Streams (in ts_functions.c), mp4 (in mp4.c) and more. The block that, after knowing the type of container, decides what to do, is in the main file, ccextractor.c,\n/* ----------------------------------------------------------------- MAIN LOOP ----------------------------------------------------------------- */ switch (stream_mode) { ... } User options, contexts, and in general where stuff is saved When adding a new user option (that can be selected via command line argument) the steps are always the same:\n Add the corresponding variable in the structure  struct ccx_s_options // Options from user parameters { int extract; // Extract 1st, 2nd or both fields int no_rollup; int noscte20; int webvtt_create_css; ... } which is defined in src/lib_ccx/ccx_common_option.h\nInitialize it to the correct default value in this function:  void init_options (struct ccx_s_options *options) { #ifdef _WIN32 options-\u0026gt;buffer_input = 1; // In Windows buffering seems to help #else options-\u0026gt;buffer_input = 0; // In linux, not so much. #endif options-\u0026gt;nofontcolor=0; // 1 = don't put \u0026lt;font color\u0026gt; tags options-\u0026gt;notypesetting=0; // 1 = Don't put \u0026lt;i\u0026gt;, \u0026lt;u\u0026gt;, etc typesetting tags which is defined src/lib_ccx/ccx_common_option.c\nAdd the corresponding parsing code in the function  int parse_parameters (struct ccx_s_options *opt, int argc, char *argv[]) { // Parse parameters for (int i=1; i\u0026lt;argc; i++) { if (!strcmp (argv[i],\u0026quot;--help\u0026quot;) || !strcmp(argv[i], \u0026quot;-h\u0026quot;)) ... } which is defined on src/lib_ccx/params.c\nAdd usage instruction on the function  void print_usage (void) { mprint (\u0026quot;Originally based on McPoodle's tools. Check his page for lots of information\\n\u0026quot;); mprint (\u0026quot;on closed captions technical details.\\n\u0026quot;); ... } which is also defined on src/lib_ccx/params.c\nDepending on what part of the code is going to actually be using that parameter you will need to copy it on the right place. The \u0026quot;place\u0026quot;, in general, is a context. A context is a structure that contain status values relevant to a group of functions, such as a decoder or an encoder. For example, if the new parameter applied to a decoder, we could copy it in the function that initializes the decoder contexts with user options:  static struct ccx_decoders_common_settings_t *init_decoder_setting( struct ccx_s_options *opt) { struct ccx_decoders_common_settings_t *setting; setting = malloc(sizeof(struct ccx_decoders_common_settings_t)); ... Note that the function receives the same structure used in steps 2 and 3, and is going to return a struct ccx_decoders_common_settings_t* .\nFinally, there's the function that really initializes the decoder context from the decoder settings:\nstruct lib_cc_decode* init_cc_decode (struct ccx_decoders_common_settings_t *setting) { struct lib_cc_decode *ctx = NULL; That struct lib_cc_decode* is what the decoders will have with all the options plus all the values they need to store as flow progresses.\nUse the variable.  A sample commit that does all the steps and adds a new option.\n","link":"https://ccextractor.org/public/general/gettingstartedwithourcode/","title":"Getting started with CCExtractor's source code"},{"body":"Code-In 2016 finished already. We're really sad, but it's been an amazing experience so we will be back!\nQuestions? You can email us at code-in@ccextractor.org. But please make sure you read the whole page first.\nFor tasks that require some resources in general we will provide them for you, including access to videos, system accounts, etc.\nRemember that the absolute best way to get invited by an organization to participate in Summer of Code is by being part of the community before GSoC is even announced. If we, as an organization, are invited to GSoC 2017 the applications from successful Code-In students will go to the top of pile.\nWe also give back to our students in any way we can, including writing recommendation letters that can help to apply to universities, visas, jobs and so on.\nIn short - don't think that the reward for participating this year may be limited to a T-Shirt :-)\nGeneral things to keep in mind while working:\n Collaboration is much better than competition. Mentors love it when a student comes up with a better idea than their own, really. Do not just do as told. If something doesn't feel right either argue against it or work on a different area. If you want to do something that is 90% or so implemented in any other open source project just take it, complete it, send the maintainers of that project whatever changes you did so they can use them if they want, and integrate with our code. Always remember to leave all license and credits intact (you can add your own name). Mentors are there to help but they're people too, not bots. So they sleep from time to time, may also have other things going on, can get sick, etc. They will reciprocate when they think of students. Whatever you do, we want to integrate. This means that your work will be public and will be around for a long time. In a few years you will find your own code again (code tends to follow you). Try to leave it in a condition that your future you will be proud of.  Slack\nSlack is a great communication tool. Most CCExtractor developers hang out in a slack team. You're welcome to request an invitation here\n","link":"https://ccextractor.org/public/codein/google_code-in_2016_task_list/","title":"Google Code-in 2016 task list"},{"body":"This year we are going to have some hard design tasks to bring design up to par with coding. Hard means that they are going to take time and talent to produce the quality results we want.\nAt least one of our finalists will be a designer even if he or she has not contributed code. We are doing this to prevent the design tasks being treated just as an easy way to complete beginner tasks. For example, you can create a T-Shirt design in 10 minutes, but that's very unlikely to be good and usable to well, actually make T-Shirts with it.\nIf you are serious about becoming a great designer and are willing to do serious work, look for tasks with the \u0026quot;HardDesign\u0026quot; tasks. At least one of the students that does a great job on those will be a finalist, and maybe a winner.\nRemember though that hard means hard. Don't expect us to approve the first design you come up with. We will give you feedback and work with you until you produce something that you can be proud of for years and that we can use.\nAlso, as a bonus, if the design is for something physical (T-Shirt, sticker, etc) we will ship you one totally free to any part of the world.\n","link":"https://ccextractor.org/public/codein/google_code-in_2017_code-in_for_designers/","title":"Google Code-in 2017 for designers"},{"body":"While the tasks themselves can't be made public until the GCI starts officially, we think it's OK to explain the kind of things we want to do for those of you that want to somehow get started - not with the tasks themselves, which is not possible, but getting prepared to start working immediately.\nIf you have already done some basic digging about Flutter, you already know what it is: A new platform that lets you write apps that will work both on Android, iOS and web. Most apps have menus, have logins, maybe access a database or some kind of internet resource, and depending on the specific app, maybe accesses the device capabilities such as the camera or location.\nThe programming language that Flutter uses is Dart, so that's something that you want to look at.\nAlso, getting Flutter to work may take a bit of time: You can start by installing it and making sure \u0026quot;Flutter Doctor\u0026quot; says everything is great.\nWe're going to be building a few apps. The goal is that build 3 applications that are actually going to be useful and we hope, popular. To get there each of them will consist on a large number of small tasks that anyone can do. Each task will have several instances (so several students can work on the same thing) and for each we'll use the best one. Of course this doesn't mean that the rest completed tasks will not be accepted. If a task it's completed, it will be accepted, and the student is of course welcome to use his/her own version of that specific piece of program.\nRemember: It's open source, so everybody is allowed to have their own copy and customize it.\nSo what are the applications? Bingo Important: This is free bingo. We're not building a betting game. That's not interesting at all - but the pieces we're going to learn, are. What are we going to learn here?\n Menus - Drawing on the screen (for example, a grid) - Interactions with a server (we're getting the tickets from a server, and getting the numbers from it) - Getting user feedback (where on the screen did the user press)  The food locator Suppose we are at a place, for example at a conference venue, or a large university campus, in which food is delivered at different places during different times of the day (this is a real use case, believe it or not). When you are hungry, you have to go around the place to find something to eat. Sometimes it's something you like, and sometimes it's not. Or maybe you won't find anything.\nWe're going to write an app that shows a map and let users report when they've seen food where they are. That information will appear to other users of the app that are in the same place, for example attending the same conference. Users can also report that food is not there, and also food can be removed from the map automatically after a certain amount of time.\nHere we're going to be learning:\n Maps - Location services - Timeouts - Interaction with servers  Smart photo app Build an app that lets you take pictures with the camera and flag them in a useful way. Also, do special things with them.\nWe all know that camera pictures can be geolocated, which means that as part of the metadata they contain the physical location. We're going to extend that by linking our pictures with things such as the calendar. For example, if your (Google) Calendar says that at 11:00-11:30 you were attending a book signing, would it be useful that the picture and the calendar event were automatically linked together?\nHere we're going to be learning:\n Camera - Location services - Accessing the Google Calendar - Basic AI (details on this will be disclosed with the tasks)  ","link":"https://ccextractor.org/public/codein/google_code-in_2019/flutter/","title":"Google Code-in 2019/ Flutter"},{"body":"Welcome to our ideas page. This is going to be an amazing year - lots of new things to work on, including JokerTV, a totally open TV receiver, plus several experimental/for fun projects. Projects in C, Node, Python... you name it, we have it. Plus resources for students - we'll give access to a high speed server, all our samples (we'll even ship a portable drive with them anywhere in the world, so don't worry about slow connections).\nYou are welcome to check out our ideas page (this is it - actual ideas at the bottom of the page) and start early in the community bonding process as well as learning a bit about our code. And of course, we'd love you to stay around even if we are not invited to GSoC or if we cannot invite you as a student.\nAbout us\nWe are a small org, which means that your contribution will have a large impact. It's not going to mean a 0.5% improvement on a big project - it's going to be more than 10% on a medium size one. If you like challenges and want a chance to shine this is your place.\nWe have -we think- statistically amazing continuity in the team: Most GSoC students from all the past years are still involved, even if they are no longer eligible as students. They still contribute code, and they mentor both in GSoC and the sister program GCi. As mentors, they also come to the Summer of Code summit which traditionally takes place in October.\nWe have mentors all over the world (North America, Europe, Asia and Australia), so time zones are never a problem. Our main channel of communication is a Slack channel to which everyone is welcome. We expect all accepted students to be available on Slack very often, even if you don't need to talk to your mentor. This will help you ask questions when necessary, and you might be able to help others out as well while working on your project.\nA mailing list is also available for those that prefer email over slack. It's a new mailing list (the old one hasn't been used in a long time) but it's read by everyone involved in GSoC.\nAll our top committers will be mentoring. Many of them are former GSoC students.\nAbout what we use\nThe core tool that names the organization (CCExtractor) is a command-line program written in C (not C++). The current Windows GUI is written in C#, and we have another GUI for Linux that's written with Qt, and a small GUI that's integrated into the main program (C). The testing tool we use to run regression tests is mainly written in Python, but it also used Javascript, CSS and some shell scripting. The Test suite is written in C#. The prototype real time subtitle website is written in NodeJS. We also have a number of support tools that do a number of different things, from downloading subtitles from streaming services to translating them with Google Translate or DeepL. Most of them are written in Python, but since they are small tools that do their job you don't need to worry much about them. For totally new things you can use whatever tool you feel is best for the job.\nAbout sample media and other resources\nWe work with huge files. Not all of them are huge, but many are. We know that many students don't have access to high speed internet. To those students we will ship (as soon as they are selected) a portable hard drive with all our samples. So if your internet connection is not good, don't worry - as long as you can plug a USB drive to your development computer you can participate with us.\nWe also have a shared Linux development server with lots of storage and a Gigabit uplink. Students get an account on it and they are welcome to use it. There's nothing there except our own work, so it's a trusted environment (for a server that is connected to internet of course).\nThe sample platform also hosts a bunch of samples, both which are small or decently sized.\nAbout the projects and getting accepted\nQualification: On top of -of course- the quality of the proposal, we will be ranking students with a points system (we introduced this two years ago, and it worked pretty well).\nWe don't have a minimum number of required points, but you definitely will need some (with equally good proposals we will rank based on acquired points). This means, the more points you get the more likely you are to be invited to join us during the summer, assuming that your proposal is good.\nYou can get points by doing one (or more) of the next options:\n1) By solving issues in our GitHub issue tracker (CCExtractor), Sample platform issues (default 1 points per issue unless specified somewhere in the issue page). Most issues have an explicit number of points that you can find in a comment.\n By joining the community in Slack. You can invite yourself here. (1 point)\n  If you are a former Code-in finalist you start with 1 point. If you were a winner, you start with 2 points. Note that there are just a few developers that meet this, so don't be discouraged if you aren't one of them. Almost no one is, but we'd love to hear from those that are.\n  By sending us a TV sample that has something we don't support. It doesn't have to be from your own country (since hopefully, we already support it), but if it is, so much the better. This is probably hard to get, since we already got all the low hanging fruit. But if your local TV has subtitles you can turn on and off, we'd love a recording.\n  Best qualification tasks\nIf you don't don't know which issues in GitHub to do, here's a list of the ones that are approachable (you don't need to dig too deep or learn many parts of the code) and useful:\nTerrible OCR results with Channel 5 (UK)\nCCExtractor won't extract subtitles from TS with no PAT/PMT\nAutomatically switch to correct encoding for 708 subtitles based on PMT data\nRequest: Allow to extract several teletext pages in one pass\n'live' raw data problem\nExtract telemetry data (which is stored in a subtitle track) from a Drone recording\nExtract EIA-608 subtitles from Matroska (.mkv)\nThe sample platform's issues are tagged with \u0026quot;gsoc-proposal-task\u0026quot;, so you can easily see what you can work on.\nCommunity etiquette\nIt goes without saying that everyone in the community has to be polite and respectful, and consider everyone else a member of a team and not a competitor.\nAll developers are part of the team, by the way. Our Slack channel has mentors, code-in participants, other students, or developers and users that are none of the above but they all play some kind of role in CCExtractor's community.\nPart of being respectful is giving consideration to everyone else's time. Most of us have day jobs, and as such are limited in the time we can use to guide you. We'd like to spend it on quality discussions, and not on things that are for example written on this website, things that you can easily retrieve by reading documentation on used libraries or on the software's help screen. Asking this kind of questions in the Slack channel shows little respect for our time. This doesn't mean you can't ask questions, but remember that being a clueless user and a lazy developer are two very different things. If you ask those questions you will probably get an answer as if you were a clueless user (polite no matter what), but if you apply to GSoC you will be considered a lazy developer. Google is your friend ;)\nTell things as you see them. Politely -you're not Linus-, but don't sugar-coat it. We know some parts of our code is poorly written, poorly documented, etc. It stands out, so you will know when you dig in. No one is going to be offended by having that code rewritten or refactored. Peer review applies to everybody's work and is done by everybody.\nCross project proposals\nBecause we use a number of libraries and in fact \u0026quot;are a library\u0026quot; ourselves (meaning other programs can link CCExtractor as a library, or invoke the binary) we interact with other communities and their software. From time to time there's a chance to do something interesting that affects CCExtractor and something else (FFmpeg comes to mind, but also Kodi, VLC, libGPAC, Red Hen, to mention just a few of our friends that typically participate in Summer of Code). So how does this work? As long as the work benefits CCExtractor and it's part of your summer project, we're OK with you spending some time on the other project. For example if you are improving our MP4 support, for which we use libGPAC, and need to fix or improve something on libGPAC you are welcome to do so. If you do, make sure you submit your changes to their maintainers and follow through with their merge process.\nYour proposal\nYou can propose to do any of the following ideas, or you can bring your own. In any case, make sure you run them by us before you actually submit your proposal.\nAt the very least your proposal needs to\n  Explain what you do want to do, why it is important to you (don't make up a story here - the reason can be that you need it, that you just think it's cool, that you have an itch to work on it, etc), and why it could be important or useful to us. - Explain how you intend to accomplish the goal, in enough detail that makes it clear that you have done your homework. For example, \u0026quot;I will modify the CCExtractor binary so that it's able to convert audio to text with perfect accuracy\u0026quot; is the same thing as sending your proposal to the trash. You need to have a plan. - Detail the timeline explaining what the expected progress is for each week or every two weeks (pay special attention to the milestones within the GSoC timeline itself, of course) and how we should validate the results. - Detail what kind of support you will need from us. For example, if you are going to need test streams, hardware, access to a server, etc, let us know, so we can prepare everything for you as soon as possible. - Detail your expected working hours in UTC. We're used to weird working schedules, so don't worry about working in the middle of the night, or weekends instead of other days, etc. Knowing your hours may help us to match you better with a mentor.\n  Mention your planned absences. We don't need you to detail what you will be doing when you are not working of course, but if you are going away for any reason we need to know so we don't think you've abandoned. - Link to your GitHub (or any other repository) profile, if you have one, so we can take a look at your previous work. - GSoC is a coding program: This means that ideas that are about testing (unless it involves coding something to test our programs ;) ), website design, etc, are out. - However, we want to have good documentation: Make sure you have time to write a good technical article explaining your work. - Be realistic and honest with the timeline. Consider each week you should work around 30 hours. If your timeline reserves a lot of time for minor things we'll think that you are not going to be working full-time in GSoC. On the other hand if you promise to do things in a lot less than that it seems realistic to us it will seem that you don't really know how much work things take. - If you are going to be using 3rd party libraries (that's OK), make sure to validate that their license is compatible with GPLv2 (which is ours). List the libraries in your proposal. Check that they are cross-platform. If you will need to extend those libraries in any way please explain. In this case, your proposal should include time to get that extension submitted to the maintainers (we love to contribute to other projects).\n  Something else: Mentors often have their fingers in several pies. If you send the same proposal to several orgs everyone will know. So do yourself a favor and don't do that. You can apply to several organizations and that's totally fine, but each organization will want to see that you have put the time to write a great proposal that is focused on them.\nThe ideas we currently have\nImportant: If you have something else in mind that relates to subtitles and accessibility please get in touch. We prefer that you do something that you are passionate about even if it's something we hadn't considered.\n   Name Description Tech you need to know Tech you will learn Difficulty     Complete 708 support This is one of the big ones. Why? Because it's been on our wish list for some time and until now no one has decided to really go for it; after the initial work it's always been incremental improvements, but no one has raised their hand and said \u0026quot;I'm going to complete this\u0026quot;. It's possible the code base it's not really friendly. Who knows. If this is the case we're OK with a total rewrite if that's what it takes to get this done. The details page has some more information if this picked your interest. C Video standards Subtitle standards CCExtractor internals Internationalization Hard   Work on JokerTV integration JokerTV is an excellent open hardware and software platform (think Arduino, but for TV). It's still early days, and we really want to be among the first supporting this amazing new platform. JokerTV can receive signals from all TV standards around the world (finally!, no more European or American models, etc). We will buy one device for the student (or students, if their ideas are different) that works on this. Abylay Ospan, the genius behind JokerTV has agreed to mentor. C Hardware Video standards Joker (the platform) Unknown   Write Python bindings for CCExtractor This was partially done during GSoC 2017, but it's not complete. You may choose to continue the work already done, or you can come up with a more robust / fast / etc approach. What we currently have \u0026quot;sort of works\u0026quot; but we've seen leaks, crashes ... so it's definitely not production ready. C Python Obscure C+Python topics CCExtractor internals Medium   Write high speed subtitle synchronization tools This one must be hard - it's the one project that unfortunately failed during 2017, even though it's a really interesting one that touches many areas (math, sound analysis...). We can provide you all the work done last year (including the winner's proposal and current code) or you can start over. Your choice Audio Video formats Optimization Algorithms Hard   Add support for DTMB countries DTMB is the standard for Chinese TV, also implemented by countries such as Cuba. What kind of student is ideal for this task? One with lots of analytic skills and patience. If you are one of those, don't disregard this task just because you don't speak (or maybe, even care) about Chinese. The experience on dealing with this will be extremely valuable in the future. We will use part of the organization funds to buy standard documents you might need, a capture device, and in general, anything required to make your life easier. C DTMB Video standards Hardware Research Unknown   Detect Automatically the most interesting bits of sample videos Write software that is able to detect, for some kind of videos, the most interesting bits (highlights). Your choice Algorithms Unknown   Project Nephos  Cloud based storage for a massive collection of TV recordings Your choice Cloud services Scalability Medium   Improve our OCR subsystem  We use tesseract to OCR bitmap based subtitles. In theory this is straight forward, but when you take into consideration all variants (color, languages, subtitles burned-in image, even moving text such as tickers) the complexity grows fast. Still, the work done by PhD students in the past is great, and we're confident this year we can complete the work on this area if someone of the same caliber decides to join the effort. C Tesseract Imaging OCR Suspected hard   The Real time subtitles project We have a great proof of concept on real time subtitles. It's rock solid (except when we're working on it), and we're really proud of it. The part of sending the subtitles to the website is completed as you can see, but of course we need more functionality added to it. Which functionality? We'd like to hear proposals. Obvious things such as adding everything to a searchable database come to mind, but that's not really a summer worth of work. So come up with 3 months worth of improvements you can think of. NodeJS Web Depends on your idea Medium   The sample platform (/ continuous integration) project The sample platform is a good way to help new contributors to check if their code doesn't introduce any regressions. It's pretty stable, but has some downsides that have been known for a while and that should finally be solved. Most of the items that are on the issue list (see the issues page) should all be solvable in less than a summer... So if you plan on working on the platform, you'll have to come up with some small extra things to make sure you're busy the entire summer ;) Python (majority) HTML, CSS JS Bash Continuous Integration (CI) Automated deployments GitHub integration Medium   Add support for Live TV over the internet (such as YouTube TV)  A number of platforms are appearing these days to distribute local TV content over the internet. For example, YouTube now has live TV. The goal is to add support for these new content distribution platforms. We will take care of the subscription cost. Network analysis Live streaming techniques Unknown    ","link":"https://ccextractor.org/public/gsoc/ideas_page_for_summer_of_code_2018/","title":"Google Summer of Code (GSoC) 2018 ideas page"},{"body":"Welcome to our ideas page. This is going to be an amazing year - lots of new things to work on, including JokerTV, a totally open TV receiver, plus several experimental/for fun projects. Projects in C, Node, Python... you name it, we have it. Plus resources for students - we'll give access to a high speed server, all our samples (we'll even ship a portable drive with them anywhere in the world, so don't worry about slow connections).\nYou are welcome to check out our ideas page (this is it - actual ideas at the bottom of the page) and start early in the community bonding process as well as learning a bit about our code. And of course, we'd love you to stay around even if we are not invited to GSoC or if we cannot invite you as a student.\nAbout us\nWe are a small org, which means that your contribution will have a large impact. It's not going to mean a 0.5% improvement on a big project - it's going to be more than 10% on a medium size one. If you like challenges and want a chance to shine this is your place.\nWe have -we think- statistically amazing continuity in the team: Most GSoC students from all the past years are still involved, even if they are no longer eligible as students. They still contribute code, and they mentor both in GSoC and the sister program GCI. As mentors, they also come to the Summer of Code summit which traditionally takes place in October.\nWe have mentors all over the world (North America, Europe, Asia and Australia), so time zones are never a problem. Our main channel of communication is a Slack channel to which everyone is welcome. We expect all accepted students to be available on Slack very often, even if you don't need to talk to your mentor. This will help you ask questions when necessary, and you might be able to help others out as well while working on your project.\nException: If your country (such as Russia) has banned Slack please get in touch in we'll work out a solution with you. We absolutely want you to participate.\nA mailing list is also available for those that prefer email over slack. It's a new mailing list (the old one hasn't been used in a long time) but it's read by everyone involved in GSoC.\nAll our top committers will be mentoring. Many of them are former GSoC students or winners of GCI.\nBooks / other references\nThis year we're going to try something new. All accepted students will get a programming book immediately after being accepted, with the hope that they read them before the coding starts. We want to see if this increases the quality of the work. So far we have selected these three books (pick one), but we're open to suggestions: Clean Code, Elements of Programming Interviews in Python, Cracking the code interview.\nThe student working on CEA-708 will also receive a copy of the latest CEA-708 specification document.\nAbout what we use\nThe core tool that names the organization (CCExtractor) is a command-line program written in C (not C++). The current Windows GUI is written in C#, and we have another GUI for Linux that's written with Qt, and a small GUI that's integrated into the main program (C). The testing tool we use to run regression tests is mainly written in Python, but it also used Javascript, CSS and some shell scripting. The Test suite is written in C#. The prototype real time subtitle website is written in NodeJS. We also have a number of support tools that do a number of different things, from downloading subtitles from streaming services to translating them with Google Translate or DeepL. Most of them are written in Python, but since they are small tools that do their job you don't need to worry much about them. For totally new things you can use whatever tool you feel is best for the job.\nSupport tool\nIf for any reason you want to show us your desktop or we want you to take a look at one of the mentors we'll use getsee (no account needed and free). Feel free to take a look at it in advance.\nAbout sample media and other resources\nWe work with huge files. Not all of them are huge, but many are. We know that many students don't have access to high speed internet. To those students we will ship (as soon as they are selected) a portable hard drive with all our samples. So if your internet connection is not good, don't worry - as long as you can plug a USB drive to your development computer you can participate with us.\nWe also have a shared Linux development server with lots of storage and a Gigabit uplink. Students get an account on it and they are welcome to use it. There's nothing there except our own work, so it's a trusted environment (for a server that is connected to internet of course).\nThe sample platform also hosts a bunch of samples, both which are small or decently sized.\nSome projects have specific requirements: For example to add support for JokerTV you will need a physical JokerTV device. We will send one to the student that takes this project well before GSoC starts. The LiveTV project requires a subscription to YouTube with LiveTV (whatever it's called this week) and Hulu. We will pay for those. If your project requires some cloud resources (Google Compute Engine, for example), we will pay for that, too.\nIn general, you are not expected to pay for anything (other than your own development computer and internet, of course) related to any project.\nIf you need anything not mentioned (such as a book) let us know. Within reason, we'll help you.\nAbout the projects and getting accepted\nQualification: On top of -of course- the quality of the proposal, we will be ranking students with a points system (we introduced this two years ago, and it worked pretty well).\nWe don't have a minimum number of required points, but you definitely will need some (with equally good proposals we will rank based on acquired points). This means, the more points you get the more likely you are to be invited to join us during the summer, assuming that your proposal is good.\nYou can get points by doing one (or more) of the next options:\n1) By solving issues in our GitHub issue tracker (CCExtractor), Sample platform issues (default 1 points per issue unless specified somewhere in the issue page). Most issues have an explicit number of points that you can find in a comment.\n By joining the community in Slack. You can invite yourself here. (1 point)\n  If you are a former Code-in finalist you start with 1 point. If you were a winner, you start with 2 points. Note that there are just a few developers that meet this, so don't be discouraged if you aren't one of them. Almost no one is, but we'd love to hear from those that are.\n  By sending us a TV sample that has something we don't support. It doesn't have to be from your own country (since hopefully, we already support it), but if it is, so much the better. This is probably hard to get, since we already got all the low hanging fruit. But if your local TV has subtitles you can turn on and off, we'd love a recording.\n  Best qualification tasks\nIf you don't don't know which issues in GitHub to do, here's a list of the ones that are approachable (you don't need to dig too deep or learn many parts of the code) and useful:\nTerrible OCR results with Channel 5 (UK)\nCCExtractor won't extract subtitles from TS with no PAT/PMT\nAutomatically switch to correct encoding for 708 subtitles based on PMT data\nRequest: Allow to extract several teletext pages in one pass\n'live' raw data problem\nExtract telemetry data (which is stored in a subtitle track) from a Drone recording\nExtract EIA-608 subtitles from Matroska (.mkv)\nThe sample platform's issues are tagged with \u0026quot;gsoc-proposal-task\u0026quot;, so you can easily see what you can work on.\nCommunity etiquette\nIt goes without saying that everyone in the community has to be polite and respectful, and consider everyone else a member of a team and not a competitor.\nAll developers are part of the team, by the way. Our Slack channel has mentors, code-in participants, other students, or developers and users that are none of the above but they all play some kind of role in CCExtractor's community.\nPart of being respectful is giving consideration to everyone else's time. Most of us have day jobs, and as such are limited in the time we can use to guide you. We'd like to spend it on quality discussions, and not on things that are for example written on this website, things that you can easily retrieve by reading documentation on used libraries or on the software's help screen. Asking this kind of questions in the Slack channel shows little respect for our time. This doesn't mean you can't ask questions, but remember that being a clueless user and a lazy developer are two very different things. If you ask those questions you will probably get an answer as if you were a clueless user (polite no matter what), but if you apply to GSoC you will be considered a lazy developer. Google is your friend ;)\nTell things as you see them. Politely -you're not Linus-, but don't sugar-coat it. We know some parts of our code is poorly written, poorly documented, etc. It stands out, so you will know when you dig in. No one is going to be offended by having that code rewritten or refactored. Peer review applies to everybody's work and is done by everybody.\nCross project proposals\nBecause we use a number of libraries and in fact \u0026quot;are a library\u0026quot; ourselves (meaning other programs can link CCExtractor as a library, or invoke the binary) we interact with other communities and their software. From time to time there's a chance to do something interesting that affects CCExtractor and something else (FFmpeg comes to mind, but also Kodi, VLC, libGPAC, Red Hen, to mention just a few of our friends that typically participate in Summer of Code). So how does this work? As long as the work benefits CCExtractor and it's part of your summer project, we're OK with you spending some time on the other project. For example if you are improving our MP4 support, for which we use libGPAC, and need to fix or improve something on libGPAC you are welcome to do so. If you do, make sure you submit your changes to their maintainers and follow through with their merge process.\nYour proposal\nYou can propose to do any of the following ideas, or you can bring your own. In any case, make sure you run them by us before you actually submit your proposal.\nAt the very least your proposal needs to\n Explain what you do want to do, why it is important to you (don't make up a story here - the reason can be that you need it, that you just think it's cool, that you have an itch to work on it, etc), and why it could be important or useful to us. - Explain how you intend to accomplish the goal, in enough detail that makes it clear that you have done your homework. For example, \u0026quot;I will modify the CCExtractor binary so that it's able to convert audio to text with perfect accuracy\u0026quot; is the same thing as sending your proposal to the trash. You need to have a plan. - Detail the timeline explaining what the expected progress is for each week or every two weeks (pay special attention to the milestones within the GSoC timeline itself, of course) and how we should validate the results. - Detail what kind of support you will need from us. For example, if you are going to need test streams, hardware, access to a server, etc, let us know, so we can prepare everything for you as soon as possible. - Detail your expected working hours in UTC. We're used to weird working schedules, so don't worry about working in the middle of the night, or weekends instead of other days, etc. Knowing your hours may help us to match you better with a mentor. Mention your planned absences. We don't need you to detail what you will be doing when you are not working of course, but if you are going away for any reason we need to know so we don't think you've abandoned. - Link to your GitHub (or any other repository) profile, if you have one, so we can take a look at your previous work. - GSoC is a coding program: This means that ideas that are about testing (unless it involves coding something to test our programs ;) ), website design, etc, are out. - However, we want to have good documentation: Make sure you have time to write a good technical article explaining your work. - Be realistic and honest with the timeline. Consider each week you should work around 30 hours. If your timeline reserves a lot of time for minor things we'll think that you are not going to be working full-time in GSoC. On the other hand if you promise to do things in a lot less than that it seems realistic to us it will seem that you don't really know how much work things take. - If you are going to be using 3rd party libraries (that's OK), make sure to validate that their license is compatible with GPLv2 (which is ours). List the libraries in your proposal. Check that they are cross-platform. If you will need to extend those libraries in any way please explain. In this case, your proposal should include time to get that extension submitted to the maintainers (we love to contribute to other projects).  Something else: Mentors often have their fingers in several pies. If you send the same proposal to several orgs everyone will know. So do yourself a favor and don't do that. You can apply to several organizations and that's totally fine, but each organization will want to see that you have put the time to write a great proposal that is focused on them.\nThe ideas we currently have\nImportant: If you have something else in mind that relates to subtitles and accessibility please get in touch. We prefer that you do something that you are passionate about even if it's something we hadn't considered.\nCore subtitle tool (CCExtractor itself)\n   Name Description Tech you need to know Tech you will learn Difficulty     Add support for streaming Live TV A number of streaming platforms now offer support for internet based live TV, which is great: It lets you watch TV on the go, it lets you get rid of cable, satellite and areal antennas... unfortunately, this live TV is not standardized at all. Your job is to do the work to add suport for Hulu and Youtube. We will pay for the subscription costs as well as any required infrastructure. Any Video standards Subtitle standards Live streaming platforms Unknown   Complete 708 support This is one of the big ones. Why? Because it's been on our wish list for some time and until now no one has decided to really go for it; after the initial work it's always been incremental improvements, but no one has raised their hand and said \u0026quot;I'm going to complete this\u0026quot;. It's possible the code base it's not really friendly. Who knows. If this is the case we're OK with a total rewrite if that's what it takes to get this done. The details page has some more information if this picked your interest. This project is guaranteed to be selected if the proposal is good. C Video standards Subtitle standards CCExtractor internals Internationalization Hard   Work on JokerTV integration JokerTV is an excellent open hardware and software platform (think Arduino, but for TV). It's still early days, and we really want to be among the first supporting this amazing new platform. JokerTV can receive signals from all TV standards around the world (finally!, no more European or American models, etc). We will buy one device for the student (or students, if their ideas are different) that works on this. Abylay Ospan, the genius behind JokerTV has agreed to mentor. C Hardware Video standards Joker (the platform) Unknown   Write Python bindings for CCExtractor This was partially done during GSoC 2017, but it's not complete. You may choose to continue the work already done, or you can come up with a more robust / fast / etc approach. What we currently have \u0026quot;sort of works\u0026quot; but we've seen leaks, crashes... so it's definitely not production ready. C Python Obscure C+Python topics CCExtractor internals Medium   Write high speed subtitle synchronization tools This one must be hard - it's the one project that unfortunately failed during 2017, even though it's a really interesting one that touches many areas (math, sound analysis...). We can provide you all the work done last year (including the winner's proposal and current code) or you can start over. Your choice Audio Video formats Optimization Algorithms Hard   Add support for DTMB countries DTMB is the standard for Chinese TV, also implemented by countries such as Cuba. What kind of student is ideal for this task? One with lots of analytic skills and patience. If you are one of those, don't disregard this task just because you don't speak (or maybe, even care) about Chinese. The experience on dealing with this will be extremely valuable in the future. We will use part of the organization funds to buy standard documents you might need, a capture device, and in general, anything required to make your life easier. C DTMB Video standards Hardware Research Unknown   Improve our OCR subsystem  We use tesseract to OCR bitmap based subtitles. In theory this is straight forward, but when you take into consideration all variants (color, languages, subtitles burned-in image, even moving text such as tickers) the complexity grows fast. Still, the work done by PhD students in the past is great, and we're confident this year we can complete the work on this area if someone of the same caliber decides to join the effort. C Tesseract Imaging OCR Suspected hard    Artificial Intelligence and clever algorithms\n   Name Description Tech you need to know Tech you will learn Difficulty     Poor's man Rekognition Amazon Rekognition is a (paid) service that is able to identify celebrity faces in a picture. We want to produce a free alternative. Your choice AI Computer vision Unknown    Support tools we and other orgs use as part of their development process\n   Name Description Tech you need to know Tech you will learn Difficulty     The sample platform (/ continuous integration) project The sample platform is a good way to help new contributors to check if their code doesn't introduce any regressions. It's pretty stable, but has some downsides that have been known for a while and that should finally be solved. Most of the items that are on the issue list (see the issues page) should all be solvable in less than a summer... The main focus this year should be on improving the comparison mechanism to determine regressions. Python (majority) C# Continuous Integration (CI) Automated deployments GitHub integration Medium    Cool things that use CCExtractor\n   Name Description Tech you need to know Tech you will learn Difficulty     The Real time subtitles project We have a great proof of concept on real time subtitles. It's rock solid (except when we're working on it), and we're really proud of it. The part of sending the subtitles to the website is completed as you can see, but of course we need more functionality added to it. Which functionality? We'd like to hear proposals. Obvious things such as adding everything to a searchable database come to mind, but that's not really a summer worth of work. So come up with 3 months worth of improvements you can think of. NodeJS Web Depends on your idea Medium    New things we're currently interested on\n   Name Description Tech you need to know Tech you will learn Difficulty     Improve PiPot  PiPot (Micro Honeypot for RPi) is a flexible honeypot for (industrial) environments that runs on a Raspberry Pi. We want to reduce the amount of open issues, which include new features Python (majority) Bash Security concepts Medium to Hard   Create a web interface for rclone (mentored by Nick Craig-Wood, rclone's developer)  rclone is a fantastic tool to synchronize cloud storage. It's rsync for the cloud. Amazing as it is it lacks a web interface. Your job is to create a great one. Really great. Not just a wrapper around the command line tool. Cloud (lots) Web (different tech) - Medium   SwagLyrics for Spotify Fetches the currently playing song from Spotify on Windows, Linux and macOS and displays the lyrics in the command-line or in a browser tab. Refreshes automatically when song changes. The lyrics are fetched from Genius. Mainly built on Python and Flask but also uses HTML, CSS, JS, AppleScript and SQL under the hood. Of course we need more functionality added to it. Which functionality? We'd like to hear proposals. Things such as syncing lyrics to the song come to mind, but we want to hear what you can come up with. So come up with 3 months worth of improvements you can think of. Python (mainly) Flask Depends on your idea, some Web (different tech) Medium to Unknown    ","link":"https://ccextractor.org/public/gsoc/ideas_page_for_summer_of_code_2019/","title":"Google Summer of Code (GSoC) 2019 ideas page"},{"body":"Welcome to our ideas page. It's great you want to start early. Please join us in our slack channel! (we'll leave as an exercise to you to find it --- it's on our website).\nThis is going to be an amazing year --- lots of new things to work on, including JokerTV, a totally open TV receiver, plus several experimental/for fun projects. Projects in C, Node.js, Python, Rust and more, you name it, we have it. Plus resources for students --- we'll give access to a high-speed server, all our samples (we'll even ship a portable drive with them anywhere in the world, so don't worry about slow connections) and various other perks.\nYou are welcome to check out the page (actual ideas at the bottom of the page, with each project having it's own separate page as well) and start early in the community bonding process as well as learning a bit about our code ethics and practices. And of course, we'd love you to stay around even if we are not invited to GSoC or if we cannot invite you as a student.\nThe ideas we currently have Important: If you have something else in mind that relates to subtitles and accessibility please get in touch. We prefer that you do something that you are passionate about even if it's something we hadn't considered.\nAfter you check out our ideas please continue reading to the bottom of the page to get information about who we are, how we collaborate, what resources we will provide to you, etc.\nSome tasks descriptions are still vague. We know that. Feel free to get in touch for questions, or just check their page from time to time. We will update the descriptions often.\nCore subtitle tool (CCExtractor itself)    Name Description Tech you need to know Tech you will learn Difficulty     Complete 708 support This is one of the big ones. Why? Because it's been on our wish list for some time and until now no one has decided to really go for it; after the initial work it's always been incremental improvements, but no one has raised their hand and said \u0026quot;I'm going to complete this\u0026quot;. It's possible the code base is not really friendly. Who knows. If this is the case we're OK with a total rewrite if that's what it takes to get this done. The details page has some more information if this picked your interest. This project is guaranteed to be selected if the proposal is good. C Video standards Subtitle standards CCExtractor internals Internationalization Hard   Add support for streaming Live TV A number of streaming platforms now offer support for internet based live TV, which is great: It lets you watch TV on the go, it lets you get rid of cable, satellite and areal antennas... unfortunately, this live TV is not standardized at all. Your job is to do the work to add suport for Hulu and Youtube. We will pay for the subscription costs as well as any required infrastructure. Any Video standards Subtitle standards Live streaming platforms Unknown   Work on JokerTV integration JokerTV is an excellent open hardware and software platform (think Arduino, but for TV). It's still early days, and we really want to be among the first supporting this amazing new platform. JokerTV can receive signals from all TV standards around the world (finally!, no more European or American models, etc). We will buy one device for the student (or students, if their ideas are different) that works on this. Abylay Ospan, the genius behind JokerTV has agreed to mentor. C Hardware Video standards Joker (the platform) Unknown   Write Python bindings for CCExtractor This was partially done during GSoC 2017, but the approach was totally wrong --- a wrapper, instead of Cython. Let's cut our losses and start over. C Python Obscure C+Python topics CCExtractor internals Medium   Add support for DTMB countries DTMB is the standard for Chinese TV, also implemented by countries such as Cuba. What kind of student is ideal for this task? One with lots of analytic skills and patience. If you are one of those, don't disregard this task just because you don't speak (or maybe, even care) about Chinese. The experience on dealing with this will be extremely valuable in the future. We will use part of the organization funds to buy standard documents you might need, a capture device, and in general, anything required to make your life easier. C DTMB Video standards Hardware Research Unknown   Improve our OCR subsystem  We use tesseract to OCR bitmap based subtitles. In theory this is straight forward, but when you take into consideration all variants (color, languages, subtitles burned-in image, even moving text such as tickers) the complexity grows fast. Still, the work done by PhD students in the past is great, and we're confident this year we can complete the work on this area if someone of the same caliber decides to join the effort. C Tesseract Imaging OCR Suspected hard   Add Japanese support  Captions are used by people all over the world on a regular basis. Most of us are familiar with regular horizontal captions at the bottom of the screen, but did you know that in Japan a common position for captions is vertically on the right or left side of the screen? Come learn more about what Japanese audiences need out of captions as well as how captioning standard likes IMSC and WebVTT support these features. Japanese (or be good with foreign languages) Depends Suspected hard    Artificial Intelligence and clever algorithms    Name Description Tech you need to know Tech you will learn Difficulty     Poor man's Rekognition (II) Amazon Rekognition is a (paid) service that is able to identify celebrity faces in a picture. Last year we did some work towards creating a free alternative. This year we want to improve on the past work. Your choice AI Computer vision Unknown   Poor man's Textract Amazon Textract a (paid) service that \u0026quot;automatically extracts text and data from scanned documents. Amazon Textract goes beyond simple optical character recognition (OCR) to also identify the contents of fields in forms and information stored in tables.\u0026quot;. We want to build a free alternative that provides an output of similar quality. Your choice AI Computer vision OCR Unknown    Support tools we and other orgs use as part of their development process    Name Description Tech you need to know Tech you will learn Difficulty     The sample platform (/ continuous integration) project The sample platform is a good way to help new contributors to check if their code doesn't introduce any regressions. It's pretty stable, but is often hard to interpret for new contributors, and still pretty slow if the queue builds up. We want to take the concepts of this existing platform and re-write it from scratch making use of the horizontally scalable cloud options that are nowadays available. This project is guaranteed to be selected if the proposal is good. Git Python Cloud services API's GitHub Actions GitHub API's Continuous Integration (CI) Automated deployments GitHub integration Medium/Hard    New things we're currently interested on    Name Description Tech you need to know Tech you will learn Difficulty     A reference channel for Roku  Roku is currently the most common media streamer. It's cheap and neutral (it's not in any \u0026quot;fight\u0026quot;). Unfortunately, there aren't any good open source channels, so if you want to start your own you have to start from scratch. We want to fix that by creating the \u0026quot;reference\u0026quot; source code for a generic channel. We will send a free Roku to our student for development. None Brightscript Roku Video Streaming Medium   An \u0026quot;algorithm video creator\u0026quot; in Python  During Google Code-in we got some proof of concepts that are actually quite cool. We want to build a complete tool that helps study and understand algorithms Python Python internals Algorithms Medium   FFmpeg + Rust  This project is two fold: One, is create proper Rust bindings into FFmpeg's libraries. The 2nd, and harder, is create a \u0026quot;graph to code\u0026quot; generator C or C++ FFmpeg's internals Rust Possibly hard   Extend rclone's web UI (mentored by Nick Craig-Wood, rclone's developer)  rclone is a fantastic tool to synchronize cloud storage. It's rsync for the cloud. Last year we started a web UI, and it was a successful GSoC project. We want to continue working on it. Cloud (lots) Web (different tech) --- Medium   SwagLyrics Last Summer of Code, we came up with a platform to align lyrics to their temporal location in the audio (https://github.com/SwagLyrics/autosynch). This year, we want to improve it, and integrate it to SwagLyrics proper. Python (mainly) Depends on your idea Medium to Unknown   Vote counter and reporter  More and more countries depend on electronic vote counting and/or reporting in their elections, and apparently no one can get this right. Either no one knows how to do it or they know exactly what they are doing. Both things are worrying, to say the least. We want to spend this summer working on an open-source solution everybody and use and audit, in any country. Systems design Flutter (frontend), your choice (backend) Hard   Mouseless for Linux  Mouseless is a nice tool to practice keyboard shortcuts for a few popular apps. Unfortunately it's only available for Mac. We'd like to create an open-source Linux version that can be easily extended. Your choice ?? Unknown   rutorrent mobile interface  rutorrent is the most popular web interface for rtorrent, which is possibly the most used BitTorrent client in linux. The job is to write a Flutter based web interface that uses rutorrent's backend service to provide a native interface. Flutter BitTorrent Medium   The next peer-to-peer protocol  BitTorrent is of course the world's most used peer to peer protocol. It's great, but it was designed before the cloud was ubiquitous and it doesn't make use of the places where you have the most storage or the most bandwidth. Can we design something for the next decade? Depends Peer-to-peer, cloud Medium   Linux tuning for network throughput  Come up with a system that tunes the linux kernel to maximize network throughput for a number of workloads, such as web server or BitTorrent Linux Kernel internals, Networking Hard    About us We are a small org, which means that your contribution will have a large impact. It's not going to mean a 0.5% improvement on a big project --- it's going to be more than 10% on a medium size one. If you like challenges and want a chance to shine this is your place.\nWe have we think statistically amazing continuity in the team: Most GSoC students from all the past years are still involved, even if they are no longer eligible as students. They still contribute code, and they mentor both in GSoC and the sister program GCI. As mentors, they also come to the Summer of Code summit which traditionally takes place in October.\nWe have mentors all over the world (North America, Europe, Asia and Australia), so time zones are never a problem. Our main channel of communication is a Slack channel to which everyone is welcome. We expect all accepted students to be available on Slack very often, even if you don't need to talk to your mentor. This will help you ask questions when necessary, and you might be able to help others out as well while working on your project.\nException: If your country (such as Russia) has banned Slack please get in touch in we'll work out a solution with you. We absolutely want you to participate.\nA mailing list is also available for those that prefer email over slack. It's a new mailing list (the old one hasn't been used in a long time) but it's read by everyone involved in GSoC.\nAll our top committers will be mentoring. Many of them are former GSoC students or winners of GCI.\nPerks All accepted students get a programming book immediately after being accepted, with the hope that they read them before the coding starts. We want to see if this increases the quality of the work. So far we have selected these three books (pick one), but we're open to suggestions: Clean Code, Elements of Programming Interviews in Python, Cracking the code interview.\nWe will also provide to all accepted students: - 6 months of access (from the acceptance date) to all courses in educative.io - 12 months of access (from the acceptance date) to backtobackswe, which is a fantastic resource to learn algorithms, prepare for coding interviews, and in general learn fundamentals.\nThe student working on CEA-708 will also receive a copy of the latest CEA-708 specification document.\nAbout what we use This is what we use today. It doesn't mean this is what we want to continue using. Probably not --- we're really open to change. We're just describing the status quo so you know what you are getting into :-)\nThe core tool that names the organization (CCExtractor) is a command-line program written in C (not C++).\nThe current Windows GUI is written in C #, and we have another GUI for Linux that's written with Qt, and a small GUI that's integrated into the main program (C). In we're being honest, nothing is great. Good news for you is that you can start over if you want.\nThe testing tool we use to run regression tests is mainly written in Python, but it also used Javascript, CSS and some shell scripting. The Test suite is written in C#. One of the projects this year is about replacing it.\nThe prototype real time subtitle website is written in NodeJS.\nWe also have a number of support tools that do a number of different things, from downloading subtitles from streaming services to translating them with Google Translate or DeepL. Most of them are written in Python, but since they are small tools that do their job you don't need to worry much about them.\nFor totally new things you can use whatever tool you feel is best for the job.\nAbout sample media and other resources We work with huge files. Not all of them are huge, but many are. We know that many students don't have access to high speed internet. To those students we will ship (as soon as they are selected) a portable hard drive with all our samples. So if your internet connection is not good, don't worry --- as long as you can plug a USB drive to your development computer you can participate with us.\nWe also have a shared Linux development server with lots of storage and a Gigabit uplink. Students get an account on it and they are welcome to use it. There's nothing there except our own work, so it's a trusted environment (for a server that is connected to internet of course).\nThe sample platform also hosts a bunch of samples, both which are small or decently sized.\nSome projects have specific requirements: For example to add support for JokerTV you will need a physical JokerTV device. We will send one to the student that takes this project well before GSoC starts. The LiveTV project requires a subscription to YouTube with LiveTV (whatever it's called this week) and Hulu. We will pay for those. If your project requires some cloud resources (Google Compute Engine, for example), we will pay for that, too.\nIn general, you are not expected to pay for anything (other than your own development computer and internet, of course) related to any project.\nIf you need anything not mentioned (such as a book) let us know. Within reason, we'll help you.\nAbout the projects and getting accepted Qualification: Our selection system is based on several factors. Of course no student ranks in all criteria, so don't worry when you read the list below.\nWork on our core tool: Even if you are going to be working on something totally different. This might seen counter intuitive, but the thing is if you prove you can dig into our (messy) code base, find yourself your way around it, and fix a few bugs, you are just the kind of person we can trust to \u0026quot;figure things out\u0026quot;. GSoC is among other things, a learning experience. No matter what project you decide to work on, there's going to be roadblocks, things you don't know how to do, etc. So we really like it when students embrace those situations.\nQualification tasks specific to the project: The detail page for some projects contains specific qualification tasks that apply to them.\nContributions to existing open source projects: This can be anything. From a good GitHub profile to pull-requests sent to any other existing project, participation in hackathons, Google Code-In, past GSoCs and so on.\nA good proposal: This is the one criteria that is non-negotiable. Your proposal has to be good, period.\nProject popularity: Some ideas just have more competition, so if participating in GSoC is a top priority for you (over working on a specific project), consider applying to one of the \u0026quot;niche\u0026quot; ideas. After all, that's a great way to get your foot in the door :-)\nBest core tool tasks\nWe're added a difficulty level to all our open issues on GitHub. Best thing you can do is head there and see if you are able to fix some of the easy ones and work your way up. We don't expect you to be able to do the hard ones but we'd be impressed if you did :-)\nFor some of the easy ones you don't even need to know C. Just being able to compile CCExtractor and dig around a bit will be enough.\nThe sample platform's issues are tagged with \u0026quot;gsoc-proposal-task\u0026quot;, so you can easily see what you can work on.\nTake home qualification tasks If instead of working on existing code you'd prefer to show us your skills working on something new, you can pick one of these projects.\nCommunity etiquette It goes without saying that everyone in the community has to be polite and respectful, and consider everyone else a member of a team and not a competitor.\nAll developers are part of the team, by the way. Our Slack channel has mentors, code-in participants, other students, or developers and users that are none of the above but they all play some kind of role in CCExtractor's community.\nPart of being respectful is giving consideration to everyone else's time. Most of us have day jobs, and as such are limited in the time we can use to guide you. We'd like to spend it on quality discussions, and not on things that are for example written on this website, things that you can easily retrieve by reading documentation on used libraries or on the software's help screen. Asking this kind of questions in the Slack channel shows little respect for our time. This doesn't mean you can't ask questions, but remember that being a clueless user and a lazy developer are two very different things. If you ask those questions you will probably get an answer as if you were a clueless user (polite no matter what), but if you apply to GSoC you will be considered a lazy developer. Google is your friend ;)\nTell things as you see them. Politely -you're not Linus-, but don't sugar-coat it. We know some parts of our code is poorly written, poorly documented, etc. It stands out, so you will know when you dig in. No one is going to be offended by having that code rewritten or refactored. Peer review applies to everybody's work and is done by everybody.\nCross project proposals Because we use a number of libraries and in fact \u0026quot;are a library\u0026quot; ourselves (meaning other programs can link CCExtractor as a library, or invoke the binary) we interact with other communities and their software. From time to time there's a chance to do something interesting that affects CCExtractor and something else (FFmpeg comes to mind, but also Kodi, VLC, libGPAC, Red Hen, to mention just a few of our friends that typically participate in Summer of Code). So how does this work? As long as the work benefits CCExtractor and it's part of your summer project, we're OK with you spending some time on the other project. For example if you are improving our MP4 support, for which we use libGPAC, and need to fix or improve something on libGPAC you are welcome to do so. If you do, make sure you submit your changes to their maintainers and follow through with their merge process.\nYour proposal You can propose to do any of the following ideas, or you can bring your own. In any case, make sure you run them by us before you actually submit your proposal.\nAt the very least your proposal needs to\n Explain what you do want to do, why it is important to you (don't make up a story here — the reason can be that you need it, that you just think it's cool, that you have an itch to work on it, etc), and why it could be important or useful to us. Explain how you intend to accomplish the goal, in enough detail that makes it clear that you have done your homework. For example, “I will modify the CCExtractor binary so that it's able to convert audio to text with perfect accuracy” is the same thing as sending your proposal to the trash. You need to have a plan. Detail the timeline explaining what the expected progress is for each week or every two weeks (pay special attention to the milestones within the GSoC timeline itself, of course) and how we should validate the results. Detail what kind of support you will need from us. For example, if you are going to need test streams, hardware, access to a server, etc, let us know, so we can prepare everything for you as soon as possible. Detail your expected working hours in UTC. We're used to weird working schedules, so don't worry about working in the middle of the night, or weekends instead of other days, etc. Knowing your hours may help us to match you better with a mentor. Mention your planned absences. We don't need you to detail what you will be doing when you are not working of course, but if you are going away for any reason we need to know so we don't think you've abandoned. Link to your GitHub (or any other repository) profile, if you have one, so we can take a look at your previous work. GSoC is a coding program: This means that ideas that are about testing (unless it involves coding something to test our programs ;) ), website design, etc, are out. However, we want to have good documentation: Make sure you have time to write a good technical article explaining your work. Be realistic and honest with the timeline. Consider each week you should work around 30 hours. If your timeline reserves a lot of time for minor things we'll think that you are not going to be working full-time in GSoC. On the other hand if you promise to do things in a lot less than that it seems realistic to us it will seem that you don't really know how much work things take. If you are going to be using 3rd party libraries (that's OK), make sure to validate that their license is compatible with GPLv2 (which is ours). List the libraries in your proposal. Check that they are cross-platform. If you will need to extend those libraries in any way please explain. In this case, your proposal should include time to get that extension submitted to the maintainers (we love to contribute to other projects).  Something else: Mentors often have their fingers in several pies. If you send the same proposal to several orgs everyone will know. So do yourself a favor and don't do that. You can apply to several organizations and that's totally fine, but each organization will want to see that you have put the time to write a great proposal that is focused on them.\nUseful resources A great resource for GSoC.\n","link":"https://ccextractor.org/public/gsoc/ideas_page_for_summer_of_code_2020/","title":"Google Summer of Code (GSoC) 2020 ideas page"},{"body":"About us\nWe are a small org, which means that your contribution is expected to have a very large impact. It's not going to mean a 0.5% improvement on a big project - it's supposed to be like 10% on a medium size one. So please come only if you like the challenge and feel like that you are ready to have a serious responsibility.\nWe have -we think- statistically amazing continuity in the team: Most GSoC students from all the past years are still involved, even if they are no longer eligible as students. They still contribute code, and they mentor both in GSoC and code-in. So while you don't have to do it, we really prefer students that consider their GSoC participation as a starting point of joining a developer community, not a summer gig.\nWe have mentors in North America, Europe, Asia and Australia. Time zones are never a problem. We hang out in a slack channel to which everyone is welcome. If you get accepted we expect to see you there often. Even if you don't need to talk to your mentor, please try to be around when working.\n__** About what we use **__\nThe core tool that names the organization (CCExtractor) is a command-line program written in C (not C++). The current Windows GUI is written in C# but one of the ideas is about replacing it. The testing tool we use to run regression tests is written in Python. The prototype real time subtitle website is written in NodeJS. For totally new things you can use whatever tool you feel is best for the job.\n__** About the projects and getting accepted **__\nQualification: In order to qualify you need to achieve a minimum of 7 points. You get points:\n1) By solving issues in our GitHub issue tracker (CCExtractor), Sample platform issues (default 1 points per issue unless specified somewhere in the issue page). Most issues have an explicit number of points that you can find in a comment. 2) By joining the community in slack. You can invite yourself here. (1 point) 3) If you are a former Code-in finalist you start with 1 point. If you were a winner, you start with 2 points. Note that there are just a few developers that meet this, so don't be discouraged if you aren't one of them. Almost no one is, but we'd love to hear from those that are. 4) By sending us a TV sample that has something we don't support. It doesn't have to be from your own country (since hopefully, we already support it), but if it is, so much the better. This is probably hard to get, since we already got all the low hanging fruit. But if your local TV has subtitles you can turn on and off, we'd love a recording.\nGetting 7 points doesn't guarantee that you will be accepted as that depends on the quality of your proposal (which also needs to be good) and the amount of slots Google allocates to us. Students without 7 points will not be accepted no matter what. If we have more slots than students with the minimum score we will just give those slots back to the pool so other orgs can use them.\n**You have until April 20th to get the points. You can work in your proposal first if needed so you can submit it and then work on the points. **\n__** Community etiquette **__\nIt goes without saying that everyone in the community has to be polite and respectful, and consider everyone else a member of a team and not a competitor.\nAll developers are part of the team, by the way. Our slack channel has mentors, code-in participants, other students, are developers and users that are none of the above but that play some kind of role in CCExtractor.\nPart of being respectful is giving consideration to everyone else's time. For example asking things that are written in the website or in the software help screen shows little respect. We don't want to seem unfriendly, but asking in the slack channel something like \u0026quot;isn't there a GUI?\u0026quot;, \u0026quot;how do I run this\u0026quot;, etc, is not a great way to start. This doesn't mean you can't ask questions, but remember than being a clueless user and a lazy developer are two very different things. If you ask those questions you will probably get an answer as if you were a clueless user (polite no matter what), but if you apply to GSoC you will be considered a lazy developer.\n__** Your proposal **__\nYou can propose to do any of the following ideas, or you can bring your own. In any case, make sure you run them by us before you actually submit your proposal.\nImportant: __The first two weeks must be allocated to solve bugs listed in GitHub__. Yes, we know it's a chore and that you would rather work immediately on the new great thing. But experience has proven that these two weeks are extremely useful to bond with the rest of the community, get you introduced to the existing code base, and of course the bonus that bugs will actually be fixed. If you really don't want to spend any time on this __we will waive this requirement for students with 15 qualification points__ (see above).\nAt the very least your proposal needs to\n- Explain what you do want to do, why it is important to you, and why it is important or useful to us. - Explain how you intend to accomplish the goal, in enough detail that makes it clear that you know what you are talking about. For example, \u0026quot;I will modify the CCExtractor binary so that it's able to convert audio to text with perfect accuracy\u0026quot; is the same thing as sending your proposal to the trash. You need to have a plan. - Detail the timeline, week by week, explaining the deliverables for each week (pay special attention to the milestones within the GSoC timeline itself, of course) and how we should validate the results. - Detail what kind of support you will need for us. For example, if you are going to need test streams, hardware, access to a server, etc, let us know, so we can plan ahead. - Detail your expected working hours in UTC. - Detail your planned absences. We don't need you to detail what you will be doing when you are not working of course, but if you are going away for any reason we need to know so we don't think you've abandoned. - Link to your GitHub profile, if you have one, so we can take a look at your previous work. - GSoC is a coding program: This means that ideas that are about testing, website design, etc, are out. - However, we want to have good documentation: Make sure you have time to write a good technical article explaining your work. - Be realistic and honest with the timeline. Consider each week you should work around 40 hours. If your timeline reserves a lot of time for minor things we'll think that you are not going to be working full-time in GSoC. On the other hand if you promise to do things in a lot less than that it seems realistic to us it will seem that you don't really know how much work things take. - If you are going to be using 3rd party libraries (that's OK), make sure to validate that their license is compatible with GPLv2 (which is ours). List the libraries in your proposal. Check that they are multiplatform. If you will need to extend those libraries in any way please explain. In this case, your proposal should include time to get that extension submitted to the maintainers (we love to contribute to other projects).\nSomething else: Mentors often have their fingers in several pies. If you send the same proposal to several orgs everyone will know. So do yourself a favor and don't do that. You can apply to several organizations and that's totally fine, but each organization will want to see that you have put the time to write a great proposal that is focused on them.\n__The ideas we currently have__\nImportant: If you have something else in mind that relates to subtitles and accessibility please get in touch. We prefer that you do something that you are passionate about even if it's something we hadn't considered.\nWrite high speed subtitle synchronization tools\nAdd support for DTMB countries\nDetect Automatically the most interesting bits of sample videos\nDo word by word subtitle-audio sync\nWrite Python bindings for CCExtractor\nCreate a integrated GUI, replacing what we have\nComplete 708 support\nA web-site to view captions in real-time\nProject Nephos: Cloud based storage for a massive collection of TV recordings\nEnable automated testing on windows and other general sample platform improvements \n","link":"https://ccextractor.org/public/gsoc/ideas_page_for_summer_of_code_2017/","title":"Google Summer of Code 2017 ideas page"},{"body":"Add support for DTMB countries\nDTMB is the Chinese TV standard, adopted by other countries such as Cuba. We still don't know much about it. Due to this, your proposal must include:\na) A link to the relevant standard documents. We don't know if they exist in English. If they don't but you speak the language they are in, that's fine. If you locate the documents but they require payment (as is often the case for technical specifications) send us a link to buy and we'll allocate organization funds to purchase them.\nb) Some TV samples. Or, if you cannot get them directly, an explanation of how you will get them, for example by purchasing a capture card that is known to be compatible (send us an exact link), plugging it to an antenna or dish, etc, that you have access to (detail), etc.\nIn short, this is an \u0026quot;adventure\u0026quot; task. We'll go all the way with the student that tries it, but we want to make sure the chances of success are reasonable.\nThis is what we (think we) know so far: DTMB regulates the physical transmission standard (signals, frequencies, etc). It seems to be available (for purchase) here.\nCuba follows it: http://www.globaltimes.cn/content/955479.shtml http://advanced-television.com/2013/03/22/cuba-adopts-chinese-tv-standard/\nThe reason Cuba is interesting is that their subtitles will have Latin characters, which will make life a lot easier for most team members. Also, the Cuban government has a good website about their TV regulations.\nApparently the subtitles themselves follow the European DVB standard. We can see that in this document from the Hong Kong regulatory body which says:\nSubtitles: Receivers shall include provisions to decode and display subtitles conforming to ETSI EN 300 743.\nThe Cuban government says the same thing:\nThat document (in English) says: The Brand and Model TV Set is intended for the reception of DTMB Digital Terrestrial Television in 6MHz bandwidth, according to the specifications GB 20600-2006.\nDVB subtitles (ETSI EN 300 743) -- The DUT must support DVB subtitles (ETSI EN 300 743).\nImportant: Since Chinese is by far the most extended language among DTMB countries, its support is essential. We have some preliminary support for it, but whatever is missing you will need to add. This applies in particular to the .srt writer. Since .srt is text based, you need to OCR the bitmaps. This is already done but almost untested for Chinese. Don't assume it's going to work. Probably not. Give yourself time in your proposal for this.\nRelated GitHub Issues Extract subtitles in a Chinese newscast\nQualification tasks\nTake a look at this page.\n","link":"https://ccextractor.org/public/gsoc/dtmb/","title":"Google Summer of Code 2018 - Add support for DTMB countries"},{"body":"Complete 708 support\n708 is the standard for digital TV in the US and a few other countries. We have preliminary support, but the goal is a 100% accurate implementation. This means:\na) Perfect timing. b) Perfect rendering, limited only by the output format. c) Full support to all languages for which samples are available.\nWe will provide hundreds of samples (for which you must complete support, no exceptions) and access to a high speed linux server for you to work with if needed. These samples are usually very large (hundreds of megabytes each) so working locally may not be feasible for you if you don't have a great internet connection.\nFor developers in India we have someone there with an external 2 TB drive with a copy of all our samples. That drive goes from developer to developer, so if needed we can get it shipped to you.\nIf you are not in India or in a country in which just downloading the samples is the easy way, get in touch. We'll figure something out so access to media is not a problem.\nThis is a high value task and we'd love to have it done, but in order to qualify you need to fix some of the existing bugs.\nAlso part of this idea:\nhttps://github.com/CCExtractor/ccextractor/issues/733\nWhich is about implementing .mcc support, which as the GitHub ticket says complements 708 very well.\nGetting started:\nThe wikipedia page on 708 This is quite good actually. It's not a complete description of the standard, but it's quite useful to understand what 708 is about.\nRelated GitHub Issues Ver 0.85 CEA-708: 16 bit charset (Korean) Not support (problem extract Korean subtitles [[https://github.com/CCExtractor/ccextractor/issues/646|[CEA-708] Missing the last subtitle]] [[https://github.com/CCExtractor/ccextractor/issues/641|[CEA-708] [Timing] Catchable bug with timing]] Finish CEA-708 support\nMentors Carlos Fernandez Sanz (@carlos.fernandez on slack). Carlos wrote the original CEA-708 code. Evgeny Shulgin (@izaron on slack). Evgeny is a 2016 Code-In Winner with CCExtractor, and worked a lot on CEA-708.\nHow to get started Best thing you can do is download a few samples (check our TV samples page) and try to solve some of the CEA-708 issues we have listed on GitHub.\nThis is also the best way to get accepted into GSoC.\nQualification tasks\nTake a look at this page.\n","link":"https://ccextractor.org/public/gsoc/complete708support/","title":"Google Summer of Code 2018 - Complete 708 support"},{"body":"Initial Rust scaffolding\nWe want to port/rewrite CCExtractor to Rust. There are a a few reasons for it, some purely practical, and some philosophical:\n Rust is exciting, and this work is quite motivating for the team that has been working on it for a long time. Contribute to improve the situation of video support on the Rust ecosystem. Our code has grown from \u0026quot;I don't know what I'm doing\u0026quot; to \u0026quot;look ma, I support a million things now\u0026quot; and it shows. We can use the rewrite anyway. We suspect we have some exploitable code around. - We want a new generation of engineers to join us.  So with this project, everything starts. What we expect to get from it? Well, it's 175 hours or so of work, which depending on the point of view is a long or not so much. We think this is realistic:\n Change the build system to use cargo (of course). Command line parsing. Help. I/O.  Note that we don't want a line-by-line port! Cleaning up and refactoring is important as part as this work.\nThe C code you need to understand is easy to read (no magic) and you don't need any video knowledge. You do need to know some Rust, but nothing too esoteric, so if you have some Rust experience that's probably enough to get started.\nThis project will be mentored by Carlos Fernandez who will work with you closely.\n","link":"https://ccextractor.org/public/gsoc/cc_rust_scaffolding/","title":"Google Summer of Code 2021 - CCExtractor Rust scaffolding"},{"body":"Port and/or rewrite CEA-708 support to Rust\n708 is the standard for digital TV in the US and a few other countries. We have preliminary support in C. We'd like to port it to Rust, and while we are at it complete the known missing bits.\nThis means:\na) Perfect timing. b) Perfect rendering, limited only by the output format. c) Full support to all languages for which samples are available.\nWe will provide hundreds of samples (for which you must complete support, no exceptions) and access to a high speed linux server for you to work with if needed. These samples are usually very large (hundreds of megabytes each) so working locally may not be feasible for you if you don't have a great internet connection.\nFor developers in India we have someone there with an external 2 TB drive with a copy of all our samples. That drive goes from developer to developer, so if needed we can get it shipped to you.\nIf you are not in India or in a country in which just downloading the samples is the easy way, get in touch. We'll figure something out so access to media is not a problem.\nThis is a high value task and we'd love to have it done, but in order to qualify you need to fix some of the existing bugs.\nAlso part of this idea:\nhttps://github.com/CCExtractor/ccextractor/issues/733\nWhich is about implementing .mcc support, which as the GitHub ticket says complements 708 very well.\nGetting started:\nThe wikipedia page on 708 This is quite good actually. It's not a complete description of the standard, but it's quite useful to understand what 708 is about.\nRelated GitHub Issues\n Ver 0.85 CEA-708: 16 bit charset (Korean) Not support problem extract Korean subtitles [CEA-708] Missing the last subtitle [CEA-708] [Timing] Catchable bug with timing Finish CEA-708 support  Mentors Carlos Fernandez Sanz (@carlos.fernandez on slack). Carlos wrote the original CEA-708 code. Evgeny Shulgin (@izaron on slack). Evgeny is a 2016 Code-In Winner with CCExtractor, and worked a lot on CEA-708.\nHow to get started Best thing you can do is download a few samples (check our TV samples page) and try to solve some of the CEA-708 issues we have listed on GitHub.\nThis is also the best way to get accepted into GSoC.\nQualification tasks\nTake a look at this page.\n","link":"https://ccextractor.org/public/gsoc/cc_rust_708/","title":"Google Summer of Code 2021 - Complete 708 support"},{"body":"If you need custom work regarding CCExtractor you can send Carlos an email:\nCarlos is currently in San Francisco.\nAn important thing: CCExtractor changes always become part of the mainstream version. We don't keep one open source version and many private versions for clients.\nWork related to CCExtractor that does not require changes to CCExtractor itself (GUIs, monitoring system, integration with 3rd party software) can be closed source, subject to NDAs, etc.\nIn general jobs are offered to everyone in the team as this encourages developers to continue their involvement with CCExtractor. This means that even if Carlos is the first point of contact, it's likely that someone else from the team will be available to help with the job.\n","link":"https://ccextractor.org/public/general/how_to_hire_us/","title":"How to hire us"},{"body":"Introduction\nrTorrent currently uses an antique XMLRPC interface, which is limited in capability, not scalable, hard to use, insecure and low-performance. Community needs a modern RPC interface with full bidirectional, stream processing, incremental data loading and high concurrency capabilities, which allows real-time events for RPC users, reduced serialization/transfer overheads, potentially better security (with authentication and/or TLS), etc.\njesec implemented feature-complete JSON-RPC over SCGI support for rTorrent [1]. Preliminary tests showed that, when compared with XMLRPC, JSON-RPC yields 2x performance, 15% lower total CPU time in rTorrent process, 33% lower total CPU time in RPC user’s process. Flood supports it from v4.5, which allows it to halve the response time of 28890-torrent list from 2.5 seconds to 1.2 seconds [2].\nYour job\nThe goal here is to implement a modern RPC interface that allows the users to receive events like download.completed.\nThe logical step is to implement JSON-RPC over WebSockets support on top of the existing JSON-RPC over SCGI (raw socket) implementation, hook event emitting function and send event to WebSocket subscribers.\nOther modern RPC protocols such as gRPC are also accepted. However, note that it is probably more difficult to start from scratch.\nThe interface should support at least two simultaneous subscribers.\nSome C++ libraries:\n uNetworking/uWebSockets warmcat/libwebsockets  ","link":"https://ccextractor.org/public/gsoc/rtorrent-modern-rpc/","title":"Implement a modern RPC interface for rTorrent"},{"body":"This year of GSoC focused on improving the existing tools I wrote the previous years (2014 \u0026amp; 2015) to achieve full GitHub integration.\nThis was achieved through:\n A full rewrite of the existing sample platform for compatibility reasons Migrating the VirtualBox VM environment to a KVM enviroment to ensure that tests run in a decent amount of time, while staying secure. Running tests under the Windows platform. Integrating the platform with GitHub using webhooks  Rewrite of the sample platform Last year's sample platform was written using PHP (https://github.com/canihavesomecoffee/ccx_submissionplatform/), and that choice induced some problems regarding the ease of operating when combining the platform with the bot.\nTo get rid of these issues, a rewrite of the platform was required. A switch to python (in which the previous github bot was written already) was made.\nThe platform is currently running live at https://sampleplatform.ccextractor.org/, and the source code for the entire platform \u0026amp; GitHub integration can be found on https://github.com/canihavesomecoffee/sample-platform.\nThe platform isn't fully finished yet, though it is usable; These things still need to be done:\n Re-enable FTP upload Finish the management of regression tests Let users schedule tests from forks  Migration from VirtualBox to KVM As the VirtualBox solution from last year proved to be terribly slow, this year, a migration to KVM was done.\nThis involved the following steps:\n Installing KVM Getting the API bindings Create a Linux VM, and configure it Program the platform to revert to a snapshot and run the test suite  The code for this is fully integrated into the Sample Platform, and as such can be found there.\nWindows testing This part is unfinished. A windows VM needs to be created \u0026amp; configured, a startup service needs to be written (that can handle the automated compilation of CCExtractor under Windows), and the lines of code in the platform that handle the VM need to be uncommented.\nIntegration with GitHub Using the webhooks GitHub provides, a full integration with their platform could be made.\nGitHub informs us of new pushes and pull requests, and the platform subsequently queues and executes the tests for given commit or PR. This code is also fully integrated into the platform, but mod_ci is the place where all the magic happens.\nOther work Besides the work detailed above, some patches for CCExtractor were contributed:\nhttps://github.com/CCExtractor/ccextractor/pull/363 https://github.com/CCExtractor/ccextractor/pull/365 https://github.com/CCExtractor/ccextractor/pull/382 https://github.com/CCExtractor/ccextractor/pull/383 https://github.com/CCExtractor/ccextractor/pull/386 https://github.com/CCExtractor/ccextractor/pull/399 https://github.com/CCExtractor/ccextractor/pull/403\nNext to that, some fixes to the test suite also were made:\nhttps://github.com/canihavesomecoffee/ccx_testsuite/commits/master\n","link":"https://ccextractor.org/public/gsoc/2016/willem/","title":"Improving GitHub CI"},{"body":"For now this is quite disorganized, just a collection of links. But it will get better :-\nData Structures and Algorithms coding challenge #2 | Programming challenges in September, 2019\n101 Coding Problems and few Tips to Crack Your Next Programming Interviews\n","link":"https://ccextractor.org/public/general/misc/interview_preparation/","title":"Interview preparation"},{"body":"Introduction\nThe linux kernel has hundreds of tunable settings. Some can be modified on the fly with sysctl; others require reboots, loading modules and so on.\nYour job\nYour job is to come up with a self-tuning system that does all the analysis it needs and finds the optimum settings to maximize throughput and/or latency for well defined workloads. One of the must be BitTorrent, since that one uses a lot of traffic and it can just be tested with real data instead of synthetic tests.\nQualification tasks\nTake a look at this page.\n","link":"https://ccextractor.org/public/gsoc/linuxtuning/","title":"Linux tuning"},{"body":"We already had two tasks about this superfun yet easy to understand game (links below). Many students have worked on creating mastermind players, so it's time to make them compete against each other! Let's see who's algorithm is better.\nIn order to do this, we need a servers for the players to connect to and play. Your job is to implement such a server.\nWe have come up with a simple protocol between player and server. Your job here is to implement the server side. The protocol is like this:\nWhen the player wants to start a game, it will request (via HTTP GET)\n/himastermind/newgame/$name_of_player\nThe \u0026quot;name_of_player\u0026quot; can be anything (alphanumeric only) but it shouldn't change - so if a player plays 100 times, it should use the same name in all of 100, so the server can keep track of results for each player.\nA player here is the AI, not the name of the developer. In fact, don't use your own name (that goes against GCI rules).\nWhen that URL is called, the server will generate a random number (for the player to guess) and a \u0026quot;game ID\u0026quot; which it will return. The \u0026quot;game ID\u0026quot; (equivalent to \u0026quot;session ID\u0026quot;, if you are used to that term when taking about websites) is a 8 characters random string (alphanumeric). The game ID is returned to the player so he can pass it to play.\nThen the game actually starts. The player will make requests like this:\n/himastermind/play/$game_id/$guess\nAnd the server will return:\n$digits_in_the_right_position $digits_in_the_wrong_position $number_of_guesses_in_this_game $time_since_the_game_started A possible interaction would be like this:\n**CLIENT REQUESTS**: /himastermind/newgame/MazingerZ/1235678 **SERVER REPLIES**: AHVEDJ34 **CLIENT REQUESTS**: /himastermind/play/AHVEDJ34/123456 **SERVERS REPLIES**: 2 1 3 **CLIENT REQUESTS**: /himastermind/play/AHVEDJ34/126544 **SERVERS REPLIES**: 4 0 4 **CLIENT REQUESTS**: /himastermind/play/AHVEDJ34/126588 **SERVERS REPLIES**: 6 0 6 Of course the game ends when the player guesses the number correctly, so the reply is 6 0.\nThings the server needs to do: - If the game ID doesn't exist, return an error - If the guess string is not correct (exactly 6 digits) return an error - Be able to handle the same player playing more than one game simultaneously, which is why we have the \u0026quot;game ID\u0026quot;. Each time the player calls \u0026quot;newgame\u0026quot; a new game is created, but it doesn't destroy the previous one the server might have. - Keep track of everything in a database. That means for each player, the games its played, the guesses, elapsed time, and so on.\nYou can deploy your work in any cloud service that as a free tier (most do).\nIn a separate task we'll create a new dashboard to see who's the best player.\nThere will be rewards for the students that create the best players and the best server.\nUseful links:\nPrevious mastermind tasks:\nhttps://codein.withgoogle.com/dashboard/tasks/6684006435782656/ https://codein.withgoogle.com/dashboard/tasks/6022435409756160/\nMastermind rules:\nhttps://www.wikihow.com/Play-Mastermind\n","link":"https://ccextractor.org/public/codein/google_code-in_2019/mastermind/","title":"Mastermind #3: Write the backend (in any language you want) for a competition between student submissions"},{"body":"Mentor: Willem Van Iseghem Introduction PiPot is a honeypot server which pretends as a potential target for attackers from network and collect the attack data. It also has the ability to deploy more instances to make it harder to get information from the real one. The goal of this GSOC project is to improve the functionality and scalability of the current PiPot.\nLinks Project repo - https://github.com/PiPot\nCompleted work(PR)  Server Development(Every new feature is covered with unit test)  Create and run server inside python virtualenv  set up virtualenv for server   Run PiPot on non-Arm platform like RPi  allow user specific network interface suppot image deployment on non-Arm platform   Allow container-based service uploading  container based service upload   Allow dynamic data report update  dynamic report update   Allow service version update  fix service cannot upload properly add service manager interface, upgrade from old to newer models from updated service add test on invalid test update     Continuous Integration  travis setup, add test database setup and with some basic tests notification management test add codecov start sql service explicity on travis   Python2 to Python3 migration  update enum attribute for sqlalchemy table fix enum attribute iteration issue due to python3 update    Usage To install pipot, please follow the installation section. When install sever, answer each question carefully to set up the right config. If you want to run the pipot server locally for test, you can simply run python run.py under server. (Assume you don't use localhost as IP address in installation, otherwise you need to close nginx by service nginx stop to free the address)\nFuture work  have container based notification uploading, ideally check the requirement before actually applied to pip install develop tests to improve the test coverage update the image deployment to support the latest Raspberry Pi model set up a mailing notification service to report the collected data password change/get back user name using mail verification  ","link":"https://ccextractor.org/public/gsoc/2019/vertexc/","title":"Micro Honeypot for RPi"},{"body":"Introduction\nMouseless is a nice tool to practice keyboard shortcuts for a few popular apps. Unfortunately it's only available for Mac. We'd like to create an open-source Linux version that can be easily extended.\nYour job\nWe don't want to clone Mouseless (we don't have any relationship with their authors, and we don't want to copy any of their work) - but the idea is good, and we think we can do a good job doing a tool that does a similar job of training users to use the mouse less and the keyboard more, but for the usual Linux tools.\nWe don't know what's the best technology is to build this, so we're open to ideas. Just come up with a good plan, and a proof of concept for any Linux tool you like.\nQualification tasks\nTake a look at this page.\n","link":"https://ccextractor.org/public/gsoc/mouseless/","title":"Mouseless for Linux"},{"body":"My project is documented at https://shrutigullapuram.wordpress.com/2016/08/22/gsoc-work-product-submission/. My project was for Red Hen Lab, which is a sister org of CCExtractor.\n","link":"https://ccextractor.org/public/gsoc/2016/shruti/","title":"News shot classification"},{"body":"","link":"https://ccextractor.org/playground/","title":"Playgrounds"},{"body":"Mentor: Johannes Lochter Introduction Building a free version of Amazon rekognition with maximum possible feature during a 3 months' time span.\nLinks Proposal\nGitHub(final submission)\nMedium blog: https://medium.com/@b216029 (refer this for detailed information about each use-case)\nindependent github code: https://github.com/backSpace001/poor_man_rekognition\nUse-cases 1.Face and Eye Detection using OpenCV - - completed 👍\n2.Facial recognition of a video using deep metric learning - - completed 👍\n3.Celebrity Recognition - - completed 👍\n4.Object Detection - - completed 👍\n5.Read text in images - - completed\n6.Facial Analysis - - completed 👍\n Sad Happy Angry Disgust Fear Surprise Neutral 7.Scene Detection - - completed 👍\nLibraries required Note: (requirement.txt is already available in the repository)\n OpenCV: For using cascade files Numpy: For array operations Matplotlib.pyplot : For plotting Pickle : For serializing and de-serializing Python object structures Keras : For importing neural network models Tensorflow : For CNN’s architecture and training Cython : To generate CPython extension modules Pillow : To load images from files Lxml : To use the ElementTree API Flask==1.1 gunicorn==19.3 werkzeug==0.15 opencv tesseract=3.02 numpy==1.11 scipy==0.18 scikit-learn\u0026gt;=0.18 Installation 5 simple steps to download this repo, run in your local server and work on it accordingly.\nStep 1. Download or clone this repo.\nStep 2. Create a bin Folder inside the repo and download this weights from the link and paste it inside this bin folder https://drive.google.com/drive/folders/1hUY_n_H7jhdL9Z8yKKHZFB0wILGW_prH?usp=sharing (note-it is very big so couldn't upload it in the github)\nStep 3. Get the requirments by typing in the command. pip install -r requirements.txt\nStep 4. You are good to go. RUN python app.py\nStep 5. Open http://127.0.0.1:5000/ in your browser\nUse Cases 1.Face and eyes detection using OpenCV: OpenCV comes with a trainer as well as a detector. Here I have used OpenCV for detection and later in the project, I will use it to create an XML file of faces for Face recognition. OpenCV already contains many pre-trained classifiers for face, eyes, smiles, etc. Those XML files are stored in the Library/etc/haarcascades. In this part, I have used face cascade and eye cascade to detect face and eyes in an image. OpenCV uses a machine learning algorithm and it contains pre-trained cascade XML files which can detect a face, eyes, etc. This basically breaks the image into pixels and form blocks, it does a very rough and quick test. If that passes, it does a slightly more detailed test, and so on. The algorithm may have 30 to 50 of these stages or cascades, and it will only detect a face if all stages pass. This technique works on the Viola-Jones Algorithm, which is a part of deep learning. This statement was said on the context of:- deep learning is a class of machine learning algorithm that learns in supervised (e.g., classification) and/or unsupervised (e.g., pattern analysis) manners. This part of face detection is also used in facial recognition section and there I will use this the file as an unrecognized file to be saved in the database and to be used as another face with no name registered. Example rectangle features shown relative to the enclosing detection window. The sum of the pixels which lie within the white rectangles is subtracted from the sum of pixels in the grey rectangles. Two-rectangle features are shown in (A) and (B). Figure © shows a three-rectangle feature, and (D) a four-rectangle feature.\n2.Facial Recognition I have used Deep Learning face recognition embedding. Here I am using deep learning and this technique is called deep metric learning.In deep learning typically a network is trained to: Accept a single input image And output a classification/label for that image However, deep metric learning is different. Instead, of trying to output a single label (or even the coordinates/bounding box of objects in an image), instead of outputting a real-valued feature vector. For the dlib facial recognition network, the output feature vector is 128-d (i.e., a list of 128 real-valued numbers) that is used to quantify the face. Training the network is done using triplets: Facial Recognition via Deep metric learning involves \u0026quot;triplet training step\u0026quot; I have first created a database for the training set and encoded (128-d) each face image into a numpy array and turn it into an XML file. Second I have imported that trained XML file into the main script to detect and recognize a face.\n3.Celebrity Recognition This part is same as the above one the only reason I made it a different sector is because this feature is listed in Amazon's rekognition project and as this is a similar project I have to add this additional name tag and create a whole new dataset consisting of many known actors. Here I have also used deep metric learning techniques.\n4.Object detection Object Detection is the process of finding real-world object instances like car, bike, TV, flowers, and humans in still images or Videos. It allows for the recognition, localization, and detection of multiple objects within an image which provides us with a much better understanding of an image as a whole. It is commonly used in applications such as image retrieval, security, surveillance, and advanced driver assistance systems (ADAS). I have performed this using YOLOv2 on an image and a video file. You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X, it processes images at 40--90 FPS and has an mAP on VOC 2007 of 78.6% and an mAP of 48.1% on COCO test-dev. One can find all the details about YOLOv2 here: https://arxiv.org/pdf/1612.08242.pdf https://www.youtube.com/watch?v=NM6lrxy0bxs\n5.Read text in images Extraction of text from an image is a subpart of image processing and is called OPTICAL CHARACTER RECOGNITION (OCR). I have used Tesseract which is an OCR engine developed by Google. It supports Unicode and has the ability to recognize more than 100 languages.\n6.Facial expression recognition https://medium.com/@b216029/report-3-494b2fdbb179 (refer this for this part)\n7.Scene detection Citation - www.algorithmia.com I have coded to implement my part so as to perform the task, all the data will be provided by algorithmia and can be seen in the algorithmia website itself. My code will mere be a bridge. [note-this part is not included in the web app because of some complexity] Scene detection is used for detecting transitions between shots in a video to split it into basic temporal segments. It helps video editors to automate the process of quickly splitting videos in bulk rather than editing it frame by frame by hand. To run scene Detection Follow this steps:\n1.Create an account on Algorithmia (includes 5,000 free credits each month).\n2.Go to your profile page, click the Credentials tab, and find your API key.\n3.Find a test video. You can use a public URL (prefer Vimeo over youtube), or upload one to their hosted data storage.\n4.Install the Python Algorithmia client using the command \u0026quot;pip install algorithmia\u0026quot;.\n5.Copy the sample code below, replace YOUR_API_KEY with your own key, and run it to extract the scenes from your video!\n","link":"https://ccextractor.org/public/gsoc/2019/faizkhan/","title":"Poor Man's Rekognition"},{"body":"Mentor : Johannes Von Lochter Developed under Google Summer of Code, 2019 with CCExtractor Development By Amit Kumar\nIntroduction The main aim of the project is to make an open-source version of Amazon Rekognition which is a (paid) service that is able to identify objects, people, text, scenes, and activities in a picture. To accomplish this, I proposed a solution by using tech stacks such as Django, Django-Rest-Framework, ffmpeg, TensorFlow Serving and ReactJS.\nProject Related Links Project repository on GitHub:\nhttps://github.com/pymit/Rekognition\nhttps://github.com/pymit/RekoUI\nDemo - Video: https://youtu.be/k_Xpy_oW1LQ\nProject Progress: https://github.com/pymit/Rekognition/projects\nhttps://github.com/pymit/RekoUI/projects\nUsage Docs Once you setup the project locally, start the react app ( installation guide link is provided in installation section) visit http://localhost:3000/doc\nBlog entry for final submission : https://medium.com/@amkr/final-work-submission-gsoc19-ccextractor-development-40a2b6c6a946\nInstallation To setup the project locally follow below wiki link https://github.com/pymit/Rekognition/wiki/Project-Setup-in-Ubuntu-18.04\nContact Details Slack: @pymit\nGitHub: @pymit\nTwitter: @amit2rockon\nEmail: amit165@iiitkalyani.ac.in\n","link":"https://ccextractor.org/public/gsoc/2019/pymit/","title":"Poor Man's Rekognition"},{"body":"Developed under Google Summer of Code 2019 by Sarfaraz Iraqui\nMentor: Johannes Von Lochter\nIntroduction Poor Man's Rekognition (PMR) aims to provide a free and open source alternative to Amazon Rekognition.\nAmazon Rekognition is a fairly complex system.\nDuring GSoC, the project focused on face detection and recognition only.\nThere are many libraries especially in Python that provide these functionality but they require a lot of expensive hardware for practical use.\nThis project is aimed to make everything run on CPU but still provide reasonable performance for a REST API.\nProject Structure The project is divided into three sub-projects:\n  Nodoface: A Nodejs C++ addon (binding) to C++ libraries that helped attain high performance on CPU for ML algorithms.\n  PMR-Core: Nodejs library (with TypeScript support) that combines Nodoface and ML libraries that are not available in C++.\n  For eg. there is no ArcFace model on C++ or Nodejs. This provides completely everything that is needed to build Amazon Rekognition like API.\n PMR-Server: The REST API for PMR-Core. This provides endpoints similar to Amazon Rekognition. Any API call generates response which is more or less identical to Rekognition.  Project links   Proposal - https://github.com/sziraqui/pmr-gsoc-tracker/blob/master/Proposal-PMR-CCExtractor.pdf\n  Nodoface repository - https://github.com/sziraqui/nodoface\n  PMR-Core repository - https://github.com/sziraqui/pmr-core\n  PMR-Server repository - https://github.com/sziraqui/pmr-server\n  Installation Only Nodoface requires a tough installation because it depends on some C++ libraries.\nPMR-Core and Server require just one command for setup.\nPart 1: Install dependencies Nodoface depends on-\n  OpenFace \u0026gt;= 2.1.0\n  OpenCV \u0026gt;= 3.4.0\n  dlib \u0026gt;= 19.13\n  All above libs must be compiled as a shared library\n node-addon-api \u0026gt;= 1.6.3  Step 1: Install OpenCV 3.4.x.\nIf opencv is already installed, ensure it is recognised by pkg-config by executing:\n$ pkg-config --modversion opencv\nStep 2: Install dlib 19.13 or greater as a shared library (default is static).\nCheck this answer by DavisKing for compiling it as shared library.\nEnsure it is recognised by pkg-config:\n$ pkg-config --modversion dlib\nStep 3: Install OpenFace. The original repo can only compile as static library.\nSo use my OpenFace fork instead. I have modified CMakelists.txt to compile OpenFace as shared lib.\n$ git clone [https://github.com/sziraqui/OpenFace.git](https://github.com/sziraqui/OpenFace.git) \u0026amp;\u0026amp; cd OpenFace $ git checkout dynamic-compile $ ./download_models.sh $ mkdir build \u0026amp;\u0026amp; cd build $ cmake -D CMAKE_BUILD_TYPE=RELEASE CMAKE_CXX_FLAGS=\u0026quot;-std=c++11\u0026quot; -D CMAKE_EXE_LINKER_FLAGS=\u0026quot;-std=c++11\u0026quot; $ make -j2 $ sudo make install After this, Nodoface can be installed in any Node project with npm install nodoface\nPart 2: Setup server The server depends on PMR-Core and knn-classifier.\nStep 1: Create a project folder. Let's name it \u0026quot;pmr\u0026quot;.\nmkdir pmr\nStep 2: Clone dependent repositories in project folder.\ncd pmr git clone [https://github.com/sziraqui/nodoface](https://github.com/sziraqui/nodoface) git clone [https://github.com/sziraqui/pmr-core](https://github.com/sziraqui/pmr-core) git clone [https://github.com/sziraqui/pmr-server](https://github.com/sziraqui/pmr-server) git clone [https://github.com/tensorflow/tfjs-models/tree/master/knn-classifier](https://github.com/tensorflow/tfjs-models/tree/master/knn-classifier) Step 3: Install packages in PMR-Core\ncd pmr-core npm install cd ../ Step 4: Setup KNN-classifier\ncp -r tfjs-models/knn-classifier knn-classifier cd knn-classifier npm install cd ../ Step 5: Setup server\ncd pmr-server npm install cd ../ Part 3: Setup database The project uses PostgreSQL database. Face embeddings and PMR-Server data is stored in a database. Follow below instructions to setup a local database for the PMR-Server.\nStep 1: Create DB schema\nInstall PostgreSQL and create a schema as per this ER diagram\nStep 2:\nDownload LFW dataset from http://vis-www.cs.umass.edu/lfw/lfw-deepfunneled.tgz\nExtract it somewhere (say pmr/lfw-deepfunneled)\nStep 3: Populate face embedding data in DB\ncd pmr-server ./bin/add_faces_to_db.ts pmr/lfw-deepfunneled LFW DEEPFUNNELED For more info on script usage, pass it --help flag with no arguments.\nAny other dataset can be used as long as the directory structure is same as that if LFW.\nStart server Run start-server script to start the server on localhost\n./bin/start-server Usage docs Nodoface: Nodoface can be used without PMR-Core and Server. See nodoface/examples directory and nodoface/tests directory to learn the usage.\nPMR-Core: PMR-Core can be used without the Server but depends on Nodoface. Look for files ending with *test.ts in pmr-core/src to learn usage. Scripts provided in pmr-server/bin directory are also good place to explore.\nPMR-Server: See the endpoints in pmr-server/src/api/vX/*.ts.\nRequest/Response syntax can be understood by going through pmr-server/src/amzn-dtypes and pmr-server/src/pmr-dtypes.\nAt the time of writing, there is no UI for this server. I use Postman to test the endpoints.\nMaking requests to server  POST /api/v0/detect-faces  Request body:\n{ \u0026quot;Image\u0026quot;: { \u0026quot;Bytes\u0026quot;: \u0026quot;base64-string-of-image\u0026quot; } }\n\u0026quot;Bytes\u0026quot; is the base64 string representation of input image. This is same as DataURL after removing the first intial characters \u0026quot;data:image/jpeg;base64,\u0026quot; (for jpeg image). I use https://www.base64-image.de to get base64 string while testing.\n POST /api/v0/recognize-celebrities\nRequest body: Same as that for detect-faces endpoint above.\n  POST /api/v0/celebrity-in-video\n  Request body:\n{ \u0026quot;Video\u0026quot;: { \u0026quot;Url\u0026quot;: \u0026quot;direct-downloadable-video-url\u0026quot; } }\nHandling response from server The server follows a \u0026quot;Dispatch and Poll\u0026quot; method. Everytime a request is received, the server dispatches a \u0026quot;Job\u0026quot; and sends response immediately with the Job status. Sample response:\n{ \u0026quot;JobId\u0026quot;: \u0026quot;string\u0026quot;, \u0026quot;JobStatus\u0026quot;: \u0026quot;PENDING\u0026quot;, \u0026quot;ResultUrl\u0026quot;: \u0026quot;url\u0026quot; }  One can poll on the ResultUrl until JobStatus becomes \u0026quot;COMPLETED\u0026quot;. When that happens, the response will include output such as BoundingBox, Celebrity name, etc depending on the request. Also the RequestUrl of a COMPLETED job will point to output file with visualisations drawn (bonding boxes, labels, etc on image/video). Read this blogto learn more.\nUseful links   My GSoC notes - https://github.com/sziraqui/pmr-gsoc-tracker/tree/master/notes\n  Blog (GSoC final evaluation) - https://link.medium.com/qlbGEnFdyZ\n  Contact details Slack - @sziraqui\nEmail/Hangouts - sarfarazghlm@gmail.com\nLinkedIn - https://www.linkedin.com/in/sziraqui\n","link":"https://ccextractor.org/public/gsoc/2019/sziraqui/","title":"Poor Man's Rekognition"},{"body":"Amazon Rekognition is a (paid) service that is able to identify objects, people, text, scenes, and activities in a picture. We want to produce a free alternative.\nDescription: Rekognition is Amazon's (paid) service capable of identifying objects, text and activities, performing facial analysis and recognition, detecting the frequency of objects or an inappropriate scene, and much more using deep learning. Poor Man's Rekognition is an open-source version of the commercial service and is currently able to do almost everything that Amazon Rekognition does.\nIdeas for PMR-III:\nFix issues with docker and make it run seamlessly on all platforms: The project as of now runs specifically on Unix based distros. The docker image is broken and needs to be fixed. The end goal is to have a containerized version of the project that can run on all platforms.\nDecrease latency of API response by reducing the size of some of the large models (or by some other means): Some of the models used in PMR are extremely large in size and thus take a lot of time to get loaded and give predictions. The memory consumption is also extremely high. We need to decrease both the response time as well as memory consumption. One way of doing this can be using models with smaller size. Other methods can be explored.\nDeploy the service for remote use: Once the above two issues have been resolved\nDomain: Artificial Intelligence, Deep Learning, Computer Vision\nRelevant links\nSource Code\nSetting Up the Project and Brief Overview\nIn detail blogs\n GSoC Chronicles --- Only Time will Tell https://medium.com/@pulkitmishra/gsoc-chronicles-best-kept-code-4893823d0f12 GSoC Chronicles --- commit the CRNN cometh the Text https://medium.com/@pulkitmishra/gsoc-chronicles-mightier-than-ssd-b89be236d852   ","link":"https://ccextractor.org/public/gsoc/poormanrekognition2/","title":"Poor Man's Rekognition (III)"},{"body":"Introduction\nAmazon Textract a (paid) service that \u0026quot;automatically extracts text and data from scanned documents. Amazon Textract goes beyond simple optical character recognition (OCR) to also identify the contents of fields in forms and information stored in tables.\u0026quot;. We want to build a free alternative that provides an output of similar quality.\nYour job\nImprove upon the existing PMT project: https://github.com/kenAlparslan/Texttract\nPrevious (GCi) tasks that did something (albeit simpler) similar:\n Musab Kılıç's exam analyzer RobOHt's exam analyzer knightron0's exam analyzer  Qualification tasks\nTake a look at this page.\n","link":"https://ccextractor.org/public/gsoc/poormantextract/","title":"Poor Man's Textract"},{"body":"708 is the standard for analog TV in the US and a few other countries. Wait, don't go! It's upconverted so even if it's \u0026quot;old\u0026quot;, it's the minimum common denominator and present in all broadcasts.\nCurrent status:\n Complete implementation in C. May have bugs, but it's been used in production for ages. - Written early, meaning lots of things weren't clear then and the code is messy. - Suspected to have some security issues that Rust can help with.  Job:\n Replace the C code with Rust code.  We will provide hundreds of samples (for which you must complete support, no exceptions) and access to a high speed linux server for you to work with if needed. These samples are usually very large (hundreds of megabytes each) so working locally may not be feasible for you if you don't have a great internet connection.\nFor developers in India we have someone there with an external 2 TB drive with a copy of all our samples. That drive goes from developer to developer, so if needed we can get it shipped to you.\nIf you are not in India or in a country in which just downloading the samples is the easy way, get in touch. We'll figure something out so access to media is not a problem.\nThis is a high value task and we'd love to have it done, but in order to qualify you need to fix some of the existing bugs.\nAlso part of this idea:\nhttps://github.com/CCExtractor/ccextractor/issues/733\nWhich is about implementing .mcc support, which as the GitHub ticket says complements 708 very well.\nGetting started:\nThe wikipedia page on 608 This is quite good actually. It's not a complete description of the standard, but it's quite useful to understand what 608 is about.\nHow to get started Best thing you can do is download a few samples (check our TV samples page) and try to solve some of the CEA-608 issues we have listed on GitHub.\nThis is also the best way to get accepted into GSoC.\nQualification tasks\nTake a look at this page.\n","link":"https://ccextractor.org/public/gsoc/cc_rust_608/","title":"Port and/or rewrite CEA-608 support to Rust"},{"body":"","link":"https://ccextractor.org/private/","title":"Privates"},{"body":"Developed under Google Summer of Code, 2018 with CCExtractorDevelopment By Aaditya MNair\n Introduction One of the function of the RedHen Organisation is to record and archive Television streams they receive for future research. Project Nephos is an effort by CCExtractor to automate the entire process. Archiving is done by compressing and uploading to Google Drive. In addition to downloading and archiving, Project Nephos provides the following functionalities:\n Tagging of videos. Searching archived videos. Sharing videos with other entities  Project Related Links  Project Repository on GitHub Project Nephos My blogs on the project Blog Reports Sample Recordings here  Installation  git clone [https://github.com/AadityaNair/ProjectNephos.git](https://github.com/AadityaNair/ProjectNephos.git) pip install ./ProjectNephos Usage Documentation Below is how you would manually use Nephos to perform actions manually. This requires the config file to be present. More information on the config file in the Configuration section.\nUploading files nephos upload \nSearching nephos search --name \u0026lt;name\u0026gt; --tags \u0026lt;tag1\u0026gt; \u0026lt;tag2\u0026gt; ... --do_and\nSearch for files with  and/or tags   .... The and/or part will be decided by the do_and parameter. If specified, all parameters (name, tags) will be joined by an AND i.e it will search for \u0026quot; AND  AND  ...\u0026quot; If not, ANDs will be replaced by ORs.\nAtleast one of --name and --tags is required.\nTagging nephos tag --for_name \u0026lt;name\u0026gt; --add_tags \u0026lt;tag1\u0026gt; \u0026lt;tag2\u0026gt; ...\nThis searches for all instances that contain  and for each of them, add the provided tags.\nProcessing nephos process \u0026lt;input_file\u0026gt; \u0026lt;output_file\u0026gt;\nConverts the input file to output file. The formats are guessed by their extensions.\nPermissions Share uploaded videos with people based on the video tags.\nnephos permission add --for_tags \u0026lt;tag1\u0026gt; \u0026lt;tag2\u0026gt; --share_with \u0026lt;email\u0026gt;\nThis command is persistent. This means that all future videos with the tag will also be shared. To avoid this action pass --not_persistent to the command.\nNote, The tags provided follow the OR semantics. i.e. in the above example, every file with the tag //tag1//\nOR tag2 will be shared.\nTo view all permissions,\nnephos permission list\nMore information can be found for each sub-command by using the --help option after the sub-command\nAutomation For the most part you want to just specify what to record and when leave Nephos at it. For that:\nAdd channels Add channel to specify where to download stuff from\nnephos channel add --name 'CNN' --ip_string '1.2.3.4:5678'\nNote that the name should be unique for each channel.\nTo view added channels. nephos channel list\nAdd job. Specify when to download other post download options.\nnephos job add --name \u0026lt;jobname\u0026gt; --channel \u0026lt;channel\u0026gt; --start \u0026lt;starttime\u0026gt; --duration \u0026lt;length\u0026gt; --upload --convert_to \u0026lt;format\u0026gt; --tag \u0026lt;tag1\u0026gt; \u0026lt;tag2\u0026gt;\nFollowing are mandatory arguments: --name is the name of the job. This should be unique for each job. --channel is the name of the associated channel. This channel should have already been added by the channel add subcommand. --start is the start time of the job written in the popular cron format. For more info on the format go here. This was used as an reference. --duration is how long you want to record. This is provided in minutes.\nRest are optional arguments: --upload instructs nephos to upload the file to Google Drive. This will most likely be the default case in the future versions. In such a case, this option will be removed. --convert_to makes so that the downloaded file is converted to the provided format before being uploaded. --tag tags the uploaded file with the provided tags.\nNote that --tag is dependent providing the --upload option. If it not provided --tag is a NOOP.\nTV Listings Nephos also has a crude API that supports TV listings.\nnephos schedule add --name \u0026lt;program_name\u0026gt; --channel \u0026lt;channel\u0026gt; --start \u0026lt;starttime\u0026gt; --duration \u0026lt;length\u0026gt; --tags \u0026lt;tag1\u0026gt; \u0026lt;tag2\u0026gt;\nThis syntax is pretty much exactly the same as for the job add above. The tags are associated with the program. This allows for a separate syntax to add a job:\nnephos job add --name \u0026lt;jobname\u0026gt; --program_tags \u0026lt;tag1\u0026gt; \u0026lt;tag2\u0026gt; .. --upload --convert_to \u0026lt;format\u0026gt; --tag \u0026lt;tag1\u0026gt; \u0026lt;tag2\u0026gt;\nThis will find all programs with any of the provided tags and add them as jobs.\nInitialise Server This starts the orchestration server which is responsible for the record -\u0026gt; process -\u0026gt; upload pipeline. This will also create all the relevant directories and perform OAuth with google drive, if not done already.\nnephos init\nCurrently, if a job is added after the server is started, it will not be picked up by the server. So, make sure you add all the jobs before starting the server. This will be fixed in a later version.\nContributing and other information Currently the project lives on the above provided github link.\nThe wiki contains more information about the internals of the project.\nThere is still a lot of stuff that can be improved here. Have a look at the issues to know what can be done and don't hesitate to create a new one if you find something new.\n","link":"https://ccextractor.org/public/gsoc/2018/aaditya/","title":"Project Nephos"},{"body":"Developed under Google Summer of Code, 2018 with CCExtractor Development By Shivam Kumar Jha\n Introduction Project Nephos aims at simplifying the process of moving samples from local storage to cloud for Universities by automating, almost, all the steps involved. It consists of three independent modules; recording module, processing module, and uploading module.\nThe recording module is responsible for managing the addition of channel lists, set up of recording jobs and saving the recorded streams. The processing module parses saved samples, associates tags, extracts subtitles and converts the video files to MP4 to reduce the file size. The uploading module then uploads the processed stream files to FTP server (if config is completed) and Google Drive, and also shares the sample with other universities (whose email addresses must be provided) if required.\nNephos has been developed, using Python and few other open source projects, to accomplish all the above-mentioned tasks with cent-percent reliability and zero failures (unless wrong data is input, which will get logged). Testing and logging has been an integral part of Nephos development and running cycle, respectively.\nProject Related Links  Project Repository on GitHub Nephos My blogs on the project GSoC Blogs  Installation   git clone https://github.com/thealphadollar/nephos.git \u0026amp;\u0026amp; cd nephos\n  On centOS 6 run the script, sudo ./install.sh\n  Observe and modify configurations available in $HOME/Nephos/config (especially maintenance and module configurations, and processing script)\n  Add nephos_start.sh as a cron job to be executed at startup in root crontab. @restart /path/to/nephos_start.sh 2\u0026amp;\u0026gt; ~/Nephos/boot_start.log\n  Run nephos using sudo ./nephos_start.sh. This command runs Nephos under a new screen session. Press ctrl + a and then d to detach from the session while it keeps running in the background.\n  You can see the recordings in Google Drive of your linked Google Account. The logs of the program are uploaded to \u0026quot;Nephos_Logs\u0026quot; folder for Redhen account.\n  To Add Channels And Jobs Please go to Nephos Config repository to modify the channels, jobs and share lists that Nephos works on.\nDeveloper's Documentation Developers can view the documentation that is present for users since it is detailed and one needs to read it in order to understand how Nephos functions. Along with that, docstrings have been placed in HTML format in docs/DevDocs and can be accessed in a systematic manner by opening docs/DevDocs/nephos.html in a browser.\nThey can also be viewed here.\nMore Info For more information regarding using Nephos and how it works, visit the wiki\n","link":"https://ccextractor.org/public/gsoc/2018/thealphadollar/","title":"Project Nephos"},{"body":"","link":"https://ccextractor.org/public/","title":"Publics"},{"body":"Developed under Google Summer of Code, 2017 with CCExtractor Development By Diptanshu Jamgade\n Introduction CCExtractor is a software written in C language. The main aim of this project was to generate the python extension module for CCExtractor which would then help Python developers to extend the applications of CCExtractor in Python.\nThe main ideology of the module was to extract the captions using CCExtractor and parse the extracted captions to Python for processing them. The module was desired to be structured in such a way that the captions arrive in Python as soon as they are extracted by CCExtractor. Thus, the captions could be processed in real-time via Python rather than waiting for the extraction to finish. Also, the extension module is expected to be silent, i.e. not outputting any STDOUT information.\nThe module was needed to be silent in terms of all the output generated by CCExtractor. The output files were to be generated via Python and not via CCExtractor as the module's prime duty was to extract the captions in CCExtractor and parse the extracted captions to Python for processing.\n Project Related Links  Project Repository on GitHub CCExtractor Project Documentation Documentation Official GSOC Project link Project My blog Blog Mentor @cfsmp3   Installation For installing the Python extension module, the user needs to make sure that the user has compiled/installed all the dependencies for CCExtractor (mentioned here).\nAfter the user has compiled/installed all the dependencies for CCExtractor, for installing Python extension module, the user needs to install two dependencies:\n SWIG swig Python-dev package ubuntu For other operating systems, the user has to install //python-dev package// as mentioned in the corresponding system's documentation.  After the user has compiled/installed the additional dependencies for Python Extension module, the user can install the extension module by\n sudo pip install ccextractor OR pip install ccextractor --user (the above method has been successfully tested on unbuntu16.04 - Xenial)\nIn case of virtual environments, the user can install the Python Extension module by\npip install ccextractor\nAfter the user has successfully installed the extension module, the user can test the module as per the test script which is used for processing a single sample. However, if the user desires to process all the samples in a particular directory then the user can use this test script.\nNOTE: In case the installation fails, make sure you have updated setuptools, pip and also installed/compiled all the dependencies mentioned in this section.\n Technical Documentation Architectural Documentation The overall documentation for the extension module as to how has the module architecture designed and how the further contributors can continue development has been done in this documentation.\nDependency Documentation For the contributors who want to either just install the dependencies for the extension module documentation would help them understand the dependency compilation.\nContributor Documentation For contributors who wish to understand how exactly is the CCExtractor Extension module compiled and installed on a system, this documentaion contains relevant information.\n Contributions [PRs/Commits] All the commits made by me to the CCExtractor repository could be found here.\nAll the pull requests by me to the CCExtractor repository could be found here.\n Bugs Tracked  I have worked on solving issue #705 and submitted a PR(merged), thus solving the issue. I have also worked on issue #304. I analyzed the issue's sample and found some errors in the way the sample information was encoded. A detailed discussion is present at our Slack under channel bug304.   GSOC 2017 Experience The overall GSOC experience was really wonderful and the entire team here at CCExtractor was really helpful. The project was really challenging and helped me learn a great deal of basic as well as advanced concepts for software development.\nThe project included additions in CCExtractor source code as well as additions in Python extension module part to continue the processing of captions via Python. Thus, the project was really helpful in exploring concepts of C as well as Python. In addition to these, I also learnt a number of technologies such as SWIG, Python C-API, GCC- compiler basics as well as advanced topics, GDB, etc.\nMoreover, this project helped me get a much deeper knowledge of Open Source Software Development.\n About me I am final year student studying at IIT Kharagpur, India. I would definitely be an active contributor not only for CCExtractor extension module but also the Sample-Platform as well as CCExtractor.\nEmail address : diptanshuj@gmail.com\nBlog : https://diptanshujamgade.wordpress.com\nGitHub profile: https://github.com/Diptanshu8\nSlack : skrill\n Thank you. ","link":"https://ccextractor.org/public/gsoc/2017/diptanshu/","title":"Python Extension Module (bindings) for CCExtractor"},{"body":"This is the main documentation of Python extension module for CCExtractor:\nCCExtractor Library Refactoring the codebase into a library Earlier version of CCExtractor was compiled as a binary and could not be used as a library. The entire codebase was executed via a single main function defined in ccextractor.c and this architecture was not suitable for extending ccextractor source code to a library. Hence, many modifications were made to ccextractor.c so that conversion to a library could be done. Major modifications were:\n Segmenting the larger functions into smaller functions so that they could be called from one main function. Earlier the entire processing was carried out from one main function itself. This was not a good idea considering the possibility for library. This would allow the user to set the parameters to be passed to CCExtractor from Python with one parameter at a time and not the entire list of all parameters together. The refactoring of the code base and architectural judgements as to how the code should be segmented so that the entire working remains the same and also the library structure could be established.  Apart from these changes, the header file ccextractor.h was also included into the codebase to define many global variables as well as the function declarations of definitions made in ccextractor.c. The major changes could be seen at this PR (merged). However, following the next stages of development after the changes made in the above mentioned PR, the final structure could be found at ccextractor.c and ccextractor.h.\nDefinitions made in ccextractor.h  In ccextractor.h, the major changes included declaring global variables which would be accessible throughout the codebase for calling the respective callbacks (discussed later in the documentation) from C to Python for processing the caption frames in Python as they are extracted in CCExtractor. The global variable was also used to keep a track of the start time and end time of caption frames so that the CE-608 grids belonging to the same frame could be clubbed together. The global variable array has been defined and the respective structure definition has also been done in ccextractor.h. The global variable array is an instance of this structure. The elements of the structure are PyObject* reporter, int sub_count and struct python_subs_modified* subs. The subs has been defined with start_time and end_time as its elements. More detailed description about why start_time and end_time have been used is given in the section describing about extractors. The main motivation for defining a global variable to catch hold of start time and end time of the caption frames as they are processed in CCExtractor is to identify the text, font and color grids (for CE-608 captions) that belong to the same caption frame. The major point to note is that the compilation of Python extension module includes setting a macro PYTHONAPI which acts as an indication that the compilation is made for Python extension module and this helps in declaring as well as defining the functions which are only needed for Python extension module. As defined here, the PYTHONAPI macro is used to define the functions/variables which are needed only by the extension module. Another major advantage of defining the macro PYTHONAPI is that the definitions made for Python extension module only need python-dev package as a prerequisite for compilation. However, if the user wants to compile only CCExtractor and not the Python extension module, then the code should not have python-dev package as a dependency. This has been attained by using macro PYTHONAPI and C pre-processors.  CCExtractor Python Extension Module Extension module dependencies 1. SWIG  For generation of the wrappers of the C code base, which would then be used to compile the extension module, I have used SWIG (swig-3.0.12). The entire compilation has been included in a build script (discussed later) and the user need not have prior knowledge of SWIG to get started. For compiling the Python extension module, the second dependency in addition to the dependencies of CCExtractor is SWIG. The user can follow these installation steps for getting SWIG installed. For generating the wrappers of the C/C++ code in a user required language, the user needs to have a basic understanding of the interface file which is used by SWIG. However, in case of generating the extension module for CCExtractor, the interface file has been written and is available here. SWIG uses this interface file to generate the wrappers for CCExtractor which are then compiled to form the extension module.  2. Python-dev package Overall architecture  The entire Python Extension module related work is done in the api/ directory with modifications to the CCExtractor codebase to integrate the divergent path, CCExtractor would take if the processing is done via Python module.  Generating the Python extension module  For this project, I have mainly used two build scripts, viz., build_api and build_library which are both present in the api/ directory. For generating the Python bindings, user need to just run the build_library script as ./build_library. This would internally generate the SWIG wrappers from the SWIG interface file (ccextractor.i) present in the same directory. The user should note that if the user has not installed SWIG, the the compilation would stop at this step itself. Once the wrappers are generated, then the build_library script would execute the build_api script which would compile the entire code base of CCExtractor along with the wrappers generated by SWIG. In addition to this, build_api would also compile the extractors and wrappers defined in the extractors/ and wrappers/ directories respectively. Once the compilation is successful, then build_library would generate a shared library called _ccextractor.so from the entire code which would be shared object for the module. In addition to generating the wrapper codes generated by SWIG, it also outputs the ccextractor.py which would be later used as Python extension module for accessing CCExtractor functionality via Python. As mentioned in earlier section, the build_api compiles the entire code base with an option -DPYTHONAPI which is used by GCC to define a macro PYTHONAPI. This macro then acts as a signal telling that the extension module is being generated and the bindings dependency need a check as well as the bindings dependent functions need to be defined.  Workflow of Python extension module The following section encompasses on the detailed description of the entire workflow of Python extension modules and the importance of each function in the codeflow. An example usage has been done in api_testing.py.\napi_init_options Function declaration- struct ccx_s_options api_init_options()*\n This function returns an initialized instance of struct ccx_s_options which is modified in CCExtractor according to the values of the parameters provided by the user while executing CCExtractor.  check_configuration_file Function declaration- void check_configuration_file(struct ccx_s_options api_options) This function is used to check the configuration file and it takes the struct ccx_s_options instance as returned by api_init_options().\napi_add_param Function declaration- void api_add_param(struct ccx_s_options api_options,char arg)**\n The api_add_param function is used to add user passed parameters to the struct ccx_s_options instance which would be used to compile the parameters and make the necessary modifications in the working of CCExtractor. This function takes the instance of struct ccx_s_options passed to check_configuration_file function and also, the string denoting the parameter passed by the user. The parameters are added to the python_params element of struct ccx_s_options and the count of the parameters is kept in python_param_count.  my_pythonapi Function declaration- (depends on whether the compilation is done as CCExtractor binary or as extension modules)\n The my_pythonapi is defined on the basis of how the compilation has been done by the user. If the user wants to use CCExtractor binary rather than the Python extension module, then this function is defined as #define my_pythonapi(args, func) set_pythonapi(args) with the set_pythonapi being defined in wrapper.c. However, if the user wants to build the extension module, then the definition of my_pythonapi is done as #define my_pythonapi(args, func) set_pythonapi_via_python(args, func) with the set_pythonapi_via_python function being defined in wrapper.c. Thus, it can been observed that my_pythonapi takes two arguments when the compilation is done as extension module. In both the case, the first argument is struct ccx_s_options instance as used by api_add_param. But in case of compiling the extension module, the my_pythonapi function takes a second parameter which is the python callback function that CCExtractor would call when passing values from C to Python (a detailed discussion about this has been done later). This function is not a mandatory function to call when using the CCExtractor binary.  compile_params Function declaration- *int compile_params(struct ccx_s_options api_options,int argc)\n The compile_params function mainly compiles all the parameters supplied by the user and modifies the elements of the api_options on the basis of the parameters supplied by the user. In this function, we add a dummy parameter ./ccextractor so that the parse_params function which is called from compile_params function properly compiles all the parameter except the first parameter as done in here. This function then returns the return value as obtained by the parse_params function.  call_from_python_api Function declaration- *void call_from_python_api(struct ccx_s_options api_options)\n The call_from_python_api function checks if the parameter -pythonapi was provided by the user. If the parameter was passed by the user then the global varable signal_python_api is set to 1 showing that the execution is done via Python modules; otherwise the value of signal_python_api is 0. In case of clarifications, the user does not explicitly need to pass the parameter -pythonapi. It is passed by the my_pythonapi function and thus used by call_from_python_api to set the signal_python_api to 1.  api_start Function declaration- int api_start(struct ccx_s_options api_options)\n This is the most important function of entire processing done by CCExtractor. After the entire compiling of parameters have been completed, then comes the stage when the actual processing is done. The api_start is the function which is majorly responsible for extracting the caption frames and passing them back to Python for processing.  The user should note that the codeflow discussed above till this point is generic to both CCExtractor binary as well as CCExtractor's Python extension module. From this point onwards, the codeflow that has been described is mainly how the Python extension module accepts the caption frames via callback function and then processings done on the caption frames to generate the output subtitle file (.srt) via Python.\n The api_start function in case of CE-608 captions calls a function general_loop for processing of the sample(video) that needs to be processed which in turn makes a call to encode_sub which encodes the subtitle buffer obtained from the sample. In encode_sub function, the sub_type is checked to be CE-608. If the sub_type is 608, then another check is made to check the value of signal_python_api. If the signal_python_api is set to 1, then a call to pass_cc_buffer_to_python is made. Otherwise, the processing continues as if the call for processing was made from CCExtractor binary.  From the pass_cc_buffer_to_python function, the call is made to the extractor function, then the extractor function in turns calls the callback function provided earlier via my_pythonapi function. The arguments given to the callback function are the ones corresponding to the information content of the caption frame which has been processed by CCExtractor. This information is accessed via the Python SRT generator scripts which would process the caption frames and write the processed information in the output subtitle files. The following sections would be sequential in-detail descriptions about how each process functions:\nPython Encoder for CCExtractor  Following the architecture of CCExtractor’s codebase, a new file named ccx_encoders_python.c was added. The main reason of adding this file was to define the functions which would be called when the extraction process or CCExtractor extraction functionality is being performed via Python extension module. At this moment, since the extension module extends support only for CE-608 samples, only pass_cc_buffer_to_python function has been defined. Later on, when the binding’s support is extended to support other formats then in that case other functions like pass_cc_bitmap_to_python and others would be included in this file following the architecture of other encoders.  pass_cc_buffer_to_python Function declaration- **int pass_cc_buffer_to_python(struct eia608_screen data, struct encoder_ctx context)\n This is the function where the actual work of passing the extracted caption buffer to Python extension modules for processing the caption frames is done. The pass_cc_buffer_to_python function is called when the sample from which the caption frames are to be extracted is a CE-608 sample and the call for extraction is made from Python extension module. In this function, whenever a caption frame element is extracted, be it the srt_counter, caption timing information or any information related to the text, font or color grid of the CE-608 captions, then that information is passed to extractor function defined in extractors/ directory. A detailed description about how exactly the extractors function would be included in the next section.  Extractors for bindings  As documented in the previous section, when the extraction of CE-608 caption frames in done via Python, then the call is made to pass_cc_buffer_to_python function defined in ccx_encoders_python.c. In this function, after extracting lines in a caption frame (lines may belong to any of the text, font or color grid for CE-608), those lines are passed to python_extract_g608_grid function defined in extractors.c.  python_extract_g608_grid Function declaration- void python_extract_g608_grid(unsigned h1, unsigned m1, unsigned s1, unsigned ms1, unsigned h2, unsigned m2, unsigned s2, unsigned ms2, char buffer, int identifier, int srt_counter, int encoding)*\n The main aim of using python_extract_g608_grid function is to able to identify the lines belonging to a particular frame and then passing these lines to the Python callback function with added identifiers for identification as to which CE-608 grid those lines belong to in a particular caption frame. More documentation about the identifiers and the nomenclature used for the bindings has been documented in the ‘Support for only CE-608 captions’ section and the user is advised to read that section to get a better understanding of the nomenclature. The arguments passed to python_extract_g608_grid include encoding which is the encoding that CCExtractor would have used to write the output subtitle file. Thus, the encoding is passed from CCExtractor to Python via the callback function so that the output subtitle file generated by Python would have the same encoding as the output generated by CCExtractor would have had. Out of all the arguments that are passed to the python_extract_g608_grid function, the one interesting argument is the identifier argument which has different values depending on the type of caption frame line it is called with. For example, if the line passed to python_extract_g608_grid function is a line belonging to its color grid, then the value of the identifier would be 2. Similarly, we have:  identifier = 0 -\u0026gt; adding start and end time identifier = 1 -\u0026gt; subtitle identifier = 2 -\u0026gt; color identifier = 3 -\u0026gt; font   This is how the python_extract_g608_grid function is able to generate the entire caption frame for a CE-608 sample along with timings.  Callback Function architecture  When using the extension module, when a particular C function is called from Python, the control is transferred to C and returned to Python only after the execution of the function. However, according to the adopted architecture, a single function would process the entire sample and extract all the caption frames until the control is passed back to Python for processing the captions in Python. Thereupon, for further processing in Python the user would have had to wait until the end of the extraction of all the caption frames from the sample. This would violate the basic ideology that the module should be able to process the caption frames in Python as they are extracted in CCExtractor rather than waiting till the end of extraction from the entire sample. As a result of this, the callback function architecture was adopted. The main advantage of this architecture is that the moment a line from the caption frame is extracted the line is passed via a callback function to Python and the processing of the extracted line could be done in Python. In the present architecture, the user has a flexibility to tell CCExtractor which Python function would act as a callback function and a mechanism has been designed to convey this function to CCExtractor. This has been done with the use of my_pythonapi function as discussed in the previous sections. NOTE: In the api_testing.py, I have defined the callback function to be named callback. However, the user has complete freedom to define any name for the callback function. The user needs to note that the callback function would be getting nothing but a line from the caption frame that is extracted by CCExtractor. Further processing of the extracted line is the responsibility of the user. After defining the callback function, the user needs to make sure that this function is passed via Python to CCExtractor so that it can be used for callback. For doing so, the user needs to set the second argument of the function my_pythonapi as the callback function. This has been done in the api_testing.py script and the user can refer to it for example. A detailed description about why a single line of the caption frame is passed via the callback function and not the entire frame is described in detail in later sections. Also, when the user passes the callback function via Python to CCExtractor so the my_pythonapi function saves a pointer to this function as an element to a global structure, array, defined and declared in ccextractor.h. The element reporter holds the callback function passed by user via Python. Whenever the user wants to pass a line to the callback function then the user needs to call the function run which has been defined in ccextractor.c.  run Function declaration- void run(PyObject * reporter, char * line, int encoding)\n The run function takes two arguments and their description is as follows:  The first argument is the callback function which the user passes via Python. According to present architecture, this callback function is contained by the element reporter contained in the global structure named array. So the first argument is array.reporter. The second argument to the run function is the line which needs to be passed to Python.    This is how the callback mechanism works for passing the lines from C to Python in real time.\nProcessing output in Python  As described in the previous sections, the extension modules just return a single line from the caption frames. The processing of the caption frames to generate the output subtitle file is done in Python. A script to generate an output subtitle file from the extracted captions frames in Python has been written. The api_testing.py has a function named callback which acts as a callback function returning the extracted caption lines in Python. These lines then are passed to generated_output_srt in api_support.py described in the api/ directory. Thereupon, the function searches if the line has specific identifier which are used to decide how the output would be generated. A detailed section has been included in this documentation regarding the nomenclature used for processing different lines in CE-608 format caption fields (Support for only CE-608 captions section). The main reason for doing so is to avoid any buffering in C to hold the caption lines until the entire caption frames are extracted. This facilitates real time processing of the extracted caption frames. For getting the output filename from CCExtractor which would then be used to write the output srt file from Python, whenever the code is run from the extension module the first line that is passed via the callback function is the output filename generated by CCExtractor. This is incorporated by calling the callback function from init_write function defined in the src/lib_ccx/output.c file. The line passed to the callback function is of the format filename-and this is then used to generate the output file. This line is then captured in the generate_output_srt function defined in the api_support.py. However, if the user wants the flexibility of defining the filename in a different manner, then for such outputs, the user must make changes in the generate_output_srt function to set the filename and ignoring the first line that appears in Python via the callback function.  Support for only CE-608 captions For understanding the CE-608 caption format, the user is advised to refer to this documentation on CE-608.\n The Python extension module is so far able to extract the captions frames from CE-608 samples. In samples with CE-608, the caption frames that are extracted by CCExtractor are in the form a 15x32 grid which depicts the screen. Thus, the information regarding the font of the captions, the colour they would be having on the screen as well as their alignment on the screen is captured in font,color and text grids respectively. Using Python modules each of such grids can be accessed in Python. However, as described in the previous section the callback function gets a single line and not the entire grid from CCExtractor, some processing needs to be done in Python for getting the user required grids per caption frames. The functions which would be acting as the processing and buffering functions for grid generations are present in the ccx_to_python_g608.py. The two major functions are return_g608_grid and g608_grid_former. The g608_grid_former is mainly used to form the grid from lines obtained at the callback function. The main advantage of the return_g608_grid function is that the user can generate whatever pattern the user desires to process in Python. For accessing various different combinations of the font, color and text grids in CE-608, a help_string has been defined in the return_g608_grid function in the ccx_to_python_g608.py file which describes on the value of mode to be passed to this function to get proper combination of the grids. In the earlier sections it has been stated that the callback function in Python is not passed with the entire caption frame but just one single line from the frame, a particular nomenclature has been devised to make sure that the lines belonging to the same caption frames are identified in the Python interface. The nomenclature is as follows:  For every frame, the first line that is passed to the callback function is the srt_counter which indicates the identifier value of the caption frame that would be extracted next. Following the srt_counter, the next line would contain a conjunction of the start time and end time of the caption frame with respect to the timings when the captions would be visible on the screen. The start_time and end_time would be conjuncted as start_time-t end_time-n and the user needs to process this line to get the timings. This processing in case of getting a srt file as an output has been done in the generate_output_srt function. After the timings have been sent via the callback function, until the next srt_counter is extracted, the lines containing information about the color, font or text grids of CE-608 samples are passed via the callback function to Python. For processing the grids separately, the color grid could be identified by identifying the presence of color[\u0026lt;srt_counter value\u0026gt;]:in the line obtained from the callback function. Similarly, for the font and text grids, the nomenclatures are font[\u0026lt;srt_counter value\u0026gt;]:and text[\u0026lt;srt_counter value\u0026gt;]:respectively. Processing a grid on the basis of such a nomenclature has been done in the g608_grid_former in the ccx_to_python_g608.py file. After the entire caption frame has been sent via the callback function to Python for further processing, when the extraction of present caption frames finishes and CCExtractor shifts to a new frame, then a line containing END OF FRAME is passed via the callback function from C to Python. The user needs to catch this line in order to get the signal that from the next line onwards a new caption frame would begin. Similar approach has been implemented in the function generate_output_srt in the api_support.py file.    This is how the entire CE-608 is transmitted to Python and the user needs to follow the nomenclature in order to get the caption frames in Python.\n However, if the user thinks to modify the nomenclature in accordance with some other nomenclature that suits their use case, then the user can do so by editing the python_extract_g608_grid function in the extractor.c file. In this file, the user needs to find the lines where the function run is called with its first parameter being the callback function that is passed from Python and the second parameter being the line which is to be passed to Python.  Wrappers for the extension module  In case of using an API, it is highly desired to set the parameters desired by the user not via command line but as call to built-in functions. This gave rise to the necessity of wrapper functions which can be called to set certain parameters for directing the functioning of the bindings. The wrappers have been defined in the wrapper.c file in api/wrappers/ directory. The user can use just call the wrappers to set some parameters. More wrappers can be defined according to the architecture followed in wrapper.c. The user needs to note that the wrappers can be called anytime in between adding parameters to CCExtractor instance (as done in api_testing.py) and before calling the compile_params function from the CCExtractor module. Another thing to note about the wrapper is that, the my_pythonapi wrapper function is a very important wrapper function. It tells CCExtractor that the call has been made using the Python module and thus the functioning of CCExtractor is altered. Hence, if the user intends to use the Python module the user is always advised to call this wrapper function with its first argument to be the object returned by api_init function from CCExtractor module and second argument being the callback function which would be called by the CCExtractor to pass the extracted caption lines back to Python.  Test Script  Once the Python module are generated then the user can use them by importing ccextractor module in Python. For testing the output of the bindings a test script, api_testing.py. But to mention, the module at this stage only supports generating a subtitle file from the CE-608 standard samples only. Another testing feature, that has been added is that the user can use recursive_tester.py to generate the subtitle files for all the samples from a directory. The only parameter needed to run this script is the location of all the samples.  Silent API  The Python bindings have been designed in such a way that the API is silent in itself as well as in the form of output generation. Silent in itself means that the API doesn’t write out any output to the STDOUT and the entire output of CCExtractor is silenced when the module is used for extraction of caption frames. This feature has been made possible by passing a parameter -pythonapi internally in api_testing.py using the function my_pythonapi() from the ccextractor module. The -pythonapi internally makes CCExtractor to silence all the outputs that could have been generated otherwise. If the user wants to add some print functionality from the CCExtractor, then may be defining the prints using printf C function could be an option. Note that the user cannot use the mprint function to get prints from the extension module from inside the CCExtractor C code part as used in CCExtractor to get the desired STDOUT prints as these are silenced via -pythonapi.  Work status  The proposal made by me for this project had a major component of multi-threading to let CCExtractor’s Python bindings run the CCExtractor’s extraction process in multi-threads. However, the end goal was modified while the GSOC 2017 coding period and after Second Phase Evaluation, the main aim was to create a Python extension module for CCExtractor which could process CE-608 video samples, extract the caption information present in them and pass this information to Python for further processing. The module was expected to be silent and the output generation from the caption information present in the video sample has to be done via Python. The present status of the extension module is that the module can extract caption information from CE-608 standard video samples and pass the caption information to Python. Further work has also been done to process this caption information to generate an output subtitle(srt) file (the user is advised to check completion of comparing_text_font_grids function sub-section under the future work section).  Future Work Identifying the input format and raising errors if unsupported  CCExtractor does not process any non-video files. Similarly, the processing of non-video files is not supported by extension module. However, since the API has been designed to be silent, the module doesn’t output any error log stating that the input file is a non-video file and it cannot be processed. This is a much desired feature and the present version of CCExtractor extension module lacks this feature. I would be working on this feature post GSOC 2017 but if any user finds that this feature has not been added until they start contribution to CCExtractor’s extension module, then their work on this feature would be highly appreciated. For adding this feature to extension module, the extension module must be extended to process the return value from CCExtractor as done in the api_start function. When the sample (non-video) is processed via CCExtractor’s binary, then the processing is stopped by raising an ‘Invalid option to CCExtractor Library’ error. However, since the extension module has been designed to be silent, this error message is suppressed. Hence, the user should extend the test scripts to process the return value of api_start function in python extension module according to the constants defined in ccx_common_common.h.  Callback class mechanism  The present architecture uses a callback mechanism to pass the extracted caption lines from the caption frames of CE-608 captions to Python for further processing. In the callback mechanism, a callback function is supplied to CCExtractor in C via the my_pythonapi function which stores the callback function as a PyObject* in the global variable array. However, according to Python documentation on C-API, everything in Python is a PyObject; be it a function, a tuple or a class. So, the ideology is to replace the present callback function by a class which can have many methods that the user can use for different use cases. An example of such an implementation has been done here. The user needs to note that for accessing the Python class in C, some modifications need to be done to the run function defined in ccextractor.c and a sample example for calling a class method named ‘callback’ could be found here. Also, an important point to be noted in this case is that the user needs to pass the callback function’s name to run function in C so that the corresponding callback method of the class passed via my_pythonapi could be called via C. As an example, the callback method’s name has been provided here. For understanding the exact implementation of this approach, I would recommend the user to understand C-API for Python as the documentation is quite extensive to every use case.  Completion of comparing_text_font_grids function  The Python extension module for CCExtractor is able to pass lines of the caption frames for different grids of CE-608 captions. However, for generating the subtitle file from the caption grids, the text grid needs to be modified according to the color grid as well as font grid. In CCExtractor, this job is done at the function, get_decoder_line_encoded. For generation of subtitle files (.srt files) from Python, an equivalent version of get_decoder_line_encoded has been implemented in Python and has been defined as comparing_text_font_grids in python_srt_generator.py However, as the user can note that this function is not a complete implementation of get_decoder_line_encoded function, completion of this function’s definition is a matter of future work.  Adding more wrapper functions  As described in the ‘Wrappers for the extension module’ section, more wrapper functions are needed to be declared in the wrapper.c file. For example, few wrappers have been defined. More wrapper functions can be defined in a similar manner.  Extending the module to support other caption formats  In this version, CCExtractor’s extension module supports processing of video samples having CE-608 standard captions in them and writing these captions to output subtitle (.srt) files. However, CCExtractor in itself has support for other caption standards like DVB, 708 etc. So, extension of module to extract of caption information from samples containing the caption information in these formats is a future task. The user should note that the information passed from CE-608 to Python is in raw form as lines which are then used to form the 608 grids. Similarly, the extension to other formats must consider passing the raw information of caption in respective format and then processing the information extracted by CCExtractor in Python. While extending, the architecture to be followed for ccx_encoders_python should be consistent to other encoders in the codebase to maintain uniformity. Thus for DVB samples, a function name pass_cc_bitmap_to_python and for 708 samples pass_cc_subtitle_to_python need to be declared in ccx_encoders_python.c.  ","link":"https://ccextractor.org/public/gsoc/python_extension_module_technical_documentation_gsoc_17/","title":"Python extension module for CCExtractor"},{"body":"The main goal of this year was to bring real-time repository to more stable, less resource demanding and usable version. A lot of decisions made in GSoC 2014 and 2015 turned out to be wrong. So this year I had to start everything almost from scratch. The things that were achieved to this date are:\n Completely changed architecture:  All captions extraction (BIN -\u0026gt; CC) is done on \u0026quot;tuners side\u0026quot; instead of sending BIN to special servers for extracting CCExtractor itself doesn't connect to repository servers, instead a client program ccr should be used. ccr sends both extracted captions and BIN data My own socket connection protocol between \u0026quot;tuners side\u0026quot; and servers was replaced by long running HTTP connection. It handles connection losses easily, as they happens quiet often and also allows to define an API. Communication between web browser and servers is done now via WebSockets. Compared to previous implementations with polling, long polling and server-side events (yes, I tried all of them :( ) it doesn't overload servers's CPUs as much. Repository servers are now handling HTTP and WebSockets requests only. All the received data is stored in Redis cache and backed up to persistent database every few minutes. (In previous versions there were no cache)   Created client program ccr Changed web servers  My own implementation of MVC pattern and routing was replaced by FatFree framework, then it turned out that it doesn't have required features and then was changed by Laravel The same happened to JavaScript client. At the end it was done with Backbone framework. Also now it allows to view multiple channels at the same time WebSocket servers were created using Node.js (check broadcasting/ in repo)   Defined an RESTful API Deployed it in Kubernetes in Google Container Engine with working autoscaling  Besides that:\n I fixed this issue (which is not actually CCExtractor fault:) ) And figured out issue #136 (which is not CCExtractor fault as well)  The first half of the summer went as planned but then some problems arouse. The first version used Google Datastore and App Engine. Turned out hosting it cost $300 per two week which was very expensive. So we decided to use Amazon AWS. I changed the code for their services and then I wasted a lot of time trying to deploy it, but I couldn't and I still don't know why (although I used it in the previous year). Then I switched to Google Container Engine, it worked, but my app used a lot of CPU %, so I had to redesign it again and reconsider a lot of decisions (in panic). Because of this the following features were not done:\n E-mail notifications Creating .deb and .rpm packets for CCExtractor Searching and downloading feature (in API and web site) is not completed  ","link":"https://ccextractor.org/public/gsoc/2016/ruslan/","title":"Real time repository and website"},{"body":"We have a very old GUI, written in .NET no less, a very long time ago. When it was written, CCExtractor was quite simple, and all the options fit in a 1024x768 single page.\nNow we have a large number of tabs that don't look good, the UI won't even adjust to screen size... well, it's rather bad :-)\nSince then, there's been a few attempts to come up with something better (we have a simple UI integrated in CCExtractor itself, a Qt version, and more), but nothing has really reached the point of being better than the old one.\nWe think that with Flutter, it's now possible to write a UI that looks good and is portable. We are targeting Windows, Linux, and OSX.\nThings you have to do:\n Come up with a good design. This means not copying the old one - this is not a port, it's a new UI! - Your program will just run CCExtractor. CCExtractor has an argument to \u0026quot;--gui-reports\u0026quot; that will output progress in an easy to parse format. So you don't need to figure out esoteric ways of integration. Your work is 100% flutter. - Focus on desktop. Mobile is not important, we don't expect anyone to run CCExtractor on their phones.  We'll help you test on all platforms (assuming you only have access to linux, for example).\nThe goal is to completely replace the old GUI, and archive the previous attempts. So this is an important project to us!\n","link":"https://ccextractor.org/public/gsoc/ccextractor_gui/","title":"Replace CCExtractor's GUI with a modern, Flutter based one."},{"body":"This is NOT about rewriting the OCR library (tesseract) of course, but rather, the use with do of it.\nSome subtitles (for example, DVB which is an European format) uses bitmaps rather than text to show subtitles. This is great in the sense that each TV channel can define its own font, style, use special characters and so on. But of course, it makes it impossible to directly generate a .srt file.\nTo solve this problem, we take the bitmap and pass it through an OCR to make the conversion.\nThis process has a bit of proprocessing to help the OCR, which has lots of moving bits around. There's a number of places in which wild-west memory management happens. You know where this is going...\n","link":"https://ccextractor.org/public/gsoc/cc_rust_ocr/","title":"Rewrite the OCR subsystem in Rust."},{"body":"Roku is currently the most common media streamer. It's cheap and neutral (it's not in any \u0026quot;fight\u0026quot;). Unfortunately, there aren't any good open source channels. We started working on one last year, but we didn't get to a status of \u0026quot;awesomeness\u0026quot;. We'd like to continue working on that.\nWe will send a free Roku to our student for development.\nBelow is the description from last year. Some things weren't complete. When you load the channel it doesn't have the polished view that other channels have (for example Netflix has a fantastic layout in which no screen is wasted).\nAn important thing is the progress bar. Roku's default is horrible, and a channel that uses it screams \u0026quot;my developers didn't care\u0026quot;. So a mandatory thing this year is a custom progress bar.\n2020 description\nWhat makes a good Roku channel?\nFor the playback itself Roku provides a basic system in which you have the usual things such as play/store, fast-forward and so on. But there's no default context menu, the progress bar is horrible and looks really bad...\nOrganization must be flexible and complete. Don't assume that things belong in just one place. For example you may want to have a section of Python tutorials, one of AI videos, one of videos in Spanish and so on. Of course there's videos that belong in all three places.\nThe home page must be well designed and pleasant to the eye. It must be easy to navigate.\nRecommendations, last played, search, settings, etc, must be easy to find and by themselves need to be good. Note that the recommendation themselves belong in a backend and you don't need to implement the actual backend: You need to implement the connection to such backend though.\nYou also need to support \u0026quot;activation\u0026quot;, which is the process in which the user links his Roku to an account existing in the system, for example to get access (case of a non-free channel) or custom recomendations.\nYour job is the Roku channel itself, but you must provide a backend skeleton at the very least to support all the channel features.\nQualification tasks\nTake a look at this page.\n","link":"https://ccextractor.org/public/gsoc/rokuchannel2/","title":"Roku reference channel(II)"},{"body":"This is Carlos' quick and dirty solution to have a grid with captions from all stations using a few tuners, obviously by rotating them to cover all channels.\nFile directories:  /bin/ → Scripts /channels/ → Channels, each file being a channel. If name starts with a C then it's cable, if it's a B it's broadcast, anything else is ignored. /tuners/ → One file per tuner, with this naming $devicetype-$tunertype-$masterorregular-$deviceid-$tunernumber where $devicetype is always HDR (for now only HDHomeRun is supported) $tunertype is USC (US-cable) or USB (US-broadcast) $masterorregular is M or R, if M then this tuner will be used to scan for channels by the chanscan script that populates the /channels/ directory $deviceid is the device ID. For HDHomeRun is returned by hdhomerun_config $tunernumber is the number within the device, so for a device with 3 tuners it's 0-2  Scripts:  /bin/tuner_scan → Discover HDHomeRun devices and features, build contents of /tuners/ /bin/channel_scan → Scan for channels, build contents of /channels/ /bin/cc_boot → Starts one capture process per tuner /bin/cc_capture → Using one of the tuners, capture data from a channel in round-robin  The /channels/ directory contains one file per channel. When a channel is being recorded its file must be renamed to $name.inuse. When done, touched, then renamed back to $name.free. If a process attempts to rename a channel file and fails it must assume that some other process picked up that channel and must continue to the next one.\nThe cc_capture script always reads contents of /channels/ and picks the oldest file that is free (meaning there isn't another process capturing it).\nDone:  Create system user (captions), copy public key Edit sudoers  To-do:  Create tuner_scan Create channel_scan Create cc_capture Create cc_boot  ","link":"https://ccextractor.org/public/general/rotating_capture_system_with_hdhomerun/","title":"Rotating capture system with HDHomeRun"},{"body":"Introduction\nrutorrent is the most popular web interface for rtorrent, which is possibly the most used BitTorrent client in linux. It is mostly a web application, but it has its own backend that connects to rtorrent. You could connect to rtorrent directly as well, but by doing that you would be missing lots of features that come with rutorrent, for example RSS support.\nYes, there are two things with almost the same name. To summarize:\nrtorrent =\u0026gt; The BitTorrent client, a console-based tool that also has an API to interact with it. rutorrent =\u0026gt; A web interface for rtorrent that uses that API. It also does other things, for example, it can download torrents from an RSS feed. You configure RSS feeds in rutorrent's web interface, but there's also a backend service (written in PHP) that is part of rutorrent to do the actual download.\nLast year we started this project, and it's gone quite well, with the userbase growing and a number of contributions being made by other developers.\nYour job\nYour job is add a number of features to this project.\n View Models: Generate a state model which holds the current state of the torrent lists even when the internet connection is not available. Currently, the torrent list vanishes as soon as internet connection is disconnected, with this state model, the user experience will improve. Automatic Tests: Write some unit tests for major classes and also widget testing for some components. Media Player: Currently, VLC media player plugin is a heavy integration and also it lacks many of the basic media player functionalities. The aim would be to find an alternative way to stream videos such that the app size gets reduced or enhance the functionalities of it. Production-type environment: The aim would be to create separate branches for master and dev and to regularly merge dev to master to create a new release. Furthermore, this can be automatic using CI/C pipeline integration for the project. Improve Documentation: Document the basic structure and architecture used in the app, maybe use Wikis, so that the new contributors find easy to understand the setup and code. rutorrent has a good IRSSI support. We want the same notifications that appear on IRSSI's tab in rutorrent to be available on our mobile app.  Notes\nIn order to understand what to do you need to actually install rtorrent and rutorrent and play with them.\nYou don't need to have previous experience (really, not important for this - it's all about Flutter), but you won't be able to come up with a good proposal if you don't know how things work.\nAlso, if you are unable to run rtorrent and rutorrent on your system, please use this docker image.\nQualification tasks\nTake a look at this page.\n","link":"https://ccextractor.org/public/gsoc/flutterrutorrent2/","title":"rutorrent mobile interface (II)"},{"body":"Technical Documentation All technical documentation has been posted to the GitHub repositories, either in the form of the README, or in form of comments.\nThe repositories are located here:\nhttps://github.com/canihavesomecoffee/ccx_testsuite (Project from GSoC 2014, not that much changes this year, except for some fixes and improvements) https://github.com/canihavesomecoffee/ccx_gitbot https://github.com/canihavesomecoffee/ccx_submissionplatform\nHow to use? Test Suite No changes from last year, still as described in the first section of CCExtractor regresssion testing / GitHub bot.\nGitHub bot Refer to the bot section in the CCExtractor regresssion testing / GitHub bot page.\nSubmission platform To view samples, test results and download samples there is no need for an account. To upload samples, registration is required. Samples (\u0026lt;1GB) can be uploaded through HTTP; FTP allows all sizes. Special care has been taken to keep all samples anonymous (except to the user itself and the admin), and if required, a user can anonymize his/her account.\nHow to evaluate? The bot can be evaluated (user-side) by issuing commands to it on GitHub (see CCExtractor regresssion testing / GitHub bot for instructions). It's been used already by Anshul, Kisselef and Ruslan for the last PR they made.\nThe sample submission platform can be tested (user-side) by either browsing around on the site and/or creating an account (the latter is required to upload samples). At this moment, a limited section of regression samples was already added, and this will be expanded very soon.\nTo test the admin parts of both the bot \u0026amp; the sample platform I refer to the mail I wrote to Carlos.\nContribution for blog The submission of new samples has been quite chaotic in the past of CCExtractor, with users submitting samples through FTP, GitHub, Google Drive, upload websites, email, ... The sample submission platform aims to create a single place to retrieve and upload new samples, as well as showing the current state (fixed, broken, ...) for those samples. Besides that, a GitHub bot was introduced to allow other contributors run the regression tests without having to download all the samples. This should improve the stability of CCExtractor and hopefully lower the barrier for new contributions.\n","link":"https://ccextractor.org/public/gsoc/2015/willem/","title":"Sample submission platform / CCExtractor improvements"},{"body":"This page is in constant development. We add things as we think of them. It's not exhaustive, and we're open to ideas brought by the technical writers as well.\nCCExtractor Website  Rework our website, which is based on dokuwiki. We're happy to switch to any other software that the technical writer is comfortable with.  User documentation   We have a help screen (which is also exported as a \u0026quot;man\u0026quot; page) that shows all the options, but it's just a list of parameters. Not a lot of examples (meaning maybe 1 or 2), no proper fonts... it could definitely use a do over.\n  Our user tutorials are hopelessly outdated. There's one to process a DVD, and a basic how-to. We need to generate a number of interest use cases.\n  Write scripts for youtube videos. We don't need you to actually produce the videos (but that would be fantastic, of course). The important thing is the script. We can get someone to read it.\n  Developer documentation   Tutorials on how to do a number of things: Write a new decoder, write a new encoder, how to integrate CCExtractor with other tools, compiling...\n  Help us write an official \u0026quot;onboarding\u0026quot; tutorial to help new developers join the team without feeling overwhelmed by our code base.\n  Sample Platform   Write official documentation (a tutorial) on how to properly perform an install of the Sample Platform.\n  Help with \u0026quot;onboarding\u0026quot; tutorials\n  Proper documentation generation based on the python docstrings.\n  Google Summer of Code documentation  Our current documentation for past GSoC projects is \u0026quot;free style\u0026quot;, and there's definitely a broad range of quality, possibly because of that. While we don't want to limit great writers by enforcing a specific style it's probably a good idea to have some \u0026quot;baseline\u0026quot; so that less gifted writers can deliver a minimum of quality. It's a pity when a good project gets less-than-stellar documentation.  Google Summer of Code Ideas pages  We can use help here. Really. We do our best to produce interesting ideas and amazing projects to work on but we seem to be failing on delivery. Given our ideas page for 2019 (some of them will appear in 2020) how can be reorganize the content so that it's clearer, more interesting...?  ","link":"https://ccextractor.org/public/gsoc/ideas_page_for_season_of_docs_2019/","title":"Season of Docs 2019"},{"body":"General mission statement: To generate useful documentation that allows new developers to be productive as quickly as their own skills allow and users to use our software without going to several different places to find how to do even the most basic of the tasks.\nOur commitment to technical writers: We will quickly provide any and all assistance you need and point you to the right people. We will trust you to make documentation decisions both in writing and in organization.\nTo make things as clear as possible we've divided the task in blocks.\nCompiling CCExtractor for the first time.\nAudience: Developers of all levels.\n   Task Current Status Where we want to go What you need to know     1 Tutorial: How to compile CCExtractor on Windows using Visual Studio Documentation does exist, but it's outdated. Also, the procedure itself it's (possibly) more complicated than it should be. This is an onboarding tutorial. It must be possible for a developer with some experience on Visual Studio to build a working binary having only VS itself, your tutorial, and internet access   2 Tutorial: How to compile CCExtractor on Windows using GCC Documentation exists for GCC on Linux, which is a good starting point This is an onboarding tutorial. It must be possible for a developer with some experience on GCC to build a working binary having only gcc (the GNU compiler) itself, your tutorial, and internet access   3 Tutorial: How to compile CCExtractor on Linux Documentation exists, but it's possibly not really well organized This is an onboarding tutorial. It must be possible for a developer with some experience compiling linux programs to build a working binary having only your tutorial, and internet access   4 Tutorial: How to compile CCExtractor on OSX Nothing recent exists. CCExtractor is known to build on OSX, but none of the core developers uses a Mac. This is an onboarding tutorial. It must be possible for a developer with some experience compiling OSX (Mac) programs to build a working binary having only your tutorial, and internet access    Updating CCExtractor dependencies.\nCCExtractor has some dependencies to be built. Some of them are \u0026quot;vendored\u0026quot;, meaning we just took the source code and integrated it into CCExtractor, which has the advantage that we don't need to deal with those dependencies changing over time if we're happy with whatever version we are using, but it also has the disadvantage that we're stuck with those versions - and some times we do need to update them.\nSome are easy to update, and some require a lot of work and/or magic. The documentation is non-existent, and because we do it every N years for some of the dependencies even the person that actually did it last time doesn't remember the details.\nWe'd like to prepare good documentation here that anyone can follow so the next time we do this it's not so painful.\nThe external libraries which we don't vendor (i.e. we use the ones found in the system) are a different problem; of course we don't want to update those, but changes in those libraries often break CCExtractor and we need to follow. We also need documentation for this.\nThe goal is to write a separate guide for each of the dependencies, which currently are:\n   Library URL     Tesseract https://tesseract-ocr.github.io/   Leptonica http://leptonica.org/   libGPAC https://gpac.wp.imt.fr/   zlib https://zlib.net/   utf8proc https://juliastrings.github.io/utf8proc/   protobuf-c https://github.com/protobuf-c/protobuf-c   libpng http://www.libpng.org/pub/png/libpng.html   FreeType https://www.freetype.org/   libhash http://libhash.sourceforge.net/   nuklear https://github.com/Immediate-Mode-UI/Nuklear   libzvbi http://zapping.sourceforge.net/ZVBI/index.html   ffmpeg https://ffmpeg.org/    documentation included with CCExtractor\nThis refers to the documentation that is shipped with CCExtractor, not to online tutorials.\n            1 Rework help screen When you run CCExtractor without parameters it dumps a huge list or arguments. The output is too long, disorganized, it has no examples... this started when CCExtractor had 3 possible options, not 60. This needs to be be reorganized. Cooperation abilities. This is needed because you will need to interact a lot with a developer that adjusts the output to what you recommend.   2 Organize existing documentation We currently have a docs folder with various things. Your job is to classify what we have. This means decide what to throw away (no longer relevant), what needs to be updated but can be saved, what need to be rewritten, what needs to be merged... Patience    Website\n            1 Reorganize The website is rather disorganized, and there's duplicate information in several pages, as well as shared content (that is sync'ed manually) between the man pages and the website Decide what goes where, rewrite pages, delete pages. -    GitHub\n            1 Create a good template for new issues We have a boiler plate template that is too long and doesn't allow to quickly see what the issue is about We want to have a simple template and tells the user exactly what to do, that doesn't feel like you are doing taxes, and that has an output that allows to understand at a glance what a problem is. -    Google Summer of Code\n            1 Improve tasks descriptions We've been doing our best every year to improve our tasks description, and we think we've done an acceptable job, but there's room for improvement Starting with two of three \u0026quot;classic\u0026quot; tasks (that are really important to us but no student ever picks), come up with a good definition that is accurate, complete, and points to the right resources. -    User documentation   Our user tutorials are hopelessly outdated. There's one to process a DVD, and a basic how-to. We need to generate a number of interest use cases.\n  Write scripts for youtube videos. We don't need you to actually produce the videos (but that would be fantastic, of course). The important thing is the script. We can get someone to read it.\n  Developer documentation   Tutorials on how to do a number of things: Write a new decoder, write a new encoder, how to integrate CCExtractor with other tools, compiling...\n  Help us write an official \u0026quot;onboarding\u0026quot; tutorial to help new developers join the team without feeling overwhelmed by our code base.\n  Sample Platform  Help with \u0026quot;onboarding\u0026quot; tutorials (e.g. submitting samples, linking GitHub to the platform so issues can be opened with the correct sample link). The Sample Platform website can be found at https://sampleplatform.ccextractor.org.  Google Summer of Code documentation  Our current documentation for past GSoC projects is \u0026quot;free style\u0026quot;, and there's definitely a broad range of quality, possibly because of that. While we don't want to limit great writers by enforcing a specific style it's probably a good idea to have some \u0026quot;baseline\u0026quot; so that less gifted writers can deliver a minimum of quality. It's a pity when a good project gets less-than-stellar documentation.  Google Summer of Code Ideas pages  We can use help here. Really. We do our best to produce interesting ideas and amazing projects to work on but we seem to be failing on delivery. Given our ideas page for 2020 (some of them will appear in 2021) - how can be reorganize the content so that it's clearer, more interesting...?  ","link":"https://ccextractor.org/public/gsoc/ideas_page_for_season_of_docs_2020/","title":"Season of Docs 2020"},{"body":"Projects  Realtime Translation using Google Translate Realtime Translation using Apertium Web application to compare statistics of Stock Price, TV Mentions and Twitter  Technical Documentation All the technical details are commented in the codes and the documentation is available in the Readme's of their directories. The variables, classes and other components of the code are named properly in Camel Case for easier understanding of the code.\nRepositories:\n https://github.com/Akirato/goslateTranslator - Google Translate Translator https://github.com/Akirato/apertiumTranslator - Apertium Translator https://github.com/Akirato/sentimentAnalysisTool - Tool for Sentiment Analysis https://github.com/Akirato/statsChart - The entire web application for statistics comparison https://github.com/Akirato/statsChart-backend - The backend of the statistics web application  How to use? Google Translate and Apertium Realtime Translation The instruction to use the codes directly are given in the Readme of the repositories. A sample of translator from English to Spanish is available at http://gsocdev.ccextractor.org/~nurendra/translated/test2/tail.php\nWeb Application for comparing Statistics The application is presently hosted at https://95.211.109.210/statsChart/default/index It has been built on Web2py framework.\n Make a MySQL database called \u0026quot;statschart\u0026quot; and run the three scripts given in https://github.com/Akirato/statsChart-backend Download web2py from http://web2py.com/init/default/download Clone https://github.com/Akirato/statsChart into web2py/applications/ Go to web2py/application/statsChart/models/db.py and connect your databases. Run the web2py server. The application should be hosted at /statsChart/default/index  Deployment on a new server:\n Make a MySQL database on the server called \u0026quot;statschart\u0026quot; and run the three scripts given in https://github.com/Akirato/statsChart-backend Install and deploy web2py on a new server. Several Deployment Recipes for common servers are given at http://web2py.com/books/default/chapter/29/13/deployment-recipes After this is done, a web2py/ directory will be made in the server. Clone https://github.com/Akirato/statsChart into web2py/applications/ Go to web2py/application/statsChart/models/db.py and connect your databases. Run the web2py server. The application should be hosted at /statsChart/default/index  How to evaluate? Google Translate and Apertium Realtime Translation Repositories of both the translators have methodAnalysis/analyse.py file. Execute this file if the code is working properly. Also English-\u0026gt;Spanish realtime translation is available at http://gsocdev.ccextractor.org/~nurendra/translated/test2/tail.php\nWeb Application for comparing Statistics The web application is hosted on https://95.211.109.210/statsChart/default/index To look at the entire code, go to https://95.211.109.210/admin/default/index Give the password: \u0026quot;akirato123\u0026quot; and select \u0026quot;statsChart\u0026quot; to check the entire code.\nContribution to blog The subtitles generated by CCExtractor can now be translated and be made available to a larger audience due to the realtime translation tool. The tool uses Google Translate and Apertium to provide online and offline translation respectively. The Statistics website collects data from Twitter using Twitter API, from TV advertisements using CCExtractor and shows it effects on the Stock Price which are updated using Google Finance. This will be very useful for opinion collection and looking at the effects of advertisements on Social Media.\n","link":"https://ccextractor.org/public/gsoc/2015/nurendra/","title":"Sentiment Analysis / Realtime Translation with Google Translate/Apertium"},{"body":"Files and Directories The most important directories and files in server application are:\n./ server base path archive/ extracted cc files Year/Month/Day/ *.srt, *.txt, *.bin files' names match to ids in programs table in db bin/ executable files build/ object files generated during compilation server server app executable ccextractor config/ db.ini database configuration (user, password etc) server.ini server app configuration (port, logs etc) web.ini Web site configuration (not used) docs/ doxygen docs, readme images io/ files generated during runtime cce_input/ ccextractor input named pipes cce_output/ ccextractor output files web/ Web site buffer logs/ server app log files src/ server app sources tests/ test scripts and test client app web/ *.php Web site additional files public/ application Web root, contains Web accessible files css/ js/ *.php Makefile Makefile for compiling server app and generating docs ","link":"https://ccextractor.org/public/gsoc/server_application_structure/","title":"Server Application Structure"},{"body":"Slack is a great communication tool. Most CCExtractor developers hang out in a slack team. You're welcome to request an invitation here, use token: subtitles\nTechnical issues By far the best way to get report issues is by opening a ticket at GitHub's issue tracker.\nWhen creating a ticket:\n Make sure you are using the last CCExtractor version. If it's a new thing (for example a video file that a previous CCExtractor version processed OK and now causes a crash) mention the last version you know was correct. If the issue is about a specific file, make that file available for us. Don't just send us the output from CCExtractor, we can't do anything about a screenshot that shows a crash, we need the input that actually causes it. Preferably you make it available for us on the Sample Platform, but you can also upload the file to Dropbox, Google Drive, etc, and add a download link to your ticket. If you cannot make the file public for any (reasonable) reason you can send us a private invitation (both Dropbox and Google Drive allow that). In this case we will download the file and upload it to the private developer repository. Do not upload your file to any location that will require us to sign up or endure a wait list, slow downloads, etc. If your upload expires make sure you keep it active somehow (replace links if needed). Keep in mind that while we go over all tickets some may take a few days, and it's important we have the file available when we actually need it. Make sure you set an alert in GitHub so you get notifications about your ticket. We may need to ask questions and we do everything inside GitHub's system. Please use English. It goes without saying, we like polite people.  Mailing list We do have a mailing list available here, and all GitHub issues are posted here.\nIt's read by the right people; you can use it if you prefer it to Slack.\nEmail If you need to use email, you can reach the organisation's admin on the next email address: carlos@ccextractor.org\n","link":"https://ccextractor.org/public/general/support/","title":"Slack"},{"body":"Introduction\nBitTorrent protocol is not secure. Its RC4 encryption mechanism (MSE/PE) is outdated and weak. It provides no anonymity. It is (at best) an obfuscation, by current standards. Even for obfuscation, it is ineffective. As early as 2010, there are efficient, reliable and highly accurate methods to unmask and classify encrypted/obfuscated BitTorrent traffic [1][2]. Nowadays, even an entry-level gateway has the capability [3] to detect and block BitTorrent traffic at little to no risk. The BitTorrent community would benefit from a new standard encryption mechanism that allows strong encryption, forward secrecy and resistance to censorship.\nTLS (SSL) is the ideal solution. It is well-established, secure, extensible, tested and optimized. There is no need to reinvent the wheel this time. TLS also gives the BitTorrent protocol the strongest resistance to censorship. HTTPS and, by extension, almost all websites/apps/games, uses TLS for transport security. Given TLS's battle-tested secrecy, BitTorrent over TLS traffic can not be distinguished from other traffic, and, as a result, the risk will be immense for anyone who wants to block it. Modern devices also have special optimizations for TLS and its cryptography algorithms, so the performance penalty of strong encryption is no longer significant.\nlibtorrent-rasterbar (used by qBittorrent, Deluge, etc.) has support for some form of BitTorrent over SSL from 2012 [4]. However, the mechanisms are never standardized and the current design has critical flaws that severely limit its usefulness. In the current implementation, a tracker must be present to sign/approve the peers, and there must be a certificate inside the .torrent file. This basically limits the feature to corporation/commercial uses only.\nYour job\nThe goal here is to design an alternative mechanism that allows all existing torrents to enjoy the benefits of TLS. For instance, there might be three security levels: Basic (only use existing data like infohash for TLS handshake, compatible with all existing torrents without modification), Strict (require match of a new certificate/data/passphrase inside .torrent file, defeat infohash leak) and Full Strict (require a secure tracker to sign off each peer, similar to the current implementation). However, ultimately, it is up to you to decide the specifics.\nYou are expected to write a BitTorrent Extension Proposal (BEP), and, with the help of your mentor, submit it to bittorrent.org, which is the first step towards standardization.\nYou should also implement a proof of concept, which is evolved along with the standard. This allows you to avoid unworkable/unrealistic parts. It also makes it easier to convince the community to accept your standard.\nIt is preferred to implement the PoC on top of an established BitTorrent implementation (libtorrent-rasterbar, libtorrent-rakshasa or libtransmission). They are the most widely-used open source BitTorrent implementations, and their developers and users have significant stakes in the community.\nAlternatively, if you are not a fan of C/C++, you may choose one of the emerging BitTorrent implementations, including but not limited to:\n anacrolix/torrent (Go) Luminarys/synapse (Rust) webtorrent (JavaScript)  ","link":"https://ccextractor.org/public/gsoc/bittorrent-tls/","title":"Standardize BitTorrent over TLS (SSL)"},{"body":"Details All the technical details are commented in the codes and the documentation is available in the Readme's of their directories. The variables, classes and other components of the code are named properly in Camel Case for easier understanding of the code.\nRepositories:\n https://github.com/abhishek-vinjamoori/SubtitleExtractor - Subtitle Extractor  I am the only contributor to this repository. Started it from scratch.\nHow to use? The usage is listed in the README file of the GitHub repository and also in the USER DOCUMENTATION WIKI PAGE\nTechnical Documentation The technical documentation about the code architecture and how to add support for new services has been written in the Technical Documentation Wiki\nAbout the Project The project deals with downloading of subtitles from popular online TV Services like Netflix, BBC,Hulu. The project aims to perform this task without the need for the user to interact with the browser. The process is automated completely. The user just needs to input the URL of the video and the application will download the subtitles. For services like YouTube, CrunchyRoll which have subtitles in multiple languages, the user gets an option to choose the preferred language. For Netflix, Amazon the user needs to have a valid login and subscription to the videos, only then the subtitles will be downloaded.\nThe whole application was written from scratch. It was coded in Python 3 and it uses a few external libraries like BeautifulSoup, selenium for Python.\nThe commits to this project repository can be found in the link -\nSubtitle Extractor Commits\nFuture Work In the future support for new services like ComedyCentral, Channel5 will be added. As the application depends on the individual services websites, the repository will be checked regularly for errors. Accordingly the bugs would be tackled. I also plan upon adding features like -\n Batch Downloading of Subtitles. (Currently on Amazon supports this feature) Choice of episode selection. Preference for file naming.  Other work Besides the work mentioned above, also contributed a few patches for bugs and features for CCExtractor:\n https://github.com/CCExtractor/ccextractor/pull/387 https://github.com/CCExtractor/ccextractor/pull/379 https://github.com/CCExtractor/ccextractor/pull/367 https://github.com/CCExtractor/ccextractor/pull/351 https://github.com/CCExtractor/ccextractor/pull/329  The detailed list of commits can be found here on this page - My commits to the main repository\n","link":"https://ccextractor.org/public/gsoc/2016/abhishek/projects/","title":"Subtitle Extractor"},{"body":"(document produced by Code-In student Deborah Chan)\nCountries under ATSC standards:\nOld: CEA-608 New: CEA-708\nAsia/Pacific:\nSouth Korea United States Minor Outlying Islands (American Samoa, Guam, Northern Mariana Islands)\nNorth America:\nBahamas Canada Dominican Republic El Salvador Mexico United States (including Puerto Rico and U.S. Virgin Islands)\nSouth America: Suriname\nCountries under DVB standards: EN 300-743 http://www.etsi.org/deliver/etsi_en/300700_300799/300743/01.05.01_60/en_300743v010501p.pdf\nAfrica: Kenya South Africa Madagascar\nAsia: China Hong Kong Iran Israel Japan Malaysia Philippines Taiwan\nEurope: Cyprus Denmark Finland Iceland Italy Netherlands Norway Poland Portugal Romania Russia Sweden United Kingdom\nAustralia: http://www.abc.net.au/mediawatch/transcripts/1105_freetvguidelines.pdf\nCroatia: http://dhap.hr/en/articles/criteria-for-quality-subtitlin/8\nFrance: (only available in French) http://www.csa.fr/content/download/20043/334122/file/Chartesoustitrage122011.pdf\nIreland: www.bai.ie/en/download/128530/\nCountries/Areas with more than 1 standard found: Canada: https://www.dcmp.org/caai/nadh218.pdf http://www.cab-acr.ca/english/social/captioning/captioning.pdf http://www.crtc.gc.ca/eng/archive/2012/2012-362.pdf\nEU: https://tech.ebu.ch/docs/tech/tech3350.pdf?vers=1.0\nUnited Kingdom: http://bbc.github.io/subtitle-guidelines/ http://www.bbc.co.uk/guidelines/futuremedia/accessibility/subtitling_guides/online_sub_editorial_guidelines_vs1_1.pdf http://www.channel4.com/media/documents/corporate/foi-docs/SG_FLP.pdf\nUnites States: https://backlothelp.netflix.com/hc/en-us/articles/215758617-Timed-Text-Style-Guide-General-Requirements http://main.wgbh.org/wgbh/pages/mag/services/captioning/faq/sugg-styles-conv-faq.html http://transition.fcc.gov/cgb/consumerfacts/closedcaption.pdf http://www.ecfr.gov/cgi-bin/text-idx?SID=72eb5a624e8dc043293819a5663dff41\u0026amp;node=47:4.0.1.1.6.1.1.1\u0026amp;rgn=div8=47 https://www.smpte.org/sites/default/files/24TB-FCC-Technical-Requirements-20120908.pdf\n","link":"https://ccextractor.org/public/general/subtitle_standards_around_the_world/","title":"Subtitle standards around the world"},{"body":"We know that working on existing codebases can be daunting, and you might end up working on a new project anyway, so this year we have some alternative qualification tasks (we'll add more soon, so come back).\nYou can still opt for the standard ones (such as fixing issues on GitHub) --- these are just alternatives that are available.\n Interprocess communication (low-level) Language: Modern C (not C++). Must work in: Linux\nCreate a program, in C, that utilizes queues and memory-based interprocess communication.\nWe're writing a system that encodes video using hardware encoders, specifically nVidia GPUs. These consumer-grade GPUs are limited to two simultaneous encode sessions. However they can encode (really) fast, easily at 300 frames per seconds.\nWe want to overcome this limitation by distributing the load in software. Suppose you have 10 cameras each of them providing a never ending stream of video at 30 frames per second. The job is to come up with a good plan (and proof of concept) that maximizes GPU usage.\nHere's a few things that will help you:\n You will need to have a queuing system that take the frames. Let's assume on the assumption that there is one process that reads data from one specific camera, so if there's 10 camera there are 10 such processes. They are the producers. Let's call them CameraManagers. Because of the way video encoding works (in which one frame can be compressed a lot by using information from the previous one), you can 't just merge data from all the cameras and them send to the GPU as they arrive. Instead, you will need to batch them and send a number of frames from one specific camera (maybe 2 seconds, so 60 frames) at a time. We'll call the program that manages the work queue and the GPU the GPU manager. Remember that while you do this the frames will continue to arrive. Frames are big, so you want to minimize copying data around. For this, you have shared memory between processes. A possibility here is to have one GPUManager, that will take the frames from the the CameraManagers. The GPUManager will need to keep one list of pending frames per camera and a queue of cameras. When a camera has sent 60 frames its list of pending frames is ready to be encoded. The GPUManager then encodes those frames (that causes a file to be generated with the output, but that's not needed for this exercise) and clears the list. Remember that while encoding was in progress other frames may have arrived and you don't want to lose them. As mentioned, there's 2 encode sessions. The GPUManager needs to support that and simultaneously encode two frame-queues at a time. Cameras can be added, removed, and come down (for example, they can break, or their CameraMananger can crash). You system needs to be tolerant to this. You need to create the mockup CameraManager and the Mockup GPUManager. Since you don't have cameras of course, for each frame read a block of 1280x800 bytes from /dev/urandom. Demostrate that it works will by validating the output, for example using a checksum of each input frame and writing it to the output which can be a sample text file that contains the \u0026quot;camera number\u0026quot;, \u0026quot;frame number\u0026quot;, and \u0026quot;checksum\u0026quot; for that frame, in order.   Meetup auto-RVSP Language: Any Must work in: Linux\nThis task is relatively simple (in theory), but it will help us assess your code organization abilities.\nWrite a program for meetup.com that sends an auto-RVSP to specific groups. For example, suppose you are a member of 7 different Meetup groups, some of which have very popular events that fill up quickly. You want to sign up for them as fast as possible to ensure that you get a spot.\nYour program needs take care of authentication, searching for events in configured groups (not all), and automatically signing up on the user's behalf in a timely manner. Usage of existing Meetup client libraries is permitted.\nIt's OK for your program to be a simple command-line tool that needs to be run from cron once an hour or something like that.\n Plan for migrating our DokuWiki website to fastpages Language: Any Must work in: Linux (whatever migration system you come up with)\nOur website currently uses an easy-to-use wiki solution called DokuWiki, but the aesthetics could be better.\nThere's a new platform that uses GitHub Pages for hosting and pull requests for content management. It seems to integrate well with things we care about, e.g. YouTube embeds.\nCan you devise a good plan for migrating from DokuWiki to fastpages?\n Export data from MyFitnessPal to Grafana Language: Any Must work in: Linux (anything server side)\nMyFitnessPal is a mobile app used to track food \u0026amp; energy intake, exercise, and more. It supports CSV data export (e.g. through email) to facilitate archival, but this style is a bit antiquated for manual viewing.\nA simple website that accepts CSV exports and renders nice visual representations using Grafana would be much better for users. This should be feasible to complete in a few days since all of the major components already exist.\n VoxelSpace in Flutter Language: Flutter Must work in: Android, iOS (OK if you can just test in one, but we will test in both and if it doesn't work we'll send you the debug info so you can fix it).\nA couple decade ago a superfun helicopter game took the gamers by storm. Well, that's a bit hyperbolic but it was really fun and a lot of people spent thousands of hours flying that helicopter.\nWhat made it revolutionary was the technique used to draw the terrain. Of course that's obsolete by today's standards, but it still looks quite good, considering it's age.\nYour job is to write a simple Flutter program that does the same thing. And no, you don't have to research VoxelSpace by yourself - there's source code already, but not in Flutter.\nWrite a Flutter program that does this. And to make it more interesting, edit the terrain map so the text \u0026quot;GSoC 2020, CCExtractor Development\u0026quot; can be read when flying.\n Beacon in Flutter Language: Flutter Must work in: Android, iOS (OK if you can just test in one, but we will test in both and if it doesn't work we'll send you the debug info so you can fix it).\nWrite a Flutter app that is able to share your location with anyone who has a specific passkey. For example, suppose you are going to start a hike with friends and you want them to know your location but only for the next 3 hours. You can do that in many ways, but let's say one is by letting people look up a passkey somewhere (to simplify things consider that it's OK to look up a list of passkeys in a static file hosted in github, so you don't need to setup a database).\nYour app then will have two modes of operation: Someone is sharing their location (that means \u0026quot;carrying the beacon\u0026quot;) and everybody else can see that location (they are \u0026quot;following the beacon\u0026quot;).\n Camera with intelligent autozoom in Flutter Language: Flutter Must work in: Android, iOS (OK if you can just test in one, but we will test in both and if it doesn't work we'll send you the debug info so you can fix it).\nWrite a Flutter app that lets you take pictures of anything and autozooms to the right size to pick up an object that is in view. For example: Take a collection of dogs, or cats (there are probably pretrained models for this, it's up to you to look them up). If your app is used to take a picture of a dog, then the zoom should be automatically adjusted to take a picture of the dog in foreground, even if the dog is a bit far.\nIt must be fast or the dog will move!\n","link":"https://ccextractor.org/public/gsoc/takehome/","title":"Take-home qualification tasks"},{"body":"Introduction\nBitTorrent is, of course, the world's most used peer to peer protocol. It's great, but it was designed before the cloud was ubiquitous and it doesn't make use of the places where you have the most storage or the most bandwidth. Can we design something for the next decade?\nBitTorrent is based on the concept of peers, which are BitTorrent clients, usually running on computers at home, that share data is a super-efficient manner. It works well, of course, but\n It requires users to have their computers on for a long time - It requires users to expose their IP address - It requires users to use their home internet connection, making it hard to do other things at the same time such as streaming  There are of course alternatives (you can rent servers in data centers for example), but they are not cheap, they're not easy to set up, and they come with their own sets of problems, in general.\nThese days most people have lots of their data in the cloud: Dropbox, Google Drive and so on.\nYour job\nThe goal here is to come up (and implement the first version) with a system that let those personal storage systems exchange data\n Securely - As cheap as possible - As fast as possible - As easily as possible  A possible idea (one of many possibilities) would be to introduce the concept for \u0026quot;agent\u0026quot;. An agent would be a process that runs in the cloud on behalf of the user and that has access to his personal storage accounts. The agents can run anywhere, but their ideal place is the cloud, for example, AWS or Google Cloud. They can be managed by the final user or by a 3rd party that provides the service.\nAgents find each other, and learn to trust each other, with the help of repositories, the equivalent of today's trackers.\nAgents that trust each other can vouch for other agents.\nThe chain of trust must always be preserved so agents can prune trees if the trust is broken.\nQualification tasks\nTake a look at this page.\n","link":"https://ccextractor.org/public/gsoc/cloudtorrent/","title":"The next peer-to-peer protocol"},{"body":"Developed under Google Summer of Code, 2018 with CCExtractor Development By Satyam Mittal\n Introduction The CCExtractor Sample Platform manages a test suite bot, sample upload and more. This platform allows for a unified place to report errors, submit samples, view existing samples and more. The sample platform has been a good way to test regression tests, but still lacks some features such as running customized tests.\nThe main aim of the project is to make sample platform fully finalized and be as stable as possible. It will include adding some new features and some fixes which will increase the stability of the platform. The features and fixes are given below.\n Detailed Description/Timeline  Comment on the opened PR if a test fails Add support for running the bot in forks Add support for single test runs or smaller sample sets Foundation upgrade broke lay-out Migration to Python-3 Adding Restart / Stop for admin and user   Original​ ​ Vs​ ​ Achieved​ ​ Goals  Comment on the opened PR if a test fails: Now users can easily see the textual overview of what is failing. It is always better to comment the all failing tests on the Pull Request. It will save the time of user by summarizing the error on the same pr and easily check the status of pull request. Template shown below: Add support for running the bot in forks: It has been added and working properly. Now Users can enter commit or select the commit from their fork repository that are not more than 30 days old. They can select the platforms (linux, platform) they want to run their tests. List of tests started by user are displayed on same page. Add support for single test runs or smaller sample sets: Now Users can customize tests based on selected regression tests and platforms. They can run their test on subset of regression tests. Test Progress will be displayed according to selected regression tests. Active Status has been added to Regression tests. Regression test status will tell whether it will run on test of main repository or not. Combined with previous feature, Customized Test would give the contributors full freedom to experiment with fixes on their forks. Foundation upgrade broke lay-out: After Foundation upgrade, there were some UI fixes left. All the pages are mobile responsive. I fixed broken layout, fixed design of some pages and made tables mobile-responsive. Python-3.6 Migration: Platform Python version has been migrated from 2.7 to 3+. Adding Restart / Stop for admin and user: A button has been added in the admin test panel to make it easy for admin to stop or restart the test. After adding single test, corresponding user can stop the test or restart if he thinks somewhere he went wrong before test completes to decrease the load in the platform. Documentation: All changed set has been properly documented. I have added pydocs from methods and inline comments. I have followed pep8 while adding pull request. User documentation has been updated. Unittesting: I have increase the test coverage to around 60%. It is still in progress.   Project Related Links  Github Project repository: https://github.com/canihavesomecoffee/sample-platform Project documentation : https://github.com/canihavesomecoffee/sample-platform/blob/master/README.md Project Proposal: https://docs.google.com/document/d/1sOwdF_924WUYEGDB6IM-caZzepp0-tutLpjfUI-xT88/edit?usp=sharing Official GSoC Project Link: https://summerofcode.withgoogle.com/projects/#4548101499518976 Mentor: Willem Van Iseghem Hosted Project Server Link: https://sampleplatform.ccextractor.org/   Contributions[Commits/PRs] All my commits to the repository can be found here: Commits\nAll my pull requests to the repository can be found here: Pull Requests\n Other Works I keep on fixing new bugs/issues raised in issue tracker time to time. I will try my best to have smooth functioning of the sample platform.\n What I have learned Doing​ ​this​ ​project​ ​is​ ​a ​lot​ ​fun​ ​with​ ​a lot​ ​of​ ​things​ ​to​ ​learn.​ ​The​ ​number​ ​of​ ​such​ ​things​ ​is​ ​more than​ ​I ​​can​ ​even​ ​write​ ​but​ ​summing​ ​up​ ​all​ ​this​ ​the​ ​major​ ​things​ ​which​ ​I ​learn​ ​includes​ ​ :\n I have been contributing in CCExtractor CI platform from last 1.5 years and the journey has been great, I have learned a lot from working in different modules and also got an opportunity to discover many concepts behind some modules. The project help me how to work in a team and in systematic way. Putting​ your​ doubts​ in​ front​ ​of​ ​others​ ​as​ ​during​ ​this​ ​period​ ​a number​ of​ errors​ ​will​ ​come and​ ​you​ ​should​ ​have​ ​to​ ​ convey​ ​what​ ​you​ ​want​ ​to​ ​say​ ​to​ ​others,​ ​seems​ ​easy​ ​but​ ​not​ ​that for​ ​me​ ​atleast. Importance​ ​of​ unit-testing, ​indentation​, ​documentation​ ​as​ ​during​ ​this​ ​period​   Known Issues/ Future Work  Since the part of work that I have done in CCextractor's Sample Platform was done with altmost care according to my knowledge, therefore I would try to remove any bug in part of my code reported by someone else or encountered by me. Apart from CI platform, I will try my best to contribute in other ongoing projects in CCExtractor organization.   Addendum I am doing my 4rth year of graduation. I will keep contributing to the sample platform. Apart from that, I will continue to do my best and contribute to the organization.\n Contact Details If you have any doubts or suggestions you can contact me anytime you want. Here are the details :\nEmail address : satyammittalid@gmail.com\nGithub : satyammittal\nBlog: Wordpress\nSlack : bashtech\n Thanks ","link":"https://ccextractor.org/public/gsoc/2018/satyam/","title":"The sample platform / Continuous integration"},{"body":"You can use the cctranslate tool (implemented by Oleg) to translate extracted captions in realtime and in SubRip formatted files. We use the Google Translate API for translation, but the tool is built so developers can easily add other translation engines.\nHow realtime translation works?  ccextractor starts with sharing service on ccextractor launches cctranslate process launched instance of cctranslate subscribes to ccextractors' messages ccextractor publishes extracted subtitles to all subscribers cctranslate requests translation from translation service and saves translated captions to an output file  Ok, and what is a \u0026quot;sharing service\u0026quot;? Sharing service is a Publisher-Subscriber IPC Pattern publisher implementation. It uses nanomsg as a cross-platform socket library, that provides simple interface to implement pub-sub model and supports lots of transport mechanisms. To serialize messages protobuf-c implementation of Google Protocol Buffers is used. Both of used solutions are language-independent, so sharing service could be easily used by third-party developers to create new solutions based on ccextractor.\nWhat about the cctranslate tool? Cctranslate tool was designed to be cross-platform and is implemented in C language. It uses:\n libcurl to perform http/https requests nanomsg as a socket library protobuf-c to parse serialized messages CJSON to parse responses from Google Translate API  Standalone SubRip-formatted files could also be translated using this tool along with realtime translation.\nSharing service messaging format Coming soon in a separate document\nHow to use it? First, you have to compile it. It uses cmake build automation system, so make sure you have it installed. For Linux/MacOSX/UNIX use:\n$ mkdir build \u0026amp;\u0026amp; cd build $ cmake ../ $ make Make sure nanomsg and libcurl dev packages are downloaded. If your distribution doesn't have a package system or these packages are not supported by maintainer, you can download tarballs and compile it by yourself.\nThen, create a Google CloudPlatform account (or use your existing) and generate an API key.\nUsing cctranslate as a standalone text file captions translator Check what languages are available at the moment:\n$./cctranslate --list-langs --key=YOUR_API_KEY Pick up languages you want your subs be translated to, and run:\n$./cctranslate --input=subs.srt --langs=fr,it,th --key=YOUR_API_KEY Using cctranslate for realtime translation Copy cctranslate tool to ccextractors' binary directory. There are two ways to translate realtime: launch ccextractor with translating mode on and launch cctranslate tool to connect to already running instance of ccextractor.\nTo launch ccextractor with translating mode on, run:\n$ ./ccextractor INPUT_OPTIONS -translate LANGUAGE_LIST -translate-auth YOUR_API_KEY To connect cctranslate tool to already running instance of ccextractor:\n$ ./cctranslate --source=extractor --key=YOUR_API_KEY In the second case, ccextractor has to be started with sharing service on. To do that add -enable-sharing option to arguments. By default, it starts TCP sharing service on localhost:3269. You can set other nanomsg-supported transport type to share captions using -sharing-url arg in format transport:address.\n","link":"https://ccextractor.org/public/gsoc/translating_captions/","title":"Translating captions"},{"body":"We often get requests for samples from other developers and users. Our full collection is available to developers that need it (some of the samples were submitted by people who explicitly told us not to make them public, which we honor) However we're starting to build a small public repository for everyone who wants to test.\nThe following link contains 10 minutes recorded of over 30 US TV channels. They were made with a HDHomeRun on Dec 14, 2016. The provider is Comcast. Nothing really interesting in content - 10 minutes per channel, recording in the West Coast morning, so just daytime TV, whatever was on.\nUS TV recordings, 10 minutes samples, HDHomeRun, Comcast\nUS TV recordings from 2017, unknown provider\nThe following link contains short recordings from some non-subscription UK channels. Some of them come from a multicast stream and some were recorded with a HDHomeRun. Whatever was on at the time (8 pm to 10 pm UK time). Be aware that the UK considers their citizens to be adults that can just switch channels if they don't like what they see.\nUK TV recordings\nThe following link contains 15 minute recording from the same UK channels as above. We have the original .ts files (that would be the input for any CCExtractor processing) and the same files with the DVB subtitles burned-in with FFMpeg in .mp4, which is very convenient to check timing. Also the .srt files with default CCExtractor settings (as of 0.85 prelease) and with -ignoreptsjumps are included.\n2017-01-09 UK samples (ts/mp4 with burned in subtitles)\nThe following link contains some recordings from Scandinavian countries. Teletext.\nScandinavian recordings\nThe following link contains some Russian samples. Teletext.\nRussian teletext samples\nAnd this one, more (unclassified) Russian samples. Some seem to have DVB.\nRussian unclassified samples\nMultiprogram transport streams. multiprogram_spanish.ts is quite interesting in that there's a mix of DVB and teletext plus TV and radio channels.\nMultiprogram transport streams\nKorean samples. See this issue in GitHub for details.\nKorean samples\nThe following link is a TV show with both regular closed captions and burned-in subtitles (in English, when the characters speak in Russian). This is the original unedited transport stream, with commercials. For development purposes only.\nDual closed captions - burned-in subtitles transport stream \nArabic samples \nBrazilian samples \nChinese samples \nSome transport streams with no PAT or PMT\nEuropean samples,teletext\nMisc files\nccextractor_bugs_allcaps_29fps_leftjustify.m2ts dvb-sub captions containing multiple lines of text.\nbig_buck_bunny_eac3_4.m2ts DVB-sub captions which prior versions of ccextractor failed to extract.\nchannel5-2018-02-12.ts A recording from Channel 5 (UK). Forget about the content itself (it's in the middle of two random programs). The important thing is that we do a terrible job with the OCR.\nDJI_0019.MP4 A recording (.mp4) from a Drone in which the telemetry data is saved as subtitles.\n","link":"https://ccextractor.org/public/general/tvsamples/","title":"TV Samples"},{"body":"Tasks here can be picked up by any student. Feel free to add them to your to-do list or if you like it better than something in your proposal you can replace. Please contact Carlos about it in any case.\n   Task Who Depends Planned dates Status Mentor notes     GXF Support Unassigned   Not started This is a request from a user; GXF is one of those professional formats (such as SCC) that we might never want to use personally but that would be really useful in the CC industry.   DV Support Unassigned   Not started This is a request from a user; See DV Support Request for details.    ","link":"https://ccextractor.org/public/gsoc/ccextractor_unassigned_tasks_pick_what_like/","title":"Unassigned tasks"},{"body":"Tmate - Instant terminal sharing \n","link":"https://ccextractor.org/public/general/misc/useful_linux_tools/","title":"Useful Linu tools"},{"body":"Activity Extractor aims to extract and download viewing activity from popular video streaming services including: Netflix, Hulu and Amazon. This process is automated and needs very little user interaction. It can be called from the command line with the streaming service as a parameter, and it outputs the viewing activity into a simple .txt file.\nThe program requires the user to have a valid login and password for the streaming service they wish to retrieve viewing activity from.\nInstallation Instructions Clone the repository from GitHub:\ngit clone https://github.com/ManveerBasra/ActivityExtractor\nInstall pip If pip3 is not installed run this in a command window:\n- sudo apt-get install python3-setuptools - sudo easy_install3 pip - sudo mv /usr/local/bin/pip /usr/local/bin/pip-3 Install Selenium Run this in a command window:\n sudo pip3 install -U selenium Install PhantomJS Make sure you have NodeJS installed (https://nodejs.org/) Using Node's package manager run this in a command window:\n npm -g install phantomjs-prebuilt Disclaimer: Use it at your own risk.\nUsage Instructions If credentials are already in userconfig.ini Open a command window in directory containing ActivityExtractor.py Run this command:\n python activityextractor.py [service] [service]: Put your streaming service here\nIf credentials are NOT already in userconfig.ini Open a command window in directory containing ActivityExtractor.py Run this command:\n python activityextractor.py [service] --email=[email] --password=[password] [service] : Put your streaming service here [email] : Put your email address for the streaming service here [password]: Put your password here\nIf you're getting activity from Netflix, you must include an additional parameter:\n... --user=[user]\n[user] : Put your Netflix username here\nPlease report any errors on GitHub along with the error message for support.\n","link":"https://ccextractor.org/public/codein/activity_extractor_user_docs/","title":"User Documentation for Activity Extractor"},{"body":"Introduction The project deals with downloading of subtitles from popular online TV Services like Netflix, BBC,Hulu. The project aims to perform this task without the need for the user to interact with the browser. The process is automated completely. The user just needs to input the URL of the video and the application will download the subtitles. For services like YouTube, CrunchyRoll which have subtitles in multiple languages, the user gets an option to choose the preferred language. For Netflix, Amazon the user needs to have a valid login and subscription to the videos, only then the subtitles will be downloaded.\nINSTALLATION INSTRUCTIONS Clone the repository -\ngit clone https://github.com/abhishek-vinjamoori/SubtitleExtractor.git\nEnsure that \u0026quot;python 3\u0026quot; is installed on your computer.\nsudo apt-get install python3\n[DEPENDENCIES]\nDependencies to be installed -\n pip install requests\nIf pip3 is not installed -\nsudo apt-get install python3-setuptools sudo easy_install3 pip sudo mv /usr/local/bin/pip /usr/local/bin/pip-3 sudo pip3 install -U selenium pip install beautifulsoup4 //Disclaimer: Use it at your own risk.//\nNote : For Amazon,Netflix subtitle downloads - \u0026quot;Stable releaseof Google Chrome is required.\u0026quot;\nFor Amazon, Netflix :\nMake sure you already have Google Chrome installed. Then download and extract the contents of - http://chromedriver.storage.googleapis.com/index.html?path=2.22/ You will get a file named \u0026quot;chromedriver\u0026quot; Then go to the directory where \u0026quot;chromedriver\u0026quot; is present and execute the following command :\nsudo mv -t /usr/local/bin/ chromedriver (Move the chromedriver file into /usr/local/bin)  HULU  Ensure that SubtitleExtractor.py executable. (Command for making it executable - chmod +x SubtitleExtractor.py) Run the python file - ./SubtitleExtractor.py Paste the desired URL (from Hulu website) for which Subtitles have to extracted and press “ENTER”. If multiple languages are available you will be prompted to choose the desired language option. Subtitles will be downloaded.   YouTube  Ensure that SubtitleExtractor.py executable. (Command for making it executable - chmod +x SubtitleExtractor.py) Run the python file - ./SubtitleExtractor.py Paste the desired YouTube URL from which Subtitles have to extracted and press “ENTER”. If multiple languages are available you will be prompted to choose the desired language option. Subtitles will be downloaded.   Amazon = Note ~ Amazon requires that you have a valid subscription for that particular video to download the subtitles\nThese instructions need to followed whenever you want to “change login details”. -\n  Ensure that SubtitleExtractor.py and “setup.py” are executable. (Command for making them executable - chmod +x SubtitleExtractor.py setup.py)\n  Open the file “userconfig.ini”.\n  Type in your new Amazon Username and Amazon Password in the respective fields.\n  Save the file and exit.\n  Now run the file setup.py - ./setup.py\n  If the setup is successfully done, you will see no errors. These instructions need to be followed when you are done with the one time setup file. From now on, you can just follow these instructions unless you want to change your login details ~\n  Run the python file - ./SubtitleExtractor.py\n  Paste the desired Amazon URL from which Subtitles have to be extracted and press “ENTER”.\n  If it is a movie, Subtitles will be downloaded normally.\n  If it is a TV Series, all the episodes of that season will be downloaded in a new folder with the corresponding title.\n   BBC Note ~ Please check that you are able to stream the video without any geo-location errors.\n Ensure that SubtitleExtractor.py executable. (Command for making it executable - chmod +x SubtitleExtractor.py) Run the python file - ./SubtitleExtractor.py Paste the desired URL (from BBC website) for which Subtitles have to extracted and press “ENTER”. Subtitles will be downloaded.   CrunchyRoll  Ensure that SubtitleExtractor.py executable. (Command for making it executable - chmod +x SubtitleExtractor.py) Run the python file - ./SubtitleExtractor.py Paste the desired URL (from Crunchyroll website) for which Subtitles have to extracted and press “ENTER”. You will be asked to choose the language in which the subtitles have to be downloaded based on the availability. Enter the corresponding number. Subtitles will be downloaded in the chosen language.   Netflix Note ~ Please check that you are able to stream the video without any geo-location errors.\n Ensure that SubtitleExtractor.py executable. (Command for making it executable - chmod +x SubtitleExtractor.py) Open the file “userconfig.ini”. Type in your new Netflix Username and Netflix Password in the respective fields. Save and exit. Run the python file - ./SubtitleExtractor.py Paste the desired URL of the video (from Netflix website) for which Subtitles have to extracted and press “ENTER”. Subtitles will be downloaded.   FOX Note ~ Please check that you are able to stream the video without any geo-location errors.\n Ensure that SubtitleExtractor.py executable. (Command for making it executable - chmod +x SubtitleExtractor.py) Run the python file - ./SubtitleExtractor.py Paste the desired URL (from FOX website) for which Subtitles have to extracted and press “ENTER”. Subtitles will be downloaded.   Crackle *Note: *Please check that you are able to stream the video without any geo-location errors. After clicking on a TV show ensure that the URL contains some integer ID in it. Or else, click again on the episode from the playlist below to obtain the desired URL.\n Ensure that SubtitleExtractor.py executable. (Command for making it executable - chmod +x SubtitleExtractor.py) Run the python file - ./SubtitleExtractor.py Paste the desired URL (from Crackle website) for which Subtitles have to extracted and press “ENTER”. Subtitles will be downloaded.  Please report any errors on GitHub along with the error message for support. ","link":"https://ccextractor.org/public/gsoc/2016/abishek/subtitle_downloader/","title":"User Documentation for Subtitle Downloader"},{"body":"Using Vim as your main editor for web development\n","link":"https://ccextractor.org/public/general/misc/vim/","title":"Vim"},{"body":"Questions? You can email us at code-in@ccextractor.org or join our Slack group! But please make sure you read the whole page first.\nThis is going to be another absolutely amazing GCI year! We have a long and proud history of taking part in the Google Summer of Code with university students, and are excited to participate in GCI again for 3rd year with pre-university students! We have tasks that are: fun, useful, educational... and for all levels and interests - coding, design, documentation, UI, research and much more!\nWhile it is completely optional, it is highly recommended that you join our Slack group. All the mentors, org admins, contributors and fellow GCI participants hang out in that group. That's the best place to get quick answers to any query or problem you might have. Go to the end of this page to invite yourself to the group.\nCan't join the Slack group? It's no problem! We try to be super fast to respond to all comments and submissions in the GCI website. If you prefer email, you can email us at code-in@ccextractor.org. There's also a mailing list/Google group for CCExtractor : https://groups.google.com/forum/#!forum/ccextractor-dev if that's how you sail!\nThings to know! ✅   For tasks that require some resources in general we will provide them for you, including access to videos, system accounts, etc.\n  This year we are going to have some system administration tasks. We will provide you with root access (Yes! We're that cool) to a small server for interested students to play with. Check out our sysadmin tasks.\n  We can't stress this enough: Winners are those that do the hard tasks. Amount of tasks is not so important.\n  Collaboration is much better than competition.\n  Mentors love it when a student comes up with a better idea than their own, really. Do not just do as told. If something doesn't feel right either argue against it (politely of course) or work on a different area.\n  If you want to do something that is 90% or so implemented in any other open source project just take it, complete it, send the maintainers of that project whatever changes you did so they can use them if they want, and integrate with our code. Always remember to leave all license and credits intact (you can add your own name).\n  Mentors are there to help but they're people too, not bots. So they sleep from time to time, may also have other things going on, can get sick, etc. They will reciprocate when they think of students.\n  Whatever you do, we want to integrate. This means that your work will be public and will be around for a long time. In a few years you will find your own code again (code tends to follow you). Try to leave it in a condition that the future you will be proud of.\n  Be mindful of your own privacy. Yes, we're a friendly bunch and you'll get to know us and we'll get to know you in our community. That's different from posting your real name publicly everywhere.\n  Perks Remember that the absolute best way to get invited by an organization to participate in Google Summer of Code is by being part of the community before GSoC is even announced. If we, as an organization, are invited to GSoC 2019 the applications from successful Code-in students will go to the top of pile.\nWe also give back to our students in any way we can, including writing recommendation letters that can help to apply to universities, visas, jobs and so on.\nIn short - don't think that the reward for participating this year may be limited to a t-shirt :-)\nCode-in for Designers 👩‍🎨 If you're passionate about becoming a great designer and willing to do some serious work, look for the tasks labelled [Harddesign]. Hard means that they are going to take time and talent to produce the quality results we want and to bring up design tasks at par with coding. At least one of the students that does a great job on those will be a finalist, and maybe a winner.\nWe are doing this to prevent the design tasks being treated just as an easy way to complete beginner tasks. For example, you can create a T-Shirt design in 10 minutes, but that's very unlikely to be good and usable to well, actually make T-Shirts with it.\nWe did this last year as well and got some amazing results. One of our winners from last year did some major design tasks including the organization logo.\nRemember though that hard means hard. Don't expect us to approve the first design you come up with. We will give you feedback and work with you until you produce something that you can be proud of for years and that we can use.\nGet familiar with Tags 🏷 We'll do our best to keep consistent tasks that help you find out good things to do. If you think we could use better tags please get in touch, with examples, and we'll improve. For some some tags you might want to look out for:\n winnerstrack: The hardest and/or more valuable tasks go here. If you are really serious about winning, work on those. To be realistic we don't think they will be solved, but it wouldn't be the first time a GCI student productivity is better than the mentors :-) So we're putting a few of these out there (not at the same time). hardtask: Difficult tasks but doable, with effort, patience, and mentor support. That's what we're here for! githubissue: The task has a related GitHub issue, so by doing this task you will be actually fixing a bug or adding a requested feature. anylanguage: Tasks that you can do in any programming language you want, usually because they are about writing a new (small) program so you would start from scratch. googleassistant: Tasks related to Google Assistant. We'll have a few of them every week, and they don't have to be related to our organization primary focus at all - they can be anything, because we want you (and us) to explore this new technology. bonus: Tasks that come with a special prize, such as a software license (that we will buy for the student) or a book. We will publish one of these tasks every week or so, so make sure to look for them often!  FAQ: Why is CCExtractor written in C? Are you from the past? ⏱ Yes, we get this from time to time :-) We know there's lots of cool languages out there, many really easy to start with, and well, C is not one of them. But the thing is, the most performance critical tools are written in C, such as the Linux kernel, or FFmpeg, or... you get the idea. A tool that needs to process lots of data (such as video) just needs to be as efficient as possible.\nWe do have auxiliary tools written in different languages, for example the Windows GUI is written in C#, and we have lots of Python as well. But the core CCExtractor tool is in C. Should you learn C then? Well, depends on how serious you are with IT in general. By learning it you will learn a lot of how things really work - without using all the magic that higher level languages provide.\nVideo from previous winners We think that the best way to let you know how cool Code-In is is to show you a video of previous winners. This was at Google's office in San Francisco in 2016, where Evgeny and Alexandru (which are of course now core developers at CCExtractor) presented what they did during GCI 2016!\n  And Aadi and Shiyuan (also core team members now as well as GCI mentors) in 2017\n  Matej and Ivan, 2018\n  Slack Slack is a great communication tool. Most CCExtractor developers hang out in a slack team. You're welcome to request an invitation here\n","link":"https://ccextractor.org/public/codein/google_code-in_2018/","title":"Welcome to Google Code-In 2018 and CCExtractor!"},{"body":"SPUPNG is two acronyms:\nSPU\nSub-Picture Unit. According to wikibooks.org: \u0026quot;Subpictures are used to display subtitles as well as menu buttons, overlaid on the video. These are stored in an MPEG stream (private stream 1) as a sequence of Sub-Picture Units (SPUs).\u0026quot;\nPNG\nPortable Network Graphics. According to libpng.org: \u0026quot;An Open, Extensible Image Format with Lossless Compression.\u0026quot;\nWhy SPUPNG?\nThe SPUPNG format is intended for use with authoring DVDs. The SPUPNG format does a better job of preserving the original closed caption format than the text based formats supported by ccextractor. Some of the problems with the text based formats are:\n  They lose row information. Closed captions can be displayed anywhere in a grid of 15 rows by 32 columns. But the text based formats do not indicate on what rows the captions should be displayed. So most applications will display captions near the bottom of the video, where most closed captions are usually placed. However, there are times when the video contains information that closed caption authors take care to not obscure by placing captions on the top rows, and sometimes even in the middle of a video. Captions are often placed at the top of video when the video is displaying text, such as credits, or the name of a speaker in a documentary.\n  They may lose column information. ccextractor provides whitespace in the text based formats so it is clear where captions should be placed horizontally. But some applications ignore the leading whitespace and simply center the text horizontally. In addition, fonts used to display captions are often proportional width fonts. If the user doesn’t (or cannot) configure the application to use a fixed width font, the way captions are laid out horizontally can be skewed. Information, such as whether the person to the left or right of the video is speaking, can be lost.\n  They usually don’t look like closed captions. Perhaps this isn’t a bad thing, but if you like the look of closed captions, you’ll like the SPUPNG format.\n  Some examples\nA picture is worth a thousand words. So here are some screenshots that show how the same caption in the same scene is displayed depending on the ccextractor output format, how an application displays the caption, and how the user configures the application to display the caption. The scene in question has two people engaged in conversation, the caption captures what both people are saying, and it is near the beginning of the show, so credits are displayed near the bottom of the scene.\n The above screenshot shows how a SRT formatted caption is displayed by VLC using VLC's default configuration where captions are displayed using the Arial font. Both people are talking, but can you tell who is saying what? Can you read the credit? Here is how the caption is encoded in the .srt file:\n20 00:02:15,636 --\u0026gt; 00:02:18,770 Wow. How long did that take? About a month.   The above screenshot shows how the dvdauthor tool, spumux, renders the same SRT formatted caption. I'll explain spumux in a later section. Now you can tell who is saying what, but it is still hard to read the credit.\n The above screenshot shows how a SAMI formatted caption is displayed by VLC after VLC's Subtitles/OSD preferences have been configured to use a fixed width font, Lucida Console, and the \u0026quot;Add a background\u0026quot; option has been checked. Here is how the caption is encoded in the .smi file:\n\u0026lt;SYNC start=135636\u0026gt;\u0026lt;P class=\u0026quot;UNKNOWNCC\u0026quot;\u0026gt; Wow. How long\u0026lt;br\u0026gt; did that take?\u0026lt;br\u0026gt; About a month. \u0026lt;br\u0026gt; \u0026lt;/P\u0026gt;\u0026lt;/SYNC\u0026gt; Who is speaking is clear in the .smi file, but not when VLC displays the caption. And the credit is even harder to read with the \u0026quot;Add a background\u0026quot; option enabled.\n The above screenshot shows how spumux renders the same SAMI formatted caption. In this case, spumux centers the text, so who is speaking is lost.\n The above screenshot shows how spumux renders the SPUPNG formatted caption. It is clear who is saying what, and the credit is not obscured by the caption.\nHow to use the SPUPNG output format\nThe SPUPNG format was designed to be used with the dvdauthor tool, spumux. According to the dvdauthor homepage: \u0026quot;DVDAuthor is a set of tools to help you author the file and directory structure of a DVD-Video disc, including programmatic commands for implementing interactive behaviour.\u0026quot; According to the spumux manpage: \u0026quot;spumux -- generates and multiplexes subtitles into an existing mpeg2 program stream\u0026quot;\nThis section describes how to use the SPUPNG format to create a very simple DVD-Video that plays one video. The procedure assumes a computer with a DVD burner running a Ubuntu flavor of Linux with the dvdauthor, ffmpeg (or libav-tools) and dvd+rw-tools packages installed. The tools in these packages are designed to be used from the command line and the dvdauthor tools are driven by XML files. A number of graphical user interface front ends for these packages are also available, some of which have been ported to Windows, along with the underlying dvdauthor and ffmpeg/libav-tools packages. More information can be found at the dvdauthor home page. I have not used any of the Windows applications, so their use is beyond my area of expertise.\n Extract closed captions in SPUPNG format  ccextractor -out=spupng -o spumux.xml source-video-file\nThis command will create the file, spumux.xml and a sub-directory, spumux.d. The sub-directory will contain lots of PNG files named subNNNN.png where NNNN is the 4 digit number of a closed caption starting at 0000. For example, the source video file used for the example screenshots, was one hour long and generated 1052 PNG files named sub0000.png to sub1052.png. Longer videos or videos with roll-up captions will generate more PNG files.\n Transcode video to DVD-Video format  Different Linux distributions will support either the ffmpeg package or the libav-tools package. The ffmpeg/avconv programs are complex and require many command line options to get the desired result. I maintain a shell script, do-ffmpeg, which I edit as needed to select:\n Cropping options, useful when the source video is letterboxed, Video bit rate (which determines how many hours can fit on a DVD with a tradeoff on quality), Video resolution (the DVD standard allows four different resolutions for NTSC and PAL each, I will usually use the most common, 720×480, but if the source video width is 704, I will use 704×480), Audio codec. I always try to copy the source video audio, but sometimes there is noise in the source that throws audio and video out of sync. In that case, I use options that transcode the audio and help maintain a/v sync. Whether to deinterlace. I usually do. Aspect ratio, either. 16:9 or 4:3.  Here is the do-ffmpeg script for ffmpeg version 0.6:\n#!/bin/bash # Transcode video to DVD-Video compatible format. # Usage: do-ffmpeg infile outfile if [ $# != 2 ] then echo \u0026quot;Usage: do-ffmpeg infile outfile\u0026quot; exit 1 fi # options of interest (applicable to ffmpeg version 0.6): # Cropping: # If a widescreen video is letterboxed in a 4:3 aspect ratio, # you might want to crop the letterboxed format, using the following: #crop=\u0026quot;-croptop 60 -cropbottom 60\u0026quot; # Sometimes you get a 4:3 video that's been letterboxed on the sides, too: crop=\u0026quot;-croptop 60 -cropbottom 60 -cropleft 90 -cropright 90\u0026quot; # The numbers need to be adjusted for the source video resolution # Bitrate determines the size and quality of the video: # 4670k = approx 2 hours of video on a 4.7GB single layer DVD # 3200k = approx 3 hours of video on a 4.7GB single layer DVD # 2400k = approx 4 hours of video on a 4.7GB single layer DVD bitrate=2400k # Video resolution: # Valid values for NTSC DVD-Video are: 720x480 704x480 352x480 352x240 # Valid values for PAL DVD-Video are: 720x576 704x576 352x576 352x288 # I usually use 720x480, unless the input is 704 wide, then I use 704x480 size=720x480 # Audio codec # If input file's audio is AC-3 or MPEG layer-2, you can usually let # ffmpeg copy it, using the following value for $acodec #acodec=\u0026quot;-acodec copy\u0026quot; # If the input audio isn't one of the above, or if there is noise in the audio # stream that throws audio-video out of sync, the following usually fixes it. acodec=\u0026quot;-acodec ac3 -ab 192k -ac 2 -async 1200\u0026quot; # Whether to deinterlace video: deint=\u0026quot;-deinterlace\u0026quot; # Aspect ratio: # 16:6 = widescreen # 4:3 = fullscreen aspect=\u0026quot;4:3\u0026quot; ffmpeg -threads 4 -v 1 -i $1 $deint $crop \\ -r ntsc -target ntsc-dvd -b $bitrate -s $size \\ $acodec -copyts -aspect $aspect \\ -y $2 If you are using a Linux distribution that supports libav-tools you will need a somewhat different script do-avconv:\n#!/bin/bash # Transcode video to DVD-Video compatible format. # Usage: do-avconv infile outfile if [ $# != 2 ] then echo \u0026quot;Usage: do-avconv infile outfile\u0026quot; exit 1 fi # options of interest (applicable to avconv version 0.8.9): # Cropping: # If a widescreen video is letterboxed in a 4:3 aspect ratio, # you might want to crop the letterboxed format, using the following: #crop=\u0026quot;-vf crop=in_w:in_h*3/4,scale=720:480\u0026quot; # Sometimes you get a 4:3 video that's been letterboxed on the sides, too: crop=\u0026quot;-vf crop=in_w*3/4:in_h*3/4,scale=720:480\u0026quot; # The scale should match the target video resolution # i.e. same as size below # Bitrate determines the size and quality of the video: # 4670k = approx 2 hours of video on a 4.7GB single layer DVD # 3200k = approx 3 hours of video on a 4.7GB single layer DVD # 2400k = approx 4 hours of video on a 4.7GB single layer DVD bitrate=2400k # Video resolution: # Valid values for NTSC DVD-Video are: 720x480 704x480 352x480 352x240 # Valid values for PAL DVD-Video are: 720x576 704x576 352x576 352x288 # I usually use 720x480, unless the input is 704 wide, then I use 704x480 size=720x480 # Audio codec # If input file's audio is AC-3 or MPEG layer-2, you can usually let # avconv copy it, using the following value for $acodec #acodec=\u0026quot;-c:a copy\u0026quot; # If the input audio isn't one of the above, or if there is noise in the audio # stream that throws audio-video out of sync, the following usually fixes it. acodec=\u0026quot;-c:a ac3 -b:a 192k -ac 2 -async 1200\u0026quot; # Whether to deinterlace video: deint=\u0026quot;-vf yadif\u0026quot; # Aspect ratio: # 16:6 = widescreen # 4:3 = fullscreen aspect=\u0026quot;4:3\u0026quot; avconv -threads 4 -v debug -i $1 $deint $crop \\ -r ntsc -target ntsc-dvd -b:v $bitrate -s $size \\ $acodec -copyts -aspect $aspect \\ -y $2 After editing the script, transcode the source video with the command: do-ffmpeg source-video-file transcoded.mpg or do-avconv source-video-file transcoded.mpg\nMultiplex SPUPNG captions into subtitle stream\nspumux spumux.xml \u0026lt; transcoded.mpg \u0026gt; subtitles.mpg\nCreate DVD-Video directory structure\nDvdauthor requires an XML file as input. Following is an extremely simple example that should start playing the subtitles.mpg as soon as the DVD is loaded in your DVD player. Paste it into a file called dvdauthor.xml.\n \u0026lt;?xml version=\u0026quot;1.0\u0026quot; encoding=\u0026quot;UTF-8\u0026quot;?\u0026gt; \u0026lt;dvdauthor\u0026gt; \u0026lt;vmgm /\u0026gt; \u0026lt;titleset\u0026gt; \u0026lt;titles\u0026gt; \u0026lt;video aspect=\u0026quot;4:3\u0026quot; format=\u0026quot;ntsc\u0026quot; /\u0026gt; \u0026lt;audio format=\u0026quot;ac3\u0026quot; lang=\u0026quot;en\u0026quot;/\u0026gt; \u0026lt;subpicture lang=\u0026quot;en\u0026quot; \u0026gt; \u0026lt;!-- doesn't work w/ dvdauthor 0.6.18 despite being documented in man page \u0026lt;stream mode=\u0026quot;normal\u0026quot; id=\u0026quot;0\u0026quot; content=\u0026quot;forced\u0026quot; /\u0026gt; --\u0026gt; \u0026lt;/subpicture\u0026gt; \u0026lt;pgc\u0026gt; \u0026lt;vob file=\u0026quot;subtitles.mpg\u0026quot; /\u0026gt; \u0026lt;/pgc\u0026gt; \u0026lt;/titles\u0026gt; \u0026lt;/titleset\u0026gt; \u0026lt;/dvdauthor\u0026gt; If you change the name of the output file, subtitles.mpg, in step 3, be sure to change it in the  element. Create the DVD-Video directory structure in a sub-directory called dvd with the command:\ndvdauthor -o dvd -x dvdauthor.xml\nIf you repeat the command, be sure to first delete the dvd sub-directory.\nBurn DVD\nLoad a blank DVD into your DVD burner. Then burn with this command:\ngrowisofs -dvd-video -V 'MyLabel' –Z /dev/dvd dvd\nPlay DVD\nThe video should start playing as soon as the DVD is read by your player. You will need to turn on subtitles using whatever mechanism your player supports, perhaps by pressing a subtitle key on the remote. Enjoy!\nContact\nIf you have questions or comments about the SPUPNG output format, please direct them to: mythtv@hbuus.com\n","link":"https://ccextractor.org/public/general/using_spupng/","title":"What does SPUPNG mean?"},{"body":"","link":"https://ccextractor.org/wiki/","title":"Wikis"},{"body":"The new interface is all you need, as it includes all the options. After installing CCExtractor you will have a shortcut in your desktop and a new entry in the Program Files folder (CCExtractor → CCExtractorGUI).\nFrom the GUI you have a lot of options. Usually, you will never need to use them (and if you do, you can save them as default) for regular usage.\nThere are several tabs. These are two that you will definitely need to use: The 'input files' tab, where you drag and drop (from Windows Explorer for example) the files you want to process, and the 'Execution' tab from where you launch the extraction process and see the progress.\nThis is the 'input files' tab:\n This is the 'execution' tab:\n As you can see, when a extraction is in progress you can see a preview of the subtitles (as they are being produced), the actual output Windows from the extraction process, progress, and more.\nBy default, CCExtractor produces .srt (SubRip) subtitles, as they are universally supported by all players, and they are easy to edit. There are however other formats that CCExtractor can generate.\nThis is the 'output' tab:\n Modifying how subtitles look like\nBy default, CCExtractor does it best to produce subtitles that look as they do on the TV. Depending on personal tastes, this is a good thing or it can be extremely annoying. In particular, there are two things that you may want to change: Position: Real closed captions are displayed on 32 columns by 15 rows grid. The person producing the captions can position them anywhere in the screen. For deaf people this is useful to know who's talking or where the sound is coming from. In the produces files, it might look like this:\nSG. FERNANDEZ VOLKER.\nIf this is annoying for you, you can select the 'center text' option in the decoder tab. Capitalization: Many stations broadcast their captions IN ALL CAPS, which is usually harder to read. I believe the reason is that the very first decoders (from decades ago) didn't support lowercase, and some stations or captions producers really really want to be on the safe side. Anyway, CCExtractor can apply the standard (English) capitalization rules and fix this. There is a small list of words that CCExtractor knows that must be capitalized, and you can also supply a file with a more complete list.\nThis is the 'decoder' tab from where you can change these and other things:\n Installation details (i.e. what are you installing on my computer?)\nStarting with version 0.64, the installer registers a DLL in your computer. This is a DirectShow filter that allows extraction of CC data from wtv files. If you don't want or can't (because you don't have administrator privileges) register this DLL, everything will still work except wtv support. Other than this the installer just copies the same files included in the .zip file with the windows binaries. No other changes are made.\nThe GUI needs the .NET runtime (it comes with Vista and 7, and most likely you already have it for other programs). If it is not installed it will download it from Microsoft's website.\nYou can uninstall everything from the Add \u0026amp; Remove programs option in the control panel and nothing is left behind (I think, because the Windows installer creator in Visual Studio is a bit of a black box...).\n","link":"https://ccextractor.org/public/general/win_gui_usage/","title":"Windows GUI usage"},{"body":"Starting in version 0.65, CCExtractor can process a stream being delivered via UDP, so there's no need to capture video to a file in order to get the subtitles.\nWhat devices are supported?\nWhile it should work with any device that is able to send the stream via UDP, at this time it's only been tested with HDHomeRun (both European and American models).\nWill other devices be supported?\nHDHomeRun works so well that it's unlikely I'll bother with any other device unless it finds its way to me for free and development is sponsored.\nHow do I use it?\nMake sure you have HDHomeRun's software installed. You will need the command line tool \u0026quot;hdhomerun_config\u0026quot; (it's available for Linux and Windows, possibly OSX too). GUI frontends are available, too, but the following instructions use just the command line tool.\nBecause you can have more than one HDHomeRun in the network, the first thing is to look for the IDs of each of them:\n./hdhomerun\\_config discover hdhomerun device 12206E95 found at 192.168.20.117 I only have one, and its ID is 12206E95. When I want to do anything with that tuner, I need to pass the ID to hdhomerun_config (note: since I only have one I could just pass FFFFFFFF which is accepted in this scenario).\nThen, have HDHomeRun scan for channels:\n./hdhomerun_config 12206E95 scan /tuner0\nThe first parameter is of course the ID of my HDHomeRun. I also need to pass /tuner0 because the device is dual-tuner, so I specify which one I want to use. The output is rather large - only a part of it is shown:\nSCANNING: 778000000 (eu-bcast:59) LOCK: t8qam64 (ss=90 snq=66 seq=100) TSID: 0x000F PROGRAM 184: 0 Boing PROGRAM 185: 0 Telecinco HD PROGRAM 304: 0 MTV PROGRAM 305: 0 Paramount Chann SCANNING: 770000000 (eu-bcast:58) LOCK: t8qam64 (ss=97 snq=28 seq=100) TSID: 0x03F4 PROGRAM 530: 0 La 1 PROGRAM 531: 0 La 2 PROGRAM 532: 0 24h PROGRAM 533: 0 Clan PROGRAM 535: 0 Radio Nacional PROGRAM 536: 0 Radio 5 Todo No In this output, the number after eu-bcast is the channel. A channel is a bundle of several programs (a program being a station) that are broadcast together. For example you can see that channel 58 contains 6 programs.\nSuppose we want the subtitles from \u0026quot;La 1\u0026quot;. First, tune to the channel that carries it: \n./hdhomerun\\_config 12206E95 set /tuner0/channel 58\nccextractor -srt -udp 1235 -stdout CCExtractor 0.65, Carlos Fernandez Sanz, Volker Quetschke. Teletext portions taken from Petr Kutalek's telxcc Input: Network, UDP/1235 [Raw Mode: Broadcast] [Extract: 1] [Stream mode: Autodetect] [Program : Auto ] [Hauppage mode: No] [Use MythTV code: Auto] [Timing mode: Auto] [Debug: No] [Buffer input: Yes] [Use pic_order_cnt_lsb for H.264: No] [Print CC decoder traces: No] [Target format: .srt] [Encoding: Latin-1] [Delay: 0] [Trim lines: No] [Add font color data: Yes] [Add font typesetting: Yes] [Convert case: No] [Video-edit join: No] [Extraction start time: not set (from start)] [Extraction end time: not set (to end)] [Live stream: No] [Clock frequency: 90000] Teletext page: Autodetect] Start credits text: [None] Sending captions to stdout. Reading from UDP socket 1235 File seems to be a transport stream, enabling TS mode Analyzing data in general mode [...] Program Master Table for program 530, PMT PID: 100 101 | MPEG-2 video 922 | MPEG-2 video 102 | MPEG-2 private data 2675 | Unknown 115 | Unknown 2051 | MPEG-4 video 1546 | Unknown 256 | Unknown 4102 | Unknown 353 | Unknown 2544 | Unknown 4976 | MPEG-2 audio 111 | MPEG-2 private data 2163 | Unknown 1 | MPEG-4 video 3301 | Unknown 768 | Unknown VBI/teletext stream ID 102 (0x66) for SID 530 (0x212) Skip forward to the next TS header mark. Programme Identification Data = La 1 Universal Time Co-ordinated = Mon Mar 11 21:36:23 2013 1 00:00:00,240 --\u0026gt; 00:00:02,560 Su voz suena en los altavoces. [...] As expected, in this example CCExtractor would run forever. You can control this with the time related parameters, in case you want CCExtractor to exit after a given number of seconds.\n","link":"https://ccextractor.org/public/general/working_with_hdhomerun/","title":"Working with HDHomeRun"}]